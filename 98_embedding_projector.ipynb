{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6013feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f5462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277ea6b",
   "metadata": {},
   "source": [
    "## Sentence Transformer to get Embeddings and Metadata for EmbeddingProjector\n",
    "[EmbeddingProjector](https://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c5916b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sentence-transformers) (0.10.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sentence-transformers) (4.11.2)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sentence-transformers) (0.1.96)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sentence-transformers) (1.9.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sentence-transformers) (0.0.18)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: tokenizers>=0.10.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sentence-transformers) (0.10.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sentence-transformers) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sentence-transformers) (0.24.1)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sentence-transformers) (4.62.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torch>=1.6.0->sentence-transformers) (0.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2020.11.13)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.0)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.46)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (20.9)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.26.0)\n",
      "Requirement already satisfied: ruamel.yaml==0.17.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from huggingface-hub->sentence-transformers) (0.17.16)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ruamel.yaml==0.17.16->huggingface-hub->sentence-transformers) (0.2.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nltk->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.6)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torchvision->sentence-transformers) (8.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ea9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model_st = SentenceTransformer('all-distilroberta-v1')\n",
    "#cat /usr/local/cuda/version.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f69a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PMID</th>\n",
       "      <th>source</th>\n",
       "      <th>Title</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The difficulty with this task lies in the fact...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The problem with rich annotations is that they...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a consequence , when adapting existing meth...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The second problem of traditional word alignme...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The main drawback of these systems is that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PMID         source Title  \\\n",
       "0           0   NaN  acl_cambridge   NaN   \n",
       "1           1   NaN  acl_cambridge   NaN   \n",
       "2           2   NaN  acl_cambridge   NaN   \n",
       "3           3   NaN  acl_cambridge   NaN   \n",
       "4           4   NaN  acl_cambridge   NaN   \n",
       "\n",
       "                                                text  labels  DOI  \n",
       "0  The difficulty with this task lies in the fact...       1  NaN  \n",
       "1  The problem with rich annotations is that they...       1  NaN  \n",
       "2  As a consequence , when adapting existing meth...       1  NaN  \n",
       "3  The second problem of traditional word alignme...       1  NaN  \n",
       "4  The main drawback of these systems is that the...       1  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/problem_statements.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648e87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"
     ]
    }
   ],
   "source": [
    "vectors = [model_st.encode(sentence) for sentence in df[\"text\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca00815",
   "metadata": {},
   "source": [
    "Saving files to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e981db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vectors).to_csv(\"downloads/vectors.csv\", index=False, header=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2313ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"downloads/metadata.csv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9438df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import base64\n",
    "def create_download_link( df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    csv = df\n",
    "    if type(df) != str:\n",
    "        csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f891d485",
   "metadata": {},
   "source": [
    "## For Longform Passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install torch==1.2.0 torchvision==0.4.0 #had to find this specification in the archives ... CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53bbcab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e2e857fda643d18d5cbbdc58d28778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606c6a500e0d4f2e96d1347a3df23cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5368f4d15c444205abdf99db8eea8c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe05f93c1c8478289f8da93faee43e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25da682ae47549b889650bd48a7ff186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "df = pd.read_csv(\"datasets/problem_statements.csv\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\") #longformer because it's a paragraph ... use sentence transformers for shorter texts\n",
    "model = AutoModel.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "#embeddings = df[\"text\"].map(lambda t: model(**tokenizer(t, return_tensors=\"pt\")))\n",
    "# text = \"Spaces is an S3-compatible object storage service that lets you store and serve large amounts of data. Each Space is a bucket for you to store and serve files. The free, built-in Spaces CDN minimizes page load times, improves performance, and reduces bandwidth and infrastructure costs.\"\n",
    "# encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# output = model(**encoded_input)\n",
    "#encoded_input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0130d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = df#[[\"name\", \"title\", \"url\", \"visit_time\"]]\n",
    "metadata.to_csv(\"metadata.tsv\", index=False, sep=\"\\t\")\n",
    "\n",
    "vectors = [model(**tokenizer(document[:4096], return_tensors='pt'))[1].squeeze(0).detach() for document in df[\"text\"].values]\n",
    "\n",
    "vectors_np = [v.numpy() for v in vectors]\n",
    "len(vectors_np)\n",
    "vectors_np[0]\n",
    "pd.DataFrame(vectors_np).to_csv(\"vectors.tsv\", index=False, header=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
