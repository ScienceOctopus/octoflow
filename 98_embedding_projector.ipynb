{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e4206a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194cbedd",
   "metadata": {},
   "source": [
    "## Sentence Transformer to get Embeddings and Metadata for EmbeddingProjector\n",
    "[EmbeddingProjector](https://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269228f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88bdc025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_st = SentenceTransformer('all-distilroberta-v1')\n",
    "cat /usr/local/cuda/version.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1702a809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PMID</th>\n",
       "      <th>source</th>\n",
       "      <th>Title</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The difficulty with this task lies in the fact...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The problem with rich annotations is that they...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a consequence , when adapting existing meth...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The second problem of traditional word alignme...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The main drawback of these systems is that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PMID         source Title  \\\n",
       "0           0   NaN  acl_cambridge   NaN   \n",
       "1           1   NaN  acl_cambridge   NaN   \n",
       "2           2   NaN  acl_cambridge   NaN   \n",
       "3           3   NaN  acl_cambridge   NaN   \n",
       "4           4   NaN  acl_cambridge   NaN   \n",
       "\n",
       "                                                text  labels  DOI  \n",
       "0  The difficulty with this task lies in the fact...       1  NaN  \n",
       "1  The problem with rich annotations is that they...       1  NaN  \n",
       "2  As a consequence , when adapting existing meth...       1  NaN  \n",
       "3  The second problem of traditional word alignme...       1  NaN  \n",
       "4  The main drawback of these systems is that the...       1  NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/problem_statements.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f196526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"
     ]
    }
   ],
   "source": [
    "vectors = [model_st.encode(sentence) for sentence in df[\"text\"].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05078b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3138"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a0df0",
   "metadata": {},
   "source": [
    "Saving files to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ac92925",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vectors).to_csv(\"temp/vectors.csv\", index=False, header=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a4f5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"temp/metadata.csv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f811ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import base64\n",
    "def create_download_link( df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    csv = df\n",
    "    if type(df) != str:\n",
    "        csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b649bf",
   "metadata": {},
   "source": [
    "## For Longform Passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40367077",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install torch==1.2.0 torchvision==0.4.0 #had to find this specification in the archives ... CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "443ffd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e2e857fda643d18d5cbbdc58d28778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606c6a500e0d4f2e96d1347a3df23cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5368f4d15c444205abdf99db8eea8c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe05f93c1c8478289f8da93faee43e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25da682ae47549b889650bd48a7ff186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "df = pd.read_csv(\"datasets/problem_statements.csv\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\") #longformer because it's a paragraph ... use sentence transformers for shorter texts\n",
    "model = AutoModel.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "#embeddings = df[\"text\"].map(lambda t: model(**tokenizer(t, return_tensors=\"pt\")))\n",
    "# text = \"Spaces is an S3-compatible object storage service that lets you store and serve large amounts of data. Each Space is a bucket for you to store and serve files. The free, built-in Spaces CDN minimizes page load times, improves performance, and reduces bandwidth and infrastructure costs.\"\n",
    "# encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# output = model(**encoded_input)\n",
    "#encoded_input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "907306b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = df#[[\"name\", \"title\", \"url\", \"visit_time\"]]\n",
    "metadata.to_csv(\"metadata.tsv\", index=False, sep=\"\\t\")\n",
    "\n",
    "vectors = [model(**tokenizer(document[:4096], return_tensors='pt'))[1].squeeze(0).detach() for document in df[\"text\"].values]\n",
    "\n",
    "vectors_np = [v.numpy() for v in vectors]\n",
    "len(vectors_np)\n",
    "vectors_np[0]\n",
    "pd.DataFrame(vectors_np).to_csv(\"vectors.tsv\", index=False, header=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
