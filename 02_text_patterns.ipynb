{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c947b34",
   "metadata": {},
   "source": [
    "# Finding (Problem Statement) Signal in Sentence Phrasing\n",
    "\n",
    "Here we look at intersecting (low signal) and exclusive (only in one class aka high signal) [n-grams](https://en.wikipedia.org/wiki/N-gram) of positive and negative labeled sentences.\n",
    "\n",
    "If there are n-grams that *almost* exclusively appear in one class (0 or 1) then they could make great matching phrases either directly for classifying a sentence without using a machine learning model or just to do last-mile quality assurance and flag suspicious model decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1779b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271fc451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/problem_statements.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61394a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_while(fn, coll):\n",
    "    \"\"\"Yield values from coll until fn is False\"\"\"\n",
    "    for e in coll:\n",
    "        if fn(e):\n",
    "            yield e\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def partition(n, coll, step=None):\n",
    "    return take_while(lambda e: len(e) == n,\n",
    "        (coll[i:i+n] for i in range(0, len(coll), step or n)))\n",
    "\n",
    "def partition_all(n, coll, step=None):\n",
    "    return (coll[i:i+n] for i in range(0, len(coll), step or n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d88560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=[\"Unnamed: 0\", \"index\", \"Unnamed: 0.1\", \"Unnamed: 9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6efe87",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-2f9c2f8c8548>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-2f9c2f8c8548>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \"The difficulty with this task lies in the fact...\".map(\"\"[\"lower\"]\u001b[0m\n\u001b[0m                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 4\n"
     ]
    }
   ],
   "source": [
    "\"The difficulty with this task lies in the fact...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "feaa5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = df[df[\"labels\"] == 1]\n",
    "negatives = df[df[\"labels\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "25f96b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>source</th>\n",
       "      <th>Title</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The difficulty with this task lies in the fact...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The problem with rich annotations is that they...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a consequence , when adapting existing meth...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PMID         source Title                                               text  labels  DOI\n",
       "0   NaN  acl_cambridge   NaN  The difficulty with this task lies in the fact...       1  NaN\n",
       "1   NaN  acl_cambridge   NaN  The problem with rich annotations is that they...       1  NaN\n",
       "2   NaN  acl_cambridge   NaN  As a consequence , when adapting existing meth...       1  NaN"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "aa74c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(texts, n_gram=2): return [\" \".join(n) for t in texts for n in partition(n_gram, t.split(\" \"), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "49e34a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grams_pos = n_grams(positives[\"text\"], 2)\n",
    "tri_grams_pos = n_grams(positives[\"text\"], 3)\n",
    "bi_grams_neg = n_grams(negatives[\"text\"], 2)\n",
    "tri_grams_neg = n_grams(negatives[\"text\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c2ed4a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The difficulty', 'difficulty with', 'with this']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_grams_pos[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ef8aa42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = dict(Counter(bi_grams_pos))\n",
    "d2 = dict(Counter(bi_grams_neg))\n",
    "\n",
    "d3 = dict(Counter(tri_grams_pos))\n",
    "d4 = dict(Counter(tri_grams_neg))\n",
    "\n",
    "bi_grams_both = {x:(d1[x], d2[x]) for x in d1 if x in d2}\n",
    "\n",
    "tri_grams_both = {x:(d3[x], d4[x]) for x in d3 if d4.get(x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "816215fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grams_pos_only = {x:d1[x] for x in d1 if not d2.get(x)} # and d2.get(x) < 5\n",
    "tri_grams_pos_only = {x:d3[x] for x in d3 if not d4.get(x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a7321fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the fact that', (12, 21)),\n",
       " ('et al. ,', (9, 66)),\n",
       " ('that they are', (12, 12)),\n",
       " ('one of the', (23, 29)),\n",
       " ('is that the', (65, 6)),\n",
       " ('the quality of', (7, 15)),\n",
       " ('is that it', (50, 3)),\n",
       " ('that it is', (11, 18)),\n",
       " ('in the training', (6, 18)),\n",
       " ('the training data', (7, 33)),\n",
       " ('it does not', (10, 24)),\n",
       " ('to the same', (4, 18)),\n",
       " ('in terms of', (6, 18)),\n",
       " ('the use of', (5, 22)),\n",
       " ('as well as', (5, 21)),\n",
       " ('the most common', (18, 11)),\n",
       " ('can be used', (3, 27)),\n",
       " ('the number of', (9, 38)),\n",
       " ('the treatment of', (2, 19)),\n",
       " ('a set of', (1, 21)),\n",
       " ('is one of', (14, 11)),\n",
       " ('of the most', (17, 8)),\n",
       " ('is a common', (19, 9)),\n",
       " ('in patients with', (2, 22))]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in Counter(tri_grams_both).items() if (v[0] + v[1]) > 20 ]\n",
    "#n-gram: (pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f22a571d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in the', (80, 311)),\n",
       " (', and', (22, 165)),\n",
       " ('is that', (272, 9)),\n",
       " ('of the', (154, 515)),\n",
       " ('is the', (74, 51)),\n",
       " (', the', (38, 108)),\n",
       " ('is not', (21, 89)),\n",
       " (', which', (21, 84)),\n",
       " ('can be', (18, 96)),\n",
       " ('number of', (18, 105)),\n",
       " ('that the', (82, 75)),\n",
       " ('does not', (26, 78)),\n",
       " ('to be', (28, 120)),\n",
       " ('to the', (48, 229)),\n",
       " ('it is', (24, 86)),\n",
       " ('on the', (23, 137)),\n",
       " ('is a', (88, 151)),\n",
       " ('of a', (14, 103)),\n",
       " ('the same', (19, 89)),\n",
       " ('for the', (19, 93)),\n",
       " (', we', (6, 120)),\n",
       " ('as a', (14, 90)),\n",
       " ('has been', (13, 93))]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in Counter(bi_grams_both).items() if (v[0] + v[1]) > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7b6d5",
   "metadata": {},
   "source": [
    "Let's look at patterns that one class shows very rarely relative to the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "71ef7366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('is that', (272, 9)), ('problem of', (54, 1)), ('shortcoming of', (24, 1))],\n",
       " [('is that the', (65, 6)), ('is that it', (50, 3))])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor = 20\n",
    "#show n-grams that appear at least 20x more often in positive samples\n",
    "[(k,v) for k,v in Counter(bi_grams_both).items() if (v[0]/v[1]) > factor], [(k,v) for k,v in Counter(tri_grams_both).items() if (v[0]/v[1]) > factor/2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242745c8",
   "metadata": {},
   "source": [
    "Apparently \"problem of\" appears 54 in \"problem statements\" and only once in \"non-problem\" statement. Let's look at that one sentence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "dc7269b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'peripheral neuropathy is the most common problem of diabetes.'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives[negatives[\"text\"].str.contains('problem of')].reset_index()[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e64be",
   "metadata": {},
   "source": [
    "Interesting ... through the bi-gram analysis we found a statement that actually sounds like a problem statement and should/could be labeled a 1 (problem statement) ... but isn't in the dataset.\n",
    "In that case I'd feel OK with using \"problem of\" as a hard-coded pattern-matching rule in finding positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d69534fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the problem', 45),\n",
       " ('drawback of', 57),\n",
       " ('limitation is', 41),\n",
       " ('limitation of', 46),\n",
       " ('drawback is', 66)]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in Counter(bi_grams_pos_only).items() if v > 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d1961d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is that they', 31),\n",
       " ('the problem of', 41),\n",
       " ('limitation is that', 32),\n",
       " ('drawback is that', 56),\n",
       " ('approach is that', 16),\n",
       " ('limitation of the', 17)]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in Counter(tri_grams_pos_only).items() if v > 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37281e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k,v) for k,v in Counter(bi_grams_both).items() if (v[0] + v[1]) > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c02c8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[df[\"text\"].str.contains(\"drawback is that\")].reset_index()[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "499873fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Its most obvious drawback is that the method c...\n",
       "1     The most significant drawback is that ontologi...\n",
       "2     The main drawback is that it needs almost 20,0...\n",
       "3     One drawback is that it cannot deal with depen...\n",
       "4     A potential drawback is that it might not work...\n",
       "5     The drawback is that , since extracted events ...\n",
       "6     The main drawback is that the entries produced...\n",
       "7     An obvious drawback is that it is necessary to...\n",
       "8     The only drawback is that it willperform slowe...\n",
       "9     The drawback is that the estimates of paramete...\n",
       "10    One possible drawback is that senses which one...\n",
       "11    Their major drawback is that they require a gr...\n",
       "12    The first drawback is that it requires more kn...\n",
       "13    Another drawback is that it is impossible to a...\n",
       "14    The drawback is that the solution may be only ...\n",
       "15    The main drawback is that structures may not b...\n",
       "16    Another major drawback is that it requires con...\n",
       "17    The major drawback is that we have to generate...\n",
       "18    The drawback is that this context may not be s...\n",
       "19               The drawback is that this is expensive\n",
       "20    Their main drawback is that they may or may no...\n",
       "21    Another drawback is that the different sentenc...\n",
       "22    The drawback is that the solution may be only ...\n",
       "23    However , an important drawback is that the ta...\n",
       "24    A drawback is that their method limits the tra...\n",
       "25    A drawback is that these features give no info...\n",
       "26    A possible drawback is that for some inputs , ...\n",
       "27    A drawback is that this structure may be cubic...\n",
       "28    The benefit of this approach is that the distr...\n",
       "29    The main drawback is that training time is inc...\n",
       "30    However , the drawback is that an adaption to ...\n",
       "31    The primary drawback is that KB annotations ar...\n",
       "32    The drawback is that there is a margin of erro...\n",
       "33    One drawback is that the parsing process might...\n",
       "34    An additional drawback is that all existing sy...\n",
       "35    A drawback is that the corpus is not publicly ...\n",
       "36    A drawback is that a grammar may need a large ...\n",
       "37    The second drawback is that the criterion for ...\n",
       "38    However , an obvious drawback is that the actu...\n",
       "39    The drawback is that the complexity in syntact...\n",
       "40    The second drawback is that 38 % of the slots ...\n",
       "41    The drawback is that the identification of men...\n",
       "42    Its main drawback is that important structural...\n",
       "43    The drawback is that we only cover about half ...\n",
       "44    The first drawback is that Ravichandran and Ho...\n",
       "45    It has many positive features , but one drawba...\n",
       "46    One potential drawback is that it requires hig...\n",
       "47    A fundamental drawback is that phrases are tra...\n",
       "48    A drawback is that theoretical approaches beco...\n",
       "49    A drawback is that the time complexity of infe...\n",
       "50    The drawback is that it causes sensitivity to ...\n",
       "51    One drawback is that LMF provides only a speci...\n",
       "52    A potential drawback is that we get fewer data...\n",
       "53    Their drawback is that , as most generative mo...\n",
       "54    The drawback is that the presence of semantic ...\n",
       "55    Their main drawback is that they are tied to t...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf006e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
