{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71174fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c9c63dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/problem_statements.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae46669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_while(fn, coll):\n",
    "    \"\"\"Yield values from coll until fn is False\"\"\"\n",
    "    for e in coll:\n",
    "        if fn(e):\n",
    "            yield e\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def partition(n, coll, step=None):\n",
    "    return take_while(lambda e: len(e) == n,\n",
    "        (coll[i:i+n] for i in range(0, len(coll), step or n)))\n",
    "\n",
    "def partition_all(n, coll, step=None):\n",
    "    return (coll[i:i+n] for i in range(0, len(coll), step or n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f40a6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=[\"Unnamed: 0\", \"index\", \"Unnamed: 0.1\", \"Unnamed: 9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fa77bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = df[df[\"labels\"] == 1]\n",
    "negatives = df[df[\"labels\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1af786c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(texts, n_gram=2): return [\" \".join(n) for t in texts for n in partition(n_gram, t.split(\" \"), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "346255c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grams_pos = n_grams(positives[\"text\"], 2)\n",
    "tri_grams_pos = n_grams(positives[\"text\"], 3)\n",
    "bi_grams_neg = n_grams(positives[\"text\"], 2)\n",
    "tri_grams_neg = n_grams(positives[\"text\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d98311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fffd3ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = dict(Counter(bi_grams_pos))\n",
    "d2 = dict(Counter(bi_grams_neg))\n",
    "\n",
    "bi_grams_both = {x:d1[x] for x in d1 if x in d2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d6d272f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in the', 80),\n",
       " ('is that', 272),\n",
       " ('that they', 34),\n",
       " ('of the', 154),\n",
       " ('the problem', 45),\n",
       " ('problem of', 54),\n",
       " ('is the', 74),\n",
       " ('The main', 32),\n",
       " ('drawback of', 57),\n",
       " ('limitation is', 41),\n",
       " (', the', 38),\n",
       " ('limitation of', 46),\n",
       " ('of this', 35),\n",
       " ('that the', 82),\n",
       " ('to the', 48),\n",
       " ('that it', 57),\n",
       " ('drawback is', 66),\n",
       " ('is a', 88),\n",
       " ('the most', 39)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in Counter(bi_grams_both).items() if v > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40eb155e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('k', 5)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={\"k\": 5}\n",
    "[(k, v) for k,v in d.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "783766ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The difficulty with': 2,\n",
       " 'difficulty with this': 2,\n",
       " 'with this task': 1,\n",
       " 'this task lies': 1,\n",
       " 'task lies in': 1,\n",
       " 'lies in the': 6,\n",
       " 'in the fact': 3,\n",
       " 'the fact that': 12,\n",
       " 'fact that prosodic': 1,\n",
       " 'that prosodic cues': 1,\n",
       " 'prosodic cues are': 1,\n",
       " 'cues are never': 1,\n",
       " 'are never absolute': 1,\n",
       " 'never absolute ;': 1,\n",
       " 'absolute ; they': 1,\n",
       " '; they are': 1,\n",
       " 'they are relative': 1,\n",
       " 'are relative to': 1,\n",
       " 'relative to individual': 1,\n",
       " 'to individual speakers': 1,\n",
       " 'individual speakers ,': 1,\n",
       " 'speakers , gender': 1,\n",
       " ', gender ,': 1,\n",
       " 'gender , dialect': 1,\n",
       " ', dialect ,': 1,\n",
       " 'dialect , discourse': 1,\n",
       " ', discourse context': 1,\n",
       " 'discourse context ,': 1,\n",
       " 'context , local': 1,\n",
       " ', local context': 1,\n",
       " 'local context ,': 1,\n",
       " 'context , phonological': 1,\n",
       " ', phonological environment': 1,\n",
       " 'phonological environment ,': 1,\n",
       " 'environment , and': 1,\n",
       " ', and many': 1,\n",
       " 'and many other': 1,\n",
       " 'many other factors': 1,\n",
       " 'The problem with': 5,\n",
       " 'problem with rich': 1,\n",
       " 'with rich annotations': 1,\n",
       " 'rich annotations is': 1,\n",
       " 'annotations is that': 1,\n",
       " 'is that they': 31,\n",
       " 'that they increase': 1,\n",
       " 'they increase the': 1,\n",
       " 'increase the state': 1,\n",
       " 'the state space': 1,\n",
       " 'state space of': 1,\n",
       " 'space of the': 1,\n",
       " 'of the grammar': 1,\n",
       " 'the grammar substantially': 1,\n",
       " 'As a consequence': 1,\n",
       " 'a consequence ,': 1,\n",
       " 'consequence , when': 1,\n",
       " ', when adapting': 1,\n",
       " 'when adapting existing': 1,\n",
       " 'adapting existing methods': 1,\n",
       " 'existing methods and': 1,\n",
       " 'methods and techniques': 1,\n",
       " 'and techniques to': 1,\n",
       " 'techniques to a': 1,\n",
       " 'to a new': 2,\n",
       " 'a new domain': 2,\n",
       " 'new domain ,': 1,\n",
       " 'domain , researchers': 1,\n",
       " ', researchers and': 1,\n",
       " 'researchers and users': 1,\n",
       " 'and users are': 1,\n",
       " 'users are faced': 1,\n",
       " 'are faced with': 1,\n",
       " 'faced with the': 2,\n",
       " 'with the problem': 2,\n",
       " 'the problem of': 41,\n",
       " 'problem of absence': 1,\n",
       " 'of absence of': 1,\n",
       " 'absence of annotated': 1,\n",
       " 'of annotated material': 1,\n",
       " 'annotated material that': 1,\n",
       " 'material that could': 1,\n",
       " 'that could be': 1,\n",
       " 'could be used': 1,\n",
       " 'be used for': 2,\n",
       " 'used for training': 1,\n",
       " 'The second problem': 2,\n",
       " 'second problem of': 2,\n",
       " 'problem of traditional': 1,\n",
       " 'of traditional word': 1,\n",
       " 'traditional word alignment': 1,\n",
       " 'word alignment approaches': 1,\n",
       " 'alignment approaches is': 1,\n",
       " 'approaches is the': 4,\n",
       " 'is the fact': 6,\n",
       " 'fact that parameter': 1,\n",
       " 'that parameter estimations': 1,\n",
       " 'parameter estimations are': 1,\n",
       " 'estimations are usually': 1,\n",
       " 'are usually based': 1,\n",
       " 'usually based on': 1,\n",
       " 'based on plain': 1,\n",
       " 'on plain text': 1,\n",
       " 'plain text items': 1,\n",
       " 'text items only': 1,\n",
       " 'The main drawback': 12,\n",
       " 'main drawback of': 4,\n",
       " 'drawback of these': 4,\n",
       " 'of these systems': 1,\n",
       " 'these systems is': 1,\n",
       " 'systems is that': 3,\n",
       " 'that they fail': 1,\n",
       " 'they fail to': 1,\n",
       " 'fail to recognize': 1,\n",
       " 'to recognize terms': 1,\n",
       " 'recognize terms which': 1,\n",
       " 'terms which are': 1,\n",
       " 'which are not': 1,\n",
       " 'are not included': 1,\n",
       " 'not included in': 1,\n",
       " 'included in the': 2,\n",
       " 'in the dictionary': 1,\n",
       " 'Although these approaches': 1,\n",
       " 'these approaches do': 1,\n",
       " 'approaches do not': 1,\n",
       " 'do not suffer': 1,\n",
       " 'not suffer from': 1,\n",
       " 'suffer from so-called': 1,\n",
       " 'from so-called label-bias': 1,\n",
       " 'so-called label-bias problems': 1,\n",
       " 'label-bias problems (': 1,\n",
       " 'problems ( Lafferty': 1,\n",
       " '( Lafferty et': 1,\n",
       " 'Lafferty et al.': 1,\n",
       " 'et al. ,': 9,\n",
       " 'al. , 2001': 1,\n",
       " ', 2001 )': 3,\n",
       " '2001 ) ,': 2,\n",
       " ') , one': 1,\n",
       " ', one limitation': 1,\n",
       " 'one limitation is': 1,\n",
       " 'limitation is that': 32,\n",
       " 'that they are': 12,\n",
       " 'they are inefficient': 1,\n",
       " 'are inefficient to': 1,\n",
       " 'inefficient to train': 1,\n",
       " 'to train with': 1,\n",
       " 'train with large-scale': 1,\n",
       " 'with large-scale ,': 1,\n",
       " 'large-scale , especially': 1,\n",
       " ', especially large': 1,\n",
       " 'especially large category': 1,\n",
       " 'large category data': 1,\n",
       " 'To overcome the': 1,\n",
       " 'overcome the disadvantage': 1,\n",
       " 'the disadvantage of': 3,\n",
       " 'disadvantage of measure': 1,\n",
       " 'of measure word': 1,\n",
       " 'measure word generation': 1,\n",
       " 'word generation in': 1,\n",
       " 'generation in a': 1,\n",
       " 'in a general': 1,\n",
       " 'a general SMT': 1,\n",
       " 'general SMT system': 1,\n",
       " 'However , the': 11,\n",
       " ', the problem': 8,\n",
       " 'the problem is': 4,\n",
       " 'problem is not': 1,\n",
       " 'is not totally': 1,\n",
       " 'not totally solved': 1,\n",
       " 'totally solved because': 1,\n",
       " 'solved because many': 1,\n",
       " 'because many verb': 1,\n",
       " 'many verb reorderings': 1,\n",
       " 'verb reorderings are': 1,\n",
       " 'reorderings are still': 1,\n",
       " 'are still missed': 1,\n",
       " 'Furthermore , most': 1,\n",
       " ', most pattern-based': 1,\n",
       " 'most pattern-based methods': 1,\n",
       " 'pattern-based methods rely': 1,\n",
       " 'methods rely on': 1,\n",
       " 'rely on term': 1,\n",
       " 'on term frequency': 1,\n",
       " 'term frequency ,': 1,\n",
       " 'frequency , which': 1,\n",
       " ', which have': 2,\n",
       " 'which have the': 1,\n",
       " 'have the limitation': 1,\n",
       " 'the limitation of': 5,\n",
       " 'limitation of finding': 1,\n",
       " 'of finding infrequent': 1,\n",
       " 'finding infrequent but': 1,\n",
       " 'infrequent but important': 1,\n",
       " 'but important product': 1,\n",
       " 'important product features': 1,\n",
       " 'This solution can': 1,\n",
       " 'solution can avoid': 1,\n",
       " 'can avoid the': 1,\n",
       " 'avoid the problem': 3,\n",
       " 'problem of the': 6,\n",
       " 'of the expansion': 1,\n",
       " 'the expansion of': 1,\n",
       " 'expansion of CFG': 1,\n",
       " 'of CFG rules': 1,\n",
       " 'The main weakness': 1,\n",
       " 'main weakness of': 1,\n",
       " 'weakness of this': 5,\n",
       " 'of this method': 6,\n",
       " 'this method is': 6,\n",
       " 'method is that': 6,\n",
       " 'is that an': 3,\n",
       " 'that an SF': 1,\n",
       " 'an SF error': 1,\n",
       " 'SF error can': 1,\n",
       " 'error can be': 1,\n",
       " 'can be corrected': 1,\n",
       " 'be corrected only': 1,\n",
       " 'corrected only if': 1,\n",
       " 'only if the': 1,\n",
       " 'if the right': 1,\n",
       " 'the right SF': 1,\n",
       " 'right SF appears': 1,\n",
       " 'SF appears at': 1,\n",
       " 'appears at least': 1,\n",
       " 'at least in': 1,\n",
       " 'least in one': 1,\n",
       " 'in one of': 1,\n",
       " 'one of the': 23,\n",
       " 'of the n-best': 1,\n",
       " 'the n-best parse': 1,\n",
       " 'n-best parse trees': 1,\n",
       " 'The only shortcoming': 1,\n",
       " 'only shortcoming is': 1,\n",
       " 'shortcoming is the': 4,\n",
       " 'is the cost': 1,\n",
       " 'the cost of': 1,\n",
       " 'cost of annotation': 1,\n",
       " 'This fact in': 1,\n",
       " 'fact in turn': 1,\n",
       " 'in turn caused': 1,\n",
       " 'turn caused the': 1,\n",
       " 'caused the problem': 1,\n",
       " 'problem of underrepresentation': 1,\n",
       " 'of underrepresentation of': 1,\n",
       " 'underrepresentation of Kazakh': 1,\n",
       " 'of Kazakh language': 1,\n",
       " 'Kazakh language in': 1,\n",
       " 'language in various': 1,\n",
       " 'in various fields': 1,\n",
       " 'various fields such': 1,\n",
       " 'fields such as': 1,\n",
       " 'such as science': 1,\n",
       " 'as science ,': 1,\n",
       " 'science , entertainment': 1,\n",
       " ', entertainment ,': 1,\n",
       " 'entertainment , official': 1,\n",
       " ', official documentation': 1,\n",
       " 'official documentation ,': 1,\n",
       " 'documentation , etc': 1,\n",
       " ', etc .': 1,\n",
       " 'Perhaps the biggest': 1,\n",
       " 'the biggest limitation': 1,\n",
       " 'biggest limitation is': 1,\n",
       " 'limitation is the': 7,\n",
       " 'is the small': 1,\n",
       " 'the small number': 1,\n",
       " 'small number of': 3,\n",
       " 'number of research': 1,\n",
       " 'of research participants': 1,\n",
       " 'To cope with': 1,\n",
       " 'cope with the': 1,\n",
       " 'problem of sparse': 1,\n",
       " 'of sparse training': 1,\n",
       " 'sparse training resources': 1,\n",
       " 'One probable disadvantage': 1,\n",
       " 'probable disadvantage is': 1,\n",
       " 'disadvantage is that': 10,\n",
       " 'is that the': 65,\n",
       " 'that the scheme': 1,\n",
       " 'the scheme will': 1,\n",
       " 'scheme will be': 1,\n",
       " 'will be less': 1,\n",
       " 'be less general': 1,\n",
       " 'The latter approach': 1,\n",
       " 'latter approach has': 1,\n",
       " 'approach has the': 2,\n",
       " 'has the potential': 2,\n",
       " 'the potential weakness': 1,\n",
       " 'potential weakness of': 1,\n",
       " 'weakness of unsupervised': 1,\n",
       " 'of unsupervised training': 1,\n",
       " 'unsupervised training erasing': 1,\n",
       " 'training erasing what': 1,\n",
       " 'erasing what was': 1,\n",
       " 'what was learned': 1,\n",
       " 'was learned from': 1,\n",
       " 'learned from the': 1,\n",
       " 'from the manually': 1,\n",
       " 'the manually annotated': 1,\n",
       " 'manually annotated corpus': 2,\n",
       " 'A notorious problem': 1,\n",
       " 'notorious problem with': 1,\n",
       " 'problem with computational': 1,\n",
       " 'with computational linguistics': 1,\n",
       " 'computational linguistics is': 1,\n",
       " 'linguistics is that': 1,\n",
       " 'is that there': 9,\n",
       " 'that there is': 5,\n",
       " 'there is no': 4,\n",
       " 'is no path': 1,\n",
       " 'no path into': 1,\n",
       " 'path into it': 1,\n",
       " 'A serious problem': 1,\n",
       " 'serious problem in': 1,\n",
       " 'problem in manual': 1,\n",
       " 'in manual nugget': 1,\n",
       " 'manual nugget creation': 1,\n",
       " 'nugget creation is': 1,\n",
       " 'creation is the': 1,\n",
       " 'is the inconsistency': 1,\n",
       " 'the inconsistency in': 1,\n",
       " 'inconsistency in human': 1,\n",
       " 'in human decisions': 1,\n",
       " 'human decisions (': 1,\n",
       " 'decisions ( Lin': 1,\n",
       " '( Lin and': 1,\n",
       " 'Lin and Hovy': 1,\n",
       " 'and Hovy ,': 1,\n",
       " 'Hovy , 2003': 1,\n",
       " ', 2003 )': 3,\n",
       " 'We also address': 1,\n",
       " 'also address the': 1,\n",
       " 'address the issue': 3,\n",
       " 'the issue of': 10,\n",
       " 'issue of sparse': 1,\n",
       " 'of sparse or': 1,\n",
       " 'sparse or impoverished': 1,\n",
       " 'or impoverished training': 1,\n",
       " 'impoverished training data': 1,\n",
       " 'The limitation is': 2,\n",
       " 'is that word': 1,\n",
       " 'that word vectors': 1,\n",
       " 'word vectors developed': 1,\n",
       " 'vectors developed from': 1,\n",
       " 'developed from distributional': 1,\n",
       " 'from distributional models': 1,\n",
       " 'distributional models cannot': 1,\n",
       " 'models cannot reveal': 1,\n",
       " 'cannot reveal word': 1,\n",
       " 'reveal word relatedness': 1,\n",
       " 'word relatedness if': 1,\n",
       " 'relatedness if its': 1,\n",
       " 'if its information': 1,\n",
       " 'its information does': 1,\n",
       " 'information does not': 1,\n",
       " 'does not lie': 1,\n",
       " 'not lie in': 1,\n",
       " 'lie in word': 1,\n",
       " 'in word distributions': 1,\n",
       " 'While these algorithms': 1,\n",
       " 'these algorithms usually': 1,\n",
       " 'algorithms usually achieve': 1,\n",
       " 'usually achieve the': 1,\n",
       " 'achieve the best': 1,\n",
       " 'the best performance': 1,\n",
       " 'best performance ,': 1,\n",
       " 'performance , as': 1,\n",
       " ', as compared': 1,\n",
       " 'as compared to': 1,\n",
       " 'compared to their': 1,\n",
       " 'to their unsupervised': 1,\n",
       " 'their unsupervised or': 1,\n",
       " 'unsupervised or knowledge-based': 1,\n",
       " 'or knowledge-based alternatives': 1,\n",
       " 'knowledge-based alternatives ,': 1,\n",
       " 'alternatives , there': 1,\n",
       " ', there is': 1,\n",
       " 'there is an': 1,\n",
       " 'is an important': 5,\n",
       " 'an important shortcoming': 1,\n",
       " 'important shortcoming associated': 1,\n",
       " 'shortcoming associated with': 1,\n",
       " 'associated with these': 1,\n",
       " 'with these methods': 1,\n",
       " 'these methods :': 1,\n",
       " 'methods : their': 1,\n",
       " ': their applicability': 1,\n",
       " 'their applicability is': 1,\n",
       " 'applicability is limited': 1,\n",
       " 'is limited only': 1,\n",
       " 'limited only to': 1,\n",
       " 'only to those': 1,\n",
       " 'to those words': 1,\n",
       " 'those words for': 1,\n",
       " 'words for which': 1,\n",
       " 'for which sense': 1,\n",
       " 'which sense tagged': 1,\n",
       " 'sense tagged data': 1,\n",
       " 'tagged data is': 1,\n",
       " 'data is available': 1,\n",
       " 'One drawback of': 6,\n",
       " 'drawback of this': 7,\n",
       " 'of this work': 2,\n",
       " 'this work is': 2,\n",
       " 'work is that': 2,\n",
       " 'is that depth-boundedness': 1,\n",
       " 'that depth-boundedness is': 1,\n",
       " 'depth-boundedness is undecidable': 1,\n",
       " 'This problem arises': 1,\n",
       " 'problem arises due': 1,\n",
       " 'arises due to': 1,\n",
       " 'due to limited': 2,\n",
       " 'to limited vowel': 1,\n",
       " 'limited vowel presentation': 1,\n",
       " 'vowel presentation in': 1,\n",
       " 'presentation in this': 1,\n",
       " 'in this writing': 1,\n",
       " 'this writing system': 1,\n",
       " 'What the author': 1,\n",
       " 'the author and': 1,\n",
       " 'author and her': 1,\n",
       " 'and her colleagues': 1,\n",
       " 'her colleagues have': 1,\n",
       " 'colleagues have done': 1,\n",
       " 'have done to': 1,\n",
       " 'done to avoid': 1,\n",
       " 'to avoid the': 1,\n",
       " 'problem of analyzer': 1,\n",
       " 'of analyzer bias': 1,\n",
       " 'So the loss': 1,\n",
       " 'the loss and': 1,\n",
       " 'loss and distortion': 1,\n",
       " 'and distortion of': 1,\n",
       " 'distortion of semantic': 1,\n",
       " 'of semantic information': 2,\n",
       " 'The problem of': 2,\n",
       " 'problem of data': 3,\n",
       " 'of data sparseness': 3,\n",
       " 'data sparseness for': 1,\n",
       " 'sparseness for PCFG': 1,\n",
       " 'A common problem': 1,\n",
       " 'common problem for': 1,\n",
       " 'problem for unsupervised': 1,\n",
       " 'for unsupervised models': 1,\n",
       " 'unsupervised models trained': 1,\n",
       " 'models trained on': 1,\n",
       " 'trained on verb-object': 1,\n",
       " 'on verb-object tuples': 1,\n",
       " 'verb-object tuples is': 1,\n",
       " 'tuples is that': 1,\n",
       " 'that the objects': 1,\n",
       " 'the objects can': 1,\n",
       " 'objects can belong': 1,\n",
       " 'can belong to': 1,\n",
       " 'belong to more': 1,\n",
       " 'to more than': 1,\n",
       " 'more than one': 1,\n",
       " 'than one semantic': 1,\n",
       " 'one semantic class': 1,\n",
       " 'Although there exist': 1,\n",
       " 'there exist abundant': 1,\n",
       " 'exist abundant collections': 1,\n",
       " 'abundant collections of': 1,\n",
       " 'collections of raw': 1,\n",
       " 'of raw text': 1,\n",
       " 'raw text ,': 1,\n",
       " 'text , the': 1,\n",
       " ', the high': 1,\n",
       " 'the high expense': 1,\n",
       " 'high expense of': 1,\n",
       " 'expense of manually': 1,\n",
       " 'of manually annotating': 1,\n",
       " 'manually annotating the': 1,\n",
       " 'annotating the text': 1,\n",
       " 'The main problem': 5,\n",
       " 'main problem of': 3,\n",
       " 'problem of non-lexicalized': 1,\n",
       " 'of non-lexicalized context-free': 1,\n",
       " 'non-lexicalized context-free grammars': 1,\n",
       " 'context-free grammars is': 1,\n",
       " 'grammars is that': 2,\n",
       " 'is that nonterminal': 1,\n",
       " 'that nonterminal symbols': 1,\n",
       " 'nonterminal symbols encode': 1,\n",
       " 'symbols encode too': 1,\n",
       " 'encode too general': 1,\n",
       " 'too general information': 1,\n",
       " 'general information which': 1,\n",
       " 'information which weakly': 1,\n",
       " 'which weakly discriminates': 1,\n",
       " 'weakly discriminates syntactic': 1,\n",
       " 'discriminates syntactic ambiguities': 1,\n",
       " 'HCDAE outperforms single': 1,\n",
       " 'outperforms single DAE': 1,\n",
       " 'single DAE for': 1,\n",
       " 'DAE for high': 1,\n",
       " 'for high dimensional': 1,\n",
       " 'high dimensional feature': 1,\n",
       " 'dimensional feature learning': 1,\n",
       " 'feature learning (': 1,\n",
       " 'learning ( row': 1,\n",
       " '( row 6': 1,\n",
       " 'row 6 vs.': 1,\n",
       " '6 vs. 5': 1,\n",
       " 'vs. 5 ;': 1,\n",
       " '5 ; row': 1,\n",
       " '; row 9': 1,\n",
       " 'row 9 vs.': 1,\n",
       " '9 vs. 8': 1,\n",
       " 'vs. 8 ;': 1,\n",
       " '8 ; row': 1,\n",
       " '; row 14': 1,\n",
       " 'row 14 vs.': 1,\n",
       " '14 vs. 13': 1,\n",
       " 'vs. 13 ;': 1,\n",
       " '13 ; row': 1,\n",
       " '; row 17': 1,\n",
       " 'row 17 vs.': 1,\n",
       " '17 vs. 16': 1,\n",
       " 'vs. 16 )': 1,\n",
       " '16 ) ,': 1,\n",
       " ') , and': 3,\n",
       " ', and further': 1,\n",
       " 'and further improve': 1,\n",
       " 'further improve the': 1,\n",
       " 'improve the performance': 1,\n",
       " 'the performance of': 3,\n",
       " 'performance of DAE': 1,\n",
       " 'of DAE feature': 1,\n",
       " 'DAE feature learning': 1,\n",
       " 'feature learning ,': 1,\n",
       " 'learning , which': 1,\n",
       " ', which can': 3,\n",
       " 'which can also': 1,\n",
       " 'can also somewhat': 1,\n",
       " 'also somewhat address': 1,\n",
       " 'somewhat address the': 1,\n",
       " 'address the bring': 1,\n",
       " 'the bring shortcoming': 1,\n",
       " 'bring shortcoming of': 1,\n",
       " 'shortcoming of the': 3,\n",
       " 'of the limited': 1,\n",
       " 'the limited input': 1,\n",
       " 'limited input features': 1,\n",
       " 'While this study': 2,\n",
       " 'this study introduces': 2,\n",
       " 'study introduces statistical': 2,\n",
       " 'introduces statistical measures': 2,\n",
       " 'statistical measures to': 2,\n",
       " 'measures to evaluate': 2,\n",
       " 'to evaluate instance': 2,\n",
       " 'evaluate instance reliability': 1,\n",
       " 'instance reliability ,': 1,\n",
       " 'reliability , it': 1,\n",
       " ', it remains': 2,\n",
       " 'it remains vulnerable': 2,\n",
       " 'remains vulnerable to': 2,\n",
       " 'vulnerable to data': 2,\n",
       " 'to data sparseness': 3,\n",
       " 'data sparseness and': 2,\n",
       " 'sparseness and has': 2,\n",
       " 'and has the': 2,\n",
       " 'has the limitation': 2,\n",
       " 'limitation of taking': 1,\n",
       " 'of taking into': 1,\n",
       " 'taking into consideration': 1,\n",
       " 'into consideration only': 1,\n",
       " 'consideration only one-word': 1,\n",
       " 'only one-word terms': 2,\n",
       " 'Our heuristics currently': 1,\n",
       " 'heuristics currently allow': 1,\n",
       " 'currently allow some': 1,\n",
       " 'allow some such': 1,\n",
       " 'some such exceptions': 1,\n",
       " 'such exceptions to': 1,\n",
       " 'exceptions to be': 1,\n",
       " 'to be found': 1,\n",
       " 'be found ,': 1,\n",
       " 'found , although': 1,\n",
       " ', although they': 1,\n",
       " 'although they are': 1,\n",
       " 'they are by': 1,\n",
       " 'are by no': 1,\n",
       " 'by no means': 1,\n",
       " 'no means a': 1,\n",
       " 'means a complete': 1,\n",
       " 'a complete solution': 1,\n",
       " 'complete solution to': 1,\n",
       " 'solution to the': 3,\n",
       " 'to the problem': 5,\n",
       " 'problem of exceptions': 1,\n",
       " 'The challenge of': 1,\n",
       " 'challenge of this': 1,\n",
       " 'of this task': 1,\n",
       " 'this task is': 2,\n",
       " 'task is the': 2,\n",
       " 'is the much': 1,\n",
       " 'the much skewed': 1,\n",
       " 'much skewed distribution': 1,\n",
       " 'skewed distribution in': 1,\n",
       " 'distribution in real': 1,\n",
       " 'in real text': 1,\n",
       " ', the main': 3,\n",
       " 'the main limitation': 3,\n",
       " 'main limitation of': 9,\n",
       " 'limitation of existing': 3,\n",
       " 'of existing approaches': 1,\n",
       " 'existing approaches is': 1,\n",
       " 'approaches is that': 3,\n",
       " 'they are ad-hoc': 1,\n",
       " 'are ad-hoc :': 1,\n",
       " 'ad-hoc : the': 1,\n",
       " ': the rules': 1,\n",
       " 'the rules that': 1,\n",
       " 'rules that govern': 1,\n",
       " 'that govern word': 1,\n",
       " 'govern word formation': 1,\n",
       " 'word formation and': 1,\n",
       " 'formation and inflection': 1,\n",
       " 'and inflection are': 1,\n",
       " 'inflection are only': 1,\n",
       " 'are only implicit': 1,\n",
       " 'only implicit in': 1,\n",
       " 'implicit in such': 1,\n",
       " 'in such systems': 1,\n",
       " 'such systems ,': 1,\n",
       " 'systems , usually': 1,\n",
       " ', usually intertwined': 1,\n",
       " 'usually intertwined with': 1,\n",
       " 'intertwined with control': 1,\n",
       " 'with control structures': 1,\n",
       " 'control structures and': 1,\n",
       " 'structures and general': 1,\n",
       " 'and general code': 1,\n",
       " 'While MERT does': 1,\n",
       " 'MERT does not': 1,\n",
       " 'does not scale': 2,\n",
       " 'not scale to': 1,\n",
       " 'scale to large': 1,\n",
       " 'to large numbers': 1,\n",
       " 'large numbers of': 1,\n",
       " 'numbers of features': 1,\n",
       " 'of features ,': 2,\n",
       " 'features , the': 1,\n",
       " ', the scarcity': 1,\n",
       " 'the scarcity of': 1,\n",
       " 'scarcity of manually': 1,\n",
       " 'of manually aligned': 1,\n",
       " 'manually aligned training': 1,\n",
       " 'aligned training data': 1,\n",
       " 'A major drawback': 3,\n",
       " 'major drawback of': 7,\n",
       " 'of this early': 1,\n",
       " 'this early work': 1,\n",
       " 'early work was': 1,\n",
       " 'work was that': 1,\n",
       " 'was that it': 2,\n",
       " 'that it used': 1,\n",
       " 'it used no': 1,\n",
       " 'used no lexical': 1,\n",
       " 'no lexical information': 1,\n",
       " 'lexical information in': 1,\n",
       " 'information in the': 2,\n",
       " 'in the supertagging': 1,\n",
       " 'the supertagging process': 1,\n",
       " 'supertagging process as': 1,\n",
       " 'process as the': 1,\n",
       " 'as the training': 1,\n",
       " 'the training material': 1,\n",
       " 'training material consisted': 1,\n",
       " 'material consisted of': 1,\n",
       " 'consisted of (': 1,\n",
       " 'of ( part-of-speech': 1,\n",
       " '( part-of-speech ,': 1,\n",
       " 'part-of-speech , supertag': 1,\n",
       " ', supertag )': 1,\n",
       " 'supertag ) pairs': 1,\n",
       " 'Despite of their': 1,\n",
       " 'of their success': 2,\n",
       " 'their success ,': 2,\n",
       " 'success , a': 2,\n",
       " ', a limitation': 3,\n",
       " 'a limitation of': 3,\n",
       " 'limitation of them': 1,\n",
       " 'of them is': 1,\n",
       " 'them is that': 1,\n",
       " 'is that their': 2,\n",
       " 'that their performances': 1,\n",
       " 'their performances are': 1,\n",
       " 'performances are easily': 1,\n",
       " 'are easily affected': 1,\n",
       " 'easily affected by': 1,\n",
       " 'affected by the': 2,\n",
       " 'by the size': 1,\n",
       " 'the size of': 3,\n",
       " 'size of the': 3,\n",
       " 'of the context': 1,\n",
       " 'the context window': 1,\n",
       " 'Furthermore , one': 1,\n",
       " ', one possible': 1,\n",
       " 'one possible drawback': 1,\n",
       " 'possible drawback in': 1,\n",
       " 'drawback in employing': 1,\n",
       " 'in employing this': 1,\n",
       " 'employing this bootstrapping': 1,\n",
       " 'this bootstrapping method': 1,\n",
       " 'bootstrapping method is': 1,\n",
       " 'that there may': 2,\n",
       " 'there may be': 3,\n",
       " 'may be a': 1,\n",
       " 'be a complementary': 1,\n",
       " 'a complementary distribution': 1,\n",
       " 'complementary distribution between': 1,\n",
       " 'distribution between prosodic': 1,\n",
       " 'between prosodic and': 1,\n",
       " 'prosodic and lexical': 1,\n",
       " 'and lexical features': 1,\n",
       " 'Its most obvious': 1,\n",
       " 'most obvious drawback': 1,\n",
       " 'obvious drawback is': 3,\n",
       " 'drawback is that': 56,\n",
       " 'that the method': 2,\n",
       " 'the method can': 1,\n",
       " 'method can translate': 1,\n",
       " 'can translate only': 1,\n",
       " 'translate only those': 1,\n",
       " 'only those source': 1,\n",
       " 'those source language': 1,\n",
       " 'source language strings': 1,\n",
       " 'language strings contained': 1,\n",
       " 'strings contained in': 1,\n",
       " 'contained in the': 1,\n",
       " 'in the translation': 1,\n",
       " 'the translation database': 1,\n",
       " 'Apart from system': 1,\n",
       " 'from system delay': 1,\n",
       " 'system delay ,': 1,\n",
       " 'delay , another': 1,\n",
       " ', another current': 1,\n",
       " 'another current limitation': 1,\n",
       " 'current limitation that': 1,\n",
       " 'limitation that will': 1,\n",
       " 'that will influence': 1,\n",
       " 'will influence future': 1,\n",
       " 'influence future interactive': 1,\n",
       " 'future interactive speech': 1,\n",
       " 'interactive speech systems': 1,\n",
       " 'speech systems is': 1,\n",
       " 'systems is the': 1,\n",
       " 'is the unavailability': 1,\n",
       " 'the unavailability of': 1,\n",
       " 'unavailability of full': 1,\n",
       " 'of full prosodic': 1,\n",
       " 'full prosodic analysis': 1,\n",
       " 'A major weakness': 2,\n",
       " 'major weakness of': 2,\n",
       " 'weakness of many': 2,\n",
       " 'of many existing': 2,\n",
       " 'many existing scoring': 1,\n",
       " 'existing scoring engines': 1,\n",
       " 'scoring engines such': 2,\n",
       " 'engines such as': 2,\n",
       " 'such as the': 2,\n",
       " 'as the Intelligent': 1,\n",
       " 'the Intelligent Essay': 1,\n",
       " 'Intelligent Essay AssessorTM': 1,\n",
       " 'Essay AssessorTM (': 1,\n",
       " 'AssessorTM ( Landauer': 1,\n",
       " '( Landauer et': 2,\n",
       " 'Landauer et al.': 2,\n",
       " 'al. , 2003': 2,\n",
       " '2003 ) is': 2,\n",
       " ') is that': 5,\n",
       " 'that they adopt': 2,\n",
       " 'they adopt a': 2,\n",
       " 'adopt a holistic': 2,\n",
       " 'a holistic scoring': 2,\n",
       " 'holistic scoring scheme': 2,\n",
       " 'scoring scheme ,': 2,\n",
       " 'scheme , which': 2,\n",
       " ', which summarizes': 2,\n",
       " 'which summarizes the': 2,\n",
       " 'summarizes the quality': 2,\n",
       " 'the quality of': 7,\n",
       " 'quality of an': 2,\n",
       " 'of an essay': 2,\n",
       " 'an essay with': 2,\n",
       " 'essay with a': 2,\n",
       " 'with a single': 2,\n",
       " 'a single score': 2,\n",
       " 'single score and': 2,\n",
       " 'score and thus': 2,\n",
       " 'and thus provides': 2,\n",
       " 'thus provides very': 2,\n",
       " 'provides very limited': 2,\n",
       " 'very limited feedback': 2,\n",
       " 'limited feedback to': 2,\n",
       " 'feedback to the': 2,\n",
       " 'to the writer': 2,\n",
       " 'The latter drawback': 1,\n",
       " 'latter drawback is': 1,\n",
       " 'drawback is the': 7,\n",
       " 'is the more': 1,\n",
       " 'the more serious': 1,\n",
       " 'more serious one': 1,\n",
       " 'serious one :': 1,\n",
       " 'one : the': 1,\n",
       " ': the metrics': 1,\n",
       " 'the metrics were': 1,\n",
       " 'metrics were not': 1,\n",
       " 'were not designed': 1,\n",
       " 'not designed to': 1,\n",
       " 'designed to evaluate': 1,\n",
       " 'to evaluate single': 1,\n",
       " 'evaluate single key/response': 1,\n",
       " 'single key/response pairs': 1,\n",
       " 'key/response pairs ,': 1,\n",
       " 'pairs , but': 1,\n",
       " ', but whole': 1,\n",
       " 'but whole texts': 1,\n",
       " 'The disadvantage of': 4,\n",
       " 'disadvantage of this': 6,\n",
       " 'of this approach': 8,\n",
       " 'this approach is': 8,\n",
       " 'approach is that': 16,\n",
       " 'is that it': 50,\n",
       " 'that it involves': 2,\n",
       " 'it involves a': 1,\n",
       " 'involves a good': 1,\n",
       " 'a good deal': 1,\n",
       " 'good deal of': 1,\n",
       " 'deal of human': 1,\n",
       " 'of human effort': 1,\n",
       " 'human effort to': 1,\n",
       " 'effort to research': 1,\n",
       " 'to research on': 1,\n",
       " 'research on a': 1,\n",
       " 'on a specific': 1,\n",
       " 'a specific data': 1,\n",
       " 'specific data set': 1,\n",
       " 'data set and': 1,\n",
       " 'set and summarize': 1,\n",
       " 'and summarize the': 1,\n",
       " 'summarize the rules': 1,\n",
       " 'The most significant': 1,\n",
       " 'most significant drawback': 1,\n",
       " 'significant drawback is': 1,\n",
       " 'is that ontologies': 1,\n",
       " 'that ontologies are': 1,\n",
       " 'ontologies are not': 1,\n",
       " 'are not standard': 1,\n",
       " 'not standard among': 1,\n",
       " 'standard among systems': 1,\n",
       " 'The limitation of': 1,\n",
       " 'limitation of locating': 1,\n",
       " 'of locating parts': 1,\n",
       " 'locating parts of': 1,\n",
       " 'parts of arguments': 1,\n",
       " 'of arguments ,': 1,\n",
       " 'arguments , such': 1,\n",
       " ', such as': 3,\n",
       " 'as the positions': 1,\n",
       " 'the positions and': 1,\n",
       " 'positions and head': 1,\n",
       " 'and head words': 1,\n",
       " 'head words ,': 1,\n",
       " 'words , is': 1,\n",
       " ', is that': 5,\n",
       " 'that it is': 11,\n",
       " 'it is only': 1,\n",
       " 'is only a': 3,\n",
       " 'only a partial': 1,\n",
       " 'a partial solution': 1,\n",
       " 'partial solution to': 1,\n",
       " 'solution to argument': 1,\n",
       " 'to argument labeling': 1,\n",
       " 'argument labeling in': 1,\n",
       " 'labeling in discourse': 1,\n",
       " 'in discourse parsing': 1,\n",
       " 'The only drawback': 4,\n",
       " 'only drawback or': 1,\n",
       " 'drawback or risk': 1,\n",
       " 'or risk of': 1,\n",
       " 'risk of this': 1,\n",
       " 'of this strategy': 2,\n",
       " 'this strategy is': 2,\n",
       " 'strategy is that': 1,\n",
       " 'is that some': 3,\n",
       " 'that some of': 1,\n",
       " 'some of the': 3,\n",
       " 'of the system': 4,\n",
       " 'the system timex-values': 1,\n",
       " 'system timex-values could': 1,\n",
       " 'timex-values could be': 1,\n",
       " 'could be incorrect': 1,\n",
       " ', the WCN': 1,\n",
       " 'the WCN does': 1,\n",
       " 'WCN does not': 1,\n",
       " 'does not assign': 1,\n",
       " 'not assign probability': 1,\n",
       " 'assign probability to': 1,\n",
       " 'probability to the': 1,\n",
       " 'to the u': 1,\n",
       " 'the u =': 1,\n",
       " 'u = fi*': 1,\n",
       " '= fi* case': 1,\n",
       " 'fi* case â€“': 1,\n",
       " 'The primary weakness': 1,\n",
       " 'primary weakness of': 1,\n",
       " 'that it relies': 1,\n",
       " 'it relies too': 2,\n",
       " 'relies too heavily': 1,\n",
       " 'too heavily on': 1,\n",
       " 'heavily on user': 1,\n",
       " 'on user interaction': 1,\n",
       " 'Our solution to': 1,\n",
       " 'problem of lone': 1,\n",
       " 'of lone prepositions': 1,\n",
       " 'One shortcoming of': 5,\n",
       " 'of the dual': 1,\n",
       " 'the dual decomposition': 1,\n",
       " 'dual decomposition approach': 1,\n",
       " 'decomposition approach is': 1,\n",
       " 'that it only': 1,\n",
       " 'it only applies': 1,\n",
       " 'only applies to': 1,\n",
       " 'applies to parse-scoring': 1,\n",
       " 'to parse-scoring functions': 1,\n",
       " 'parse-scoring functions with': 1,\n",
       " 'functions with an': 1,\n",
       " 'with an arc-factored': 1,\n",
       " 'an arc-factored component': 1,\n",
       " 'One disadvantage of': 1,\n",
       " 'disadvantage of the': 2,\n",
       " 'of the model': 8,\n",
       " 'the model above': 1,\n",
       " 'model above is': 1,\n",
       " 'above is that': 2,\n",
       " 'it is not': 5,\n",
       " 'is not capable': 1,\n",
       " 'not capable of': 2,\n",
       " 'capable of modeling': 1,\n",
       " 'of modeling bilexical': 1,\n",
       " 'modeling bilexical dependencies': 1,\n",
       " 'bilexical dependencies on': 1,\n",
       " 'dependencies on the': 1,\n",
       " 'on the right': 1,\n",
       " 'the right hand': 1,\n",
       " 'right hand side': 1,\n",
       " 'hand side of': 1,\n",
       " 'side of the': 1,\n",
       " 'of the rules': 3,\n",
       " 'Another issue with': 1,\n",
       " 'issue with the': 2,\n",
       " 'with the linear': 1,\n",
       " 'the linear representation': 1,\n",
       " 'linear representation of': 1,\n",
       " 'representation of ECs': 1,\n",
       " 'of ECs is': 1,\n",
       " 'ECs is that': 1,\n",
       " 'is that crucial': 1,\n",
       " 'that crucial dependencies': 1,\n",
       " 'crucial dependencies between': 1,\n",
       " 'dependencies between ECs': 1,\n",
       " 'between ECs and': 1,\n",
       " 'ECs and other': 1,\n",
       " 'and other elements': 1,\n",
       " 'other elements in': 1,\n",
       " 'elements in the': 1,\n",
       " 'in the syntactic': 1,\n",
       " 'the syntactic structure': 1,\n",
       " 'syntactic structure are': 1,\n",
       " 'structure are not': 1,\n",
       " 'are not represented': 1,\n",
       " 'main drawback is': 8,\n",
       " 'that it needs': 1,\n",
       " 'it needs almost': 1,\n",
       " 'needs almost 20,000': 1,\n",
       " 'almost 20,000 iterations': 1,\n",
       " '20,000 iterations before': 1,\n",
       " 'iterations before the': 1,\n",
       " 'before the Gibbs': 1,\n",
       " 'the Gibbs sampler': 1,\n",
       " 'Gibbs sampler converges': 1,\n",
       " 'One drawback is': 3,\n",
       " 'that it cannot': 1,\n",
       " 'it cannot deal': 1,\n",
       " 'cannot deal with': 2,\n",
       " 'deal with dependencies': 1,\n",
       " 'with dependencies of': 1,\n",
       " 'dependencies of higher': 1,\n",
       " 'of higher order': 1,\n",
       " 'higher order of': 1,\n",
       " 'order of TU': 1,\n",
       " 'of TU n-grams': 1,\n",
       " 'TU n-grams than': 1,\n",
       " 'n-grams than bigrams': 1,\n",
       " 'Another limitation that': 2,\n",
       " 'limitation that may': 1,\n",
       " 'that may have': 1,\n",
       " 'may have affected': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "dict(Counter(tri_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersecting two dictionaries\n",
    "intersect_bigrams = {x:ini_dict1[x] for x in ini_dict1 \n",
    "                              if x in ini_dict2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4efff7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The difficulty',\n",
       " 'difficulty with',\n",
       " 'with this',\n",
       " 'this task',\n",
       " 'task lies',\n",
       " 'lies in',\n",
       " 'in the',\n",
       " 'the fact',\n",
       " 'fact that',\n",
       " 'that prosodic',\n",
       " 'prosodic cues',\n",
       " 'cues are',\n",
       " 'are never',\n",
       " 'never absolute',\n",
       " 'absolute ;',\n",
       " '; they',\n",
       " 'they are',\n",
       " 'are relative',\n",
       " 'relative to',\n",
       " 'to individual',\n",
       " 'individual speakers',\n",
       " 'speakers ,',\n",
       " ', gender',\n",
       " 'gender ,',\n",
       " ', dialect',\n",
       " 'dialect ,',\n",
       " ', discourse',\n",
       " 'discourse context',\n",
       " 'context ,',\n",
       " ', local',\n",
       " 'local context',\n",
       " 'context ,',\n",
       " ', phonological',\n",
       " 'phonological environment',\n",
       " 'environment ,',\n",
       " ', and',\n",
       " 'and many',\n",
       " 'many other',\n",
       " 'other factors',\n",
       " 'The problem',\n",
       " 'problem with',\n",
       " 'with rich',\n",
       " 'rich annotations',\n",
       " 'annotations is',\n",
       " 'is that',\n",
       " 'that they',\n",
       " 'they increase',\n",
       " 'increase the',\n",
       " 'the state',\n",
       " 'state space',\n",
       " 'space of',\n",
       " 'of the',\n",
       " 'the grammar',\n",
       " 'grammar substantially',\n",
       " 'As a',\n",
       " 'a consequence',\n",
       " 'consequence ,',\n",
       " ', when',\n",
       " 'when adapting',\n",
       " 'adapting existing',\n",
       " 'existing methods',\n",
       " 'methods and',\n",
       " 'and techniques',\n",
       " 'techniques to',\n",
       " 'to a',\n",
       " 'a new',\n",
       " 'new domain',\n",
       " 'domain ,',\n",
       " ', researchers',\n",
       " 'researchers and']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_grams[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[*partition(2, [1, 2,3 ,4,5, 5,6,7], 1)]\n",
    "bi_grams = [a+b for a,b in partition(2, note_names, 1)]\n",
    "tri_grams = [a+b+c for a,b,c in partition(3, note_names,1)]\n",
    "quart_grams = [a+b+c+d for a,b,c,d in partition(4, note_names,1)]\n",
    "\n",
    "tri_grams += [\"---\"]\n",
    "quart_grams += [\"----\", \"----\"] #place filler\n",
    "len(bi_grams), len(tri_grams), len(quart_grams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
