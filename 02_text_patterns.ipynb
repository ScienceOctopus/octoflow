{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eeb96ae",
   "metadata": {},
   "source": [
    "# Finding (Problem Statement) Signal in Sentence Phrasing\n",
    "\n",
    "Here we look at intersecting (low signal) and exclusive (only in one class aka high signal) [n-grams](https://en.wikipedia.org/wiki/N-gram) of positive and negative labeled sentences.\n",
    "\n",
    "If there are n-grams that *almost* exclusively appear in one class (0 or 1) then they could make great matching phrases either directly for classifying a sentence without using a machine learning model or just to do last-mile quality assurance and flag suspicious model decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8387b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"datasets/problem_statements.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37992cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def take_while(fn, coll):\n",
    "    \"\"\"Yield values from coll until fn is False\"\"\"\n",
    "    for e in coll:\n",
    "        if fn(e):\n",
    "            yield e\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def partition(n, coll, step=None):\n",
    "    return take_while(lambda e: len(e) == n,\n",
    "        (coll[i:i+n] for i in range(0, len(coll), step or n)))\n",
    "\n",
    "def partition_all(n, coll, step=None):\n",
    "    return (coll[i:i+n] for i in range(0, len(coll), step or n))\n",
    "\n",
    "def n_grams(texts, n_gram=2): return [\" \".join(n) for t in texts for n in partition(n_gram, t.split(\" \"), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def lemmatize(text, nlp=nlp):\n",
    "    return \" \".join([tok.lemma_ for tok in nlp(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfba938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemmatized\"] = df[\"text\"].map(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"lemmatized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = df[df[\"labels\"] == 1]\n",
    "negatives = df[df[\"labels\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0b0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PMID</th>\n",
       "      <th>source</th>\n",
       "      <th>Title</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>DOI</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the difficulty with this task lie in the fact ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the difficulty with this task lie in the fact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the problem with rich annotation be that they ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the problem with rich annotation be that they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acl_cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as a consequence , when adapt exist method and...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as a consequence , when adapt exist method and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PMID         source Title  \\\n",
       "0           0   NaN  acl_cambridge   NaN   \n",
       "1           1   NaN  acl_cambridge   NaN   \n",
       "2           2   NaN  acl_cambridge   NaN   \n",
       "\n",
       "                                                text  labels  DOI  \\\n",
       "0  the difficulty with this task lie in the fact ...       1  NaN   \n",
       "1  the problem with rich annotation be that they ...       1  NaN   \n",
       "2  as a consequence , when adapt exist method and...       1  NaN   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  the difficulty with this task lie in the fact ...  \n",
       "1  the problem with rich annotation be that they ...  \n",
       "2  as a consequence , when adapt exist method and...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f94298",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grams_pos = n_grams(positives[\"text\"], 2)\n",
    "tri_grams_pos = n_grams(positives[\"text\"], 3)\n",
    "bi_grams_neg = n_grams(negatives[\"text\"], 2)\n",
    "tri_grams_neg = n_grams(negatives[\"text\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f54f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the difficulty', 'difficulty with', 'with this']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_grams_pos[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5726cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "d1 = dict(Counter(bi_grams_pos))\n",
    "d2 = dict(Counter(bi_grams_neg))\n",
    "\n",
    "d3 = dict(Counter(tri_grams_pos))\n",
    "d4 = dict(Counter(tri_grams_neg))\n",
    "\n",
    "bi_grams_both = {x:(d1[x], d2[x]) for x in d1 if x in d2}\n",
    "\n",
    "tri_grams_both = {x:(d3[x], d4[x]) for x in d3 if d4.get(x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grams_pos_only = {x:d1[x] for x in d1 if not d2.get(x)} # and d2.get(x) < 5\n",
    "tri_grams_pos_only = {x:d3[x] for x in d3 if not d4.get(x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08db784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the fact that', (12, 21)),\n",
       " ('be use for', (3, 24)),\n",
       " ('et al .', (9, 79)),\n",
       " ('al . ,', (9, 66)),\n",
       " ('that they be', (12, 12)),\n",
       " ('one of the', (23, 34)),\n",
       " ('be that the', (66, 9)),\n",
       " ('be that it', (52, 3)),\n",
       " ('- of -', (6, 23)),\n",
       " ('the quality of', (7, 15)),\n",
       " ('that it be', (12, 18)),\n",
       " ('it be not', (5, 18)),\n",
       " ('n - gram', (8, 27)),\n",
       " ('in the training', (6, 18)),\n",
       " ('the training datum', (6, 30)),\n",
       " ('have not be', (5, 23)),\n",
       " ('it do not', (10, 24)),\n",
       " ('to the same', (4, 18)),\n",
       " ('in term of', (6, 18)),\n",
       " ('the use of', (5, 25)),\n",
       " (', which be', (8, 22)),\n",
       " ('be able to', (6, 18)),\n",
       " ('as well as', (5, 21)),\n",
       " ('they do not', (7, 15)),\n",
       " ('the most common', (18, 13)),\n",
       " ('take into account', (5, 18)),\n",
       " ('can not be', (5, 19)),\n",
       " ('can be use', (3, 27)),\n",
       " ('we do not', (3, 18)),\n",
       " ('the number of', (9, 39)),\n",
       " ('in order to', (3, 18)),\n",
       " ('be use to', (3, 25)),\n",
       " ('the treatment of', (2, 19)),\n",
       " ('- to -', (3, 24)),\n",
       " ('the effect of', (2, 28)),\n",
       " ('there be a', (4, 27)),\n",
       " ('a set of', (1, 21)),\n",
       " ('base on the', (1, 29)),\n",
       " (') be a', (23, 19)),\n",
       " ('be one of', (15, 16)),\n",
       " ('of the most', (17, 8)),\n",
       " ('be a common', (23, 10)),\n",
       " ('be the most', (14, 17)),\n",
       " ('in patient with', (2, 23)),\n",
       " (') have be', (1, 20))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in Counter(tri_grams_both).items() if (v[0] + v[1]) > 20 ]\n",
    "#n-gram: (pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0354c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in the', (81, 331)),\n",
       " (', and', (47, 221)),\n",
       " ('be that', (279, 12)),\n",
       " ('of the', (154, 519)),\n",
       " ('as a', (16, 96)),\n",
       " ('be use', (13, 106)),\n",
       " ('be the', (87, 70)),\n",
       " ('be not', (37, 159)),\n",
       " ('do not', (45, 144)),\n",
       " (', the', (44, 126)),\n",
       " (', which', (36, 93)),\n",
       " ('can be', (18, 96)),\n",
       " ('number of', (20, 108)),\n",
       " ('that the', (82, 75)),\n",
       " ('there be', (19, 85)),\n",
       " ('to be', (28, 120)),\n",
       " ('to the', (48, 229)),\n",
       " ('be a', (104, 181)),\n",
       " (') be', (64, 88)),\n",
       " ('it be', (28, 106)),\n",
       " ('on the', (24, 143)),\n",
       " ('of a', (14, 103)),\n",
       " ('the same', (19, 98)),\n",
       " ('have be', (26, 133)),\n",
       " ('for the', (19, 102)),\n",
       " (', we', (6, 122))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in Counter(bi_grams_both).items() if (v[0] + v[1]) > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad74b119",
   "metadata": {},
   "source": [
    "Let's look at patterns that one class shows very rarely relative to the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec9870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('be that', (279, 12)),\n",
       "  ('problem of', (57, 1)),\n",
       "  ('problem be', (22, 1)),\n",
       "  ('limitation of', (48, 1)),\n",
       "  ('shortcoming of', (24, 1))],\n",
       " [('be that it', (52, 3)), ('lead cause of', (9, 1))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor = 15\n",
    "#show n-grams that appear at least 20x more often in positive samples\n",
    "[(k,v) for k,v in Counter(bi_grams_both).items() if (v[0]/v[1]) > factor], [(k,v) for k,v in Counter(tri_grams_both).items() if (v[0]/v[1]) > factor/2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da71e46b",
   "metadata": {},
   "source": [
    "Apparently \"problem of\" appears 54 in \"problem statements\" and only once in \"non-problem\" statement. Let's look at that one sentence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eda4779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'peripheral neuropathy be the most common problem of diabetes .'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives[negatives[\"text\"].str.contains('problem of')].reset_index()[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96afc26e",
   "metadata": {},
   "source": [
    "Interesting ... through the bi-gram analysis we found a statement that actually sounds like a problem statement and should/could be labeled a 1 (problem statement) ... but isn't in the dataset.\n",
    "In that case I'd feel OK with using \"problem of\" as a hard-coded pattern-matching rule in finding positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9710e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('with this', 11),\n",
       " ('the problem', 57),\n",
       " ('problem with', 20),\n",
       " ('main drawback', 16),\n",
       " ('drawback of', 57),\n",
       " ('limitation be', 41),\n",
       " ('the disadvantage', 15),\n",
       " ('disadvantage of', 16),\n",
       " ('method be', 14),\n",
       " ('shortcoming be', 18),\n",
       " ('disadvantage be', 12),\n",
       " ('a serious', 13),\n",
       " ('issue of', 14),\n",
       " ('one drawback', 11),\n",
       " ('main limitation', 11),\n",
       " ('major drawback', 13),\n",
       " ('drawback be', 67),\n",
       " ('another limitation', 14),\n",
       " ('a drawback', 17),\n",
       " ('the drawback', 38),\n",
       " ('of use', 14),\n",
       " ('the major', 14)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in Counter(bi_grams_pos_only).items() if v > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa37139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lie in the', 7),\n",
       " ('be that they', 31),\n",
       " ('the problem of', 44),\n",
       " ('approach be the', 9),\n",
       " ('be the fact', 7),\n",
       " ('the main drawback', 12),\n",
       " ('limitation be that', 32),\n",
       " ('the disadvantage of', 7),\n",
       " (', the problem', 8),\n",
       " ('the problem be', 8),\n",
       " ('problem of the', 7),\n",
       " ('method be that', 10),\n",
       " ('limitation be the', 7),\n",
       " ('disadvantage be that', 10),\n",
       " ('be that there', 9),\n",
       " ('the issue of', 10),\n",
       " ('drawback of this', 7),\n",
       " ('the main limitation', 11),\n",
       " ('main limitation of', 9),\n",
       " ('approach be that', 19),\n",
       " ('major drawback of', 7),\n",
       " ('drawback be that', 57),\n",
       " ('drawback be the', 7),\n",
       " ('of this approach', 8),\n",
       " ('this approach be', 9),\n",
       " ('main drawback be', 8),\n",
       " ('limitation of the', 17),\n",
       " ('the drawback of', 20),\n",
       " ('the drawback be', 16),\n",
       " ('shortcoming be that', 12),\n",
       " ('that it do', 7),\n",
       " ('be that we', 10),\n",
       " ('be that a', 9),\n",
       " ('have the drawback', 9),\n",
       " ('another limitation be', 8),\n",
       " ('a drawback of', 8),\n",
       " ('drawback of the', 8),\n",
       " ('problem with this', 7),\n",
       " ('model be that', 7),\n",
       " ('problem be that', 14),\n",
       " ('a drawback be', 7),\n",
       " ('be a serious', 7)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in Counter(tri_grams_pos_only).items() if v > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccae529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hi you\" not in [\"hi you\", \"hey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22de83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trigrams that are not supersets of bigrams\n",
    "[bigram for bigram in bi_grams_pos_only.keys() if not any(bigram in tg for tg in tri_grams_pos_only.keys())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea1cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[df[\"text\"].str.contains(\"drawback be that\")].reset_index()[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b169b78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     its most obvious drawback be that the method c...\n",
       "1     the most significant drawback be that ontology...\n",
       "2     the main drawback be that it need almost 20,00...\n",
       "3     one drawback be that it can not deal with depe...\n",
       "4     a potential drawback be that it might not work...\n",
       "5     the drawback be that , since extract event in ...\n",
       "6     the main drawback be that the entry produce au...\n",
       "7     an obvious drawback be that it be necessary to...\n",
       "8     the only drawback be that it willperform slow ...\n",
       "9     the drawback be that the estimate of parameter...\n",
       "10    one possible drawback be that sense which one ...\n",
       "11    their major drawback be that they require a gr...\n",
       "12    the first drawback be that it require more kno...\n",
       "13    another drawback be that it be impossible to a...\n",
       "14    the drawback be that the solution may be only ...\n",
       "15    the main drawback be that structure may not be...\n",
       "16    another major drawback be that it require cons...\n",
       "17    the major drawback be that we have to generate...\n",
       "18    the drawback be that this context may not be s...\n",
       "19               the drawback be that this be expensive\n",
       "20    their main drawback be that they may or may no...\n",
       "21    another drawback be that the different sentenc...\n",
       "22    the drawback be that the solution may be only ...\n",
       "23    however , an important drawback be that the ta...\n",
       "24    a drawback be that their method limit the trai...\n",
       "25    the drawback be that morphotactic be explicitl...\n",
       "26    a drawback be that these feature give no infor...\n",
       "27    a possible drawback be that for some input , t...\n",
       "28    a drawback be that this structure may be cubic...\n",
       "29    the benefit of this approach be that the distr...\n",
       "30    the main drawback be that training time be inc...\n",
       "31    however , the drawback be that an adaption to ...\n",
       "32    the primary drawback be that KB annotation be ...\n",
       "33    the drawback be that there be a margin of erro...\n",
       "34    one drawback be that the parsing process might...\n",
       "35    an additional drawback be that all exist syste...\n",
       "36    a drawback be that the corpus be not publicly ...\n",
       "37    a drawback be that a grammar may need a large ...\n",
       "38    the second drawback be that the criterion for ...\n",
       "39    however , an obvious drawback be that the actu...\n",
       "40    the drawback be that the complexity in syntact...\n",
       "41    the second drawback be that 38 % of the slot t...\n",
       "42    the drawback be that the identification of men...\n",
       "43    its main drawback be that important structural...\n",
       "44    the drawback be that we only cover about half ...\n",
       "45    the first drawback be that Ravichandran and Ho...\n",
       "46    it have many positive feature , but one drawba...\n",
       "47    one potential drawback be that it require high...\n",
       "48    a fundamental drawback be that phrase be trans...\n",
       "49    a drawback be that theoretical approach become...\n",
       "50    a drawback be that the time complexity of infe...\n",
       "51    the drawback be that it cause sensitivity to o...\n",
       "52    one drawback be that LMF provide only a specif...\n",
       "53    a potential drawback be that we get few datum ...\n",
       "54    their drawback be that , as most generative mo...\n",
       "55    the drawback be that the presence of semantic ...\n",
       "56    their main drawback be that they be tie to the...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
