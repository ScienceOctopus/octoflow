{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6dd2921",
   "metadata": {},
   "source": [
    "Keybert for sample subset of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1af907",
   "metadata": {},
   "outputs": [],
   "source": [
    "* attach DOI to each cluster\n",
    "* attach topic1 and topic2 to each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "def get_kw(text, kw_model=kw_model):\n",
    "    kws = kw_model.extract_keywords(text, \n",
    "                          keyphrase_ngram_range=(1, 2), \n",
    "                          stop_words='english',\n",
    "                          use_mmr=True, \n",
    "                          diversity=0.2)\n",
    "    \n",
    "    kws.sort(key=lambda x: x[1], reverse=True)\n",
    "    return kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35556c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{cluster: [cluster],\n",
    "doi: [dois],\n",
    "topic: topicname,\n",
    "\n",
    "}\n",
    "for cluster in clusters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ingest the processed docs into the HierarchicalTagger pipeline\n",
    "\n",
    "# Load topic labels from precomputed datast\n",
    "# If you ran Engines on your own data, change the path to where you stored the output.\n",
    "PRECOMPUTED_ITEM_TOPICS = os.path.join(ROOT_DIR, \"./examples/data/amazon_products_precomputed.json\")\n",
    "with open(PRECOMPUTED_ITEM_TOPICS, \"r\") as f:\n",
    "    topics = json.load(f)\n",
    "\n",
    "# Confirm we have topics for all 3000 documents\n",
    "len(topics)\n",
    "\n",
    "JSON(topics)\n",
    "\n",
    "\n",
    "\n",
    "# Inspect results for an item. We are interested in the `topics` key\n",
    "topics[\"96d96237978ba26bbc6baa437372527a\"]\n",
    "\n",
    "!pwd\n",
    "!pip install -r ../requirements.txt\n",
    "\n",
    "import sys\n",
    "sys.path\n",
    "sys.path.insert(0, \"/home/ec2-user/SageMaker/primer-hierarchical-tagger/\") \n",
    "\n",
    "!pip install sentence-transformers\n",
    "\n",
    "!pip install treelib scikit-network\n",
    "\n",
    "\n",
    "# Import module and create a HierarchicalTagger instance\n",
    "from hierarchical_tagger.hierarchical_tagger import HierarchicalTagger\n",
    "hierarchical_tagger = HierarchicalTagger()\n",
    "\n",
    "# Rework the document topic representations into a dictionary mapping document_id: List[topic labels as str]\n",
    "document_topics = {document_id: topics_entry['topics'] for document_id, topics_entry in topics.items()}\n",
    "\n",
    "JSON(document_topics)\n",
    "\n",
    "# Send the document ids and their corresponding topic labels for ingest\n",
    "hierarchical_tagger.ingest(document_terms=document_topics)\n",
    "\n",
    "# The previous step is the most computationally demanding.\n",
    "# To avoid having to repeat this, we can save our HierarchicalTagger instance to a json file, using the .to_json() helper method.\n",
    "# As this file will also be the input data to our web app, so let's save it in `webapp/data/`\n",
    "SERIALIZED_INSTANCE_PATH = os.path.join(ROOT_DIR, \"./webapp/data/amazon_products.json\")\n",
    "with open(SERIALIZED_INSTANCE_PATH, \"w\") as f:\n",
    "    f.write(hierarchical_tagger.to_json())\n",
    "\n",
    "# This is how we can reload a HierarchicalTagger instance from file\n",
    "with open(SERIALIZED_INSTANCE_PATH, \"r\") as f:\n",
    "    reloaded_serialized =  json.load(f)\n",
    "hierarchical_tagger = HierarchicalTagger.from_dict(reloaded_serialized)\n",
    "\n",
    "## Build the topic tree and tag the documents\n",
    "\n",
    "#### Hierarchical topic tree\n",
    "\n",
    "The `.fit_tag_tree()` method populates the `.tree` attribute with a [treelib](https://treelib.readthedocs.io/en/latest/) object representing the extracted term tree. This can be manipulated and explored with all the treelib methods, for example `.show()` to print out a text representation of the tree.\n",
    "\n",
    "# Fit the tree\n",
    "hierarchical_tagger.fit_tag_tree()\n",
    "hierarchical_tagger.tree.show()\n",
    "\n",
    "# The final step is tagging the original documents based on the hierarchy we found in the tree\n",
    "hierarchical_tagger.tag_documents()\n",
    "\n",
    "#### Document tags\n",
    "\n",
    "Inspect the `document_tags` attribute: a dictionary mapping document `id` to a list of tuples of the form `(term, score, node_id)` sorted by descending score. `score` measures how close in meaning the term is to the document. We would expect higher level abstractions to have lower scores.\n",
    "`node_id` loosely indicates how high the node is in the tree: it's not a perfect measure, but more abstract terms will generally have higher `node_id`s.\n",
    "\n",
    "# Let's see how the tags assinged to the Hover Board example we saw above\n",
    "hierarchical_tagger.document_tags[\"96d96237978ba26bbc6baa437372527a\"]\n",
    "\n",
    "## Tuning parameters and using the web app\n",
    "\n",
    "We expose several tuning parameters that the investigator can tweak to guide the extraction of the term tree and the logic applied when tagging the documents. You can find detailed documentation [here](https://github.com/PrimerAI/hierarchical-tagger/blob/main/hierarchical_tagger/hierarchical_tagger.py#L33). \n",
    "\n",
    "This repository also includes a simple web app to facilitate this iterative exploration. In a terminal, just run activate this tutorial's virtual enviroment and run the app like this:\n",
    "\n",
    "```\n",
    "$ workon ht-repo # Or alternative command to activate your virtual environment\n",
    "$ streamlit run webapp/app.py\n",
    "```\n",
    "\n",
    "You can find more detailed instructions in our [companion tutorial](TODO_ADDLINK).\n",
    "\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "We hope you enjoyed this tutorial! Can you think of any other data you could run this on?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Let's see how the tags assinged to the Hover Board example we saw above\n",
    "hierarchical_tagger.document_tags[\"96d96237978ba26bbc6baa437372527a\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
