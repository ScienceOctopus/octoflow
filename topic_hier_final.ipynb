{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c33efdcb",
   "metadata": {},
   "source": [
    "Keybert for sample subset of each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e9be0",
   "metadata": {},
   "source": [
    "* attach DOI to each cluster\n",
    "* attach topic1 and topic2 to each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d36c3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "field = \"env\"\n",
    "\n",
    "clusters_path = f'downloads/{field}_clusters.json'\n",
    "topic_path=f'downloads/{field}_topics.json'\n",
    "hier_path = f'{field}_hier'\n",
    "\n",
    "# df = df[df.text.notna() & df.doi.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cf0cdb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'downloads/env_clusters.json'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a9a5c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"downloads/env_aug13.csv\")#.sample(frac=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a2c49677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(clusters_path) as f:\n",
    "    clusters = json.loads(f.read())\n",
    "    #print(data['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "37ecde8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keybert in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.6.0)\n",
      "Requirement already satisfied: flatdict in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keybert) (1.19.5)\n",
      "Requirement already satisfied: rich>=10.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keybert) (12.5.1)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keybert) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keybert) (0.24.2)\n",
      "Requirement already satisfied: dataclasses<0.9,>=0.7 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rich>=10.4.0->keybert) (0.8)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rich>=10.4.0->keybert) (4.1.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rich>=10.4.0->keybert) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rich>=10.4.0->keybert) (2.9.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn>=0.22.2->keybert) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn>=0.22.2->keybert) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn>=0.22.2->keybert) (1.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers>=0.3.8->keybert) (0.4.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers>=0.3.8->keybert) (0.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers>=0.3.8->keybert) (4.18.0)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers>=0.3.8->keybert) (0.1.97)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers>=0.3.8->keybert) (1.6.0)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers>=0.3.8->keybert) (3.6.2)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers>=0.3.8->keybert) (4.64.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (21.3)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (5.4.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.5.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.25.1)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (0.18.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2021.4.4)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.12.1)\n",
      "Requirement already satisfied: importlib-resources in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tqdm->sentence-transformers>=0.3.8->keybert) (5.4.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (8.0.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (1.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (8.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.4.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (1.26.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert flatdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eedcf9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "223e51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"downloads/verbs-conjugations.json\") as f:\n",
    "    verbs = json.loads(f.read())\n",
    "    #print(data['data'][0])\n",
    "    \n",
    "import flatdict\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "def contains_number(value):\n",
    "    for character in value:\n",
    "        if character.isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "all_verbs = [flatten(flatdict.FlatDict(v_dict).values()) for v_dict in verbs]     \n",
    "flat_verbs = flatten(all_verbs)\n",
    "flat_verbs = [v for v in flat_verbs if len(v) > 2]\n",
    "unique_verbs = list(set(flat_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d8af2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kws(text, kw_model=kw_model, blacklist=unique_verbs):\n",
    "    kws = kw_model.extract_keywords(text, \n",
    "                          keyphrase_ngram_range=(1, 2), \n",
    "                          stop_words='english',\n",
    "                          use_mmr=True, \n",
    "                          diversity=0.25)\n",
    "    \n",
    "    kws.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    nkws = []\n",
    "    for kw in kws:\n",
    "        name, probs = kw\n",
    "        terms = name.split(\" \")\n",
    "        if len([term for term in terms if \n",
    "                term.endswith(\"ing\") \n",
    "                or term.endswith(\"ly\") \n",
    "                or term in blacklist\n",
    "                or len(term) < 4\n",
    "                #or the last letter is the only vowel\n",
    "                or contains_number(term) \n",
    "                or not any(vowel in term for vowel in [\"a\", \"e\", \"i\", \"o\", \"u\"]) #avoid words like hdfg\n",
    "               ]) == 0:\n",
    "            nkws += [kw]\n",
    "    \n",
    "    return nkws\n",
    "#         if len([term for term in kw.split(\" \") if term.endswith(\"ing\")] > or \n",
    "#     return kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5e56df8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('soil carbon', 0.7111),\n",
       " ('forest soils', 0.6667),\n",
       " ('control soil', 0.5403),\n",
       " ('forest ecosystems', 0.5208),\n",
       " ('carbon dynamics', 0.5128)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_kws(clusters[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d0aae001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(clusters):\n",
    "    c[\"topics\"] = get_kws(c[\"text\"])\n",
    "    if i % 200 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e8ff3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = {}\n",
    "for c in clusters:\n",
    "    topic_dict[c[\"doi\"]] = [t[0] for t in c[\"topics\"][:4] if t[1] > 0.4] #limit to top three ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0ee5e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "#JSON(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb636a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "14ef4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(topic_path, 'w') as f:\n",
    "    json.dump(topic_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e875af",
   "metadata": {},
   "source": [
    "## Hiearchies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "54d4ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defined at bottom\n",
    "hierarchical_tagger = HierarchicalTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ee9fda08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ingest the processed docs into the HierarchicalTagger pipeline\n",
    "\n",
    "# Load topic labels from precomputed datast\n",
    "ROOT_DIR= \"/home/ec2-user/SageMaker/octoflow\"\n",
    "# If you ran Engines on your own data, change the path to where you stored the output.\n",
    "PRECOMPUTED_ITEM_TOPICS = os.path.join(ROOT_DIR, topic_path)\n",
    "with open(PRECOMPUTED_ITEM_TOPICS, \"r\") as f:\n",
    "    topics = json.load(f)\n",
    "# Confirm we have topics for all 3000 documents\n",
    "len(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "262bc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = {r[\"doi\"]: {\"fields\": r['fields'], \"text\": r['text']} for i, r in df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bb965c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rework the document topic representations into a dictionary mapping document_id: List[topic labels as str]\n",
    "# document_topics = {document_id: topics_entry['topics'] for document_id, topics_entry in topics.items()}\n",
    "# Send the document ids and their corresponding topic labels for ingest\n",
    "hierarchical_tagger.ingest(document_terms=topics, document_attributes=attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "53cf9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous step is the most computationally demanding.\n",
    "# To avoid having to repeat this, we can save our HierarchicalTagger instance to a json file, using the .to_json() helper method.\n",
    "# As this file will also be the input data to our web app, so let's save it in `webapp/data/`\n",
    "SERIALIZED_INSTANCE_PATH = os.path.join(ROOT_DIR, \"downloads/hierarch_biomed.json\")\n",
    "with open(SERIALIZED_INSTANCE_PATH, \"w\") as f:\n",
    "    f.write(hierarchical_tagger.to_json())\n",
    "\n",
    "# This is how we can reload a HierarchicalTagger instance from file\n",
    "with open(SERIALIZED_INSTANCE_PATH, \"r\") as f:\n",
    "    reloaded_serialized =  json.load(f)\n",
    "hierarchical_tagger = HierarchicalTagger.from_dict(reloaded_serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f21a3a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environmental problems\n",
      "├── anaerobic\n",
      "├── carbon soil\n",
      "│   ├── pollution\n",
      "│   │   ├── carbon dioxide\n",
      "│   │   │   ├── carbon sequestration\n",
      "│   │   │   │   └── emission greenhouse\n",
      "│   │   │   └── fossil fuel\n",
      "│   │   └── nitrogen deposition\n",
      "│   │       └── heavy metal\n",
      "│   │           └── phosphorus\n",
      "│   └── soil\n",
      "│       ├── irrigated agriculture\n",
      "│       ├── soil organic\n",
      "│       └── wastewater\n",
      "│           └── groundwater\n",
      "├── ecosystem\n",
      "│   ├── climate\n",
      "│   ├── crucial ecosystem\n",
      "│   ├── marine environment\n",
      "│   ├── terrestrial ecosystems\n",
      "│   └── wetland\n",
      "└── renewable energy\n",
      "    ├── biomass\n",
      "    │   └── biofuels\n",
      "    │       └── bioenergy crops\n",
      "    └── solar energy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the tree\n",
    "hierarchical_tagger.fit_tag_tree( term_similarity_threshold = 0.9)\n",
    "hierarchical_tagger.tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cc2d4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = hierarchical_tagger.tree.save2file(\"downloads/matsci_tree_188k_90%sim.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8bb91725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/sparse/compressed.py:290: SparseEfficiencyWarning: Comparing a sparse matrix with a scalar greater than zero using <= is inefficient, try using > instead.\n",
      "  warn(bad_scalar_msg, SparseEfficiencyWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/sparse/_index.py:124: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# The final step is tagging the original documents based on the hierarchy we found in the tree\n",
    "hierarchical_tagger.tag_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "11670652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final step is tagging the original documents based on the hierarchy we found in the tree\n",
    "# hierarchical_tagger.document_tags['10.1021/acsomega.0c00729']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f953732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_topics = list(set(flatten([t for t in hierarchical_tagger.processed_document_terms.values()])))\n",
    "#Apparently these are not the topics that end up in the tree\n",
    "tree_dict = hierarchical_tagger.tree.to_dict()\n",
    "j = hierarchical_tagger.tree.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7a622f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('downloads/matscitree.json', 'w') as f:\n",
    "#     json.dump(json.dumps(tree_dict), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "64077c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "environmental problems": {
        "children": [
         "anaerobic",
         {
          "carbon soil": {
           "children": [
            {
             "pollution": {
              "children": [
               {
                "carbon dioxide": {
                 "children": [
                  {
                   "carbon sequestration": {
                    "children": [
                     "emission greenhouse"
                    ]
                   }
                  },
                  "fossil fuel"
                 ]
                }
               },
               {
                "nitrogen deposition": {
                 "children": [
                  {
                   "heavy metal": {
                    "children": [
                     "phosphorus"
                    ]
                   }
                  }
                 ]
                }
               }
              ]
             }
            },
            {
             "soil": {
              "children": [
               "irrigated agriculture",
               "soil organic",
               {
                "wastewater": {
                 "children": [
                  "groundwater"
                 ]
                }
               }
              ]
             }
            }
           ]
          }
         },
         {
          "ecosystem": {
           "children": [
            "climate",
            "crucial ecosystem",
            "marine environment",
            "terrestrial ecosystems",
            "wetland"
           ]
          }
         },
         {
          "renewable energy": {
           "children": [
            {
             "biomass": {
              "children": [
               {
                "biofuels": {
                 "children": [
                  "bioenergy crops"
                 ]
                }
               }
              ]
             }
            },
            "solar energy"
           ]
          }
         }
        ]
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 210,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(tree_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cc93729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_tree(tree, memory=[]):\n",
    "    for k, v in tree.items():\n",
    "        memory += [k]\n",
    "        children=v.get(\"children\")\n",
    "        if children:\n",
    "            for c in children:\n",
    "                if isinstance(c, dict):\n",
    "                    traverse_tree(c, memory)\n",
    "                else:\n",
    "                    memory += [c]\n",
    "    return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3806ccb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_topics = traverse_tree(tree_dict, [])\n",
    "len(tree_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2d874059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "environmental problems": {
        "children": [
         "anaerobic",
         {
          "carbon soil": {
           "children": [
            {
             "pollution": {
              "children": [
               {
                "carbon dioxide": {
                 "children": [
                  {
                   "carbon sequestration": {
                    "children": [
                     "emission greenhouse"
                    ]
                   }
                  },
                  "fossil fuel"
                 ]
                }
               },
               {
                "nitrogen deposition": {
                 "children": [
                  {
                   "heavy metal": {
                    "children": [
                     "phosphorus"
                    ]
                   }
                  }
                 ]
                }
               }
              ]
             }
            },
            {
             "soil": {
              "children": [
               "irrigated agriculture",
               "soil organic",
               {
                "wastewater": {
                 "children": [
                  "groundwater"
                 ]
                }
               }
              ]
             }
            }
           ]
          }
         },
         {
          "ecosystem": {
           "children": [
            "climate",
            "crucial ecosystem",
            "marine environment",
            "terrestrial ecosystems",
            "wetland"
           ]
          }
         },
         {
          "renewable energy": {
           "children": [
            {
             "biomass": {
              "children": [
               {
                "biofuels": {
                 "children": [
                  "bioenergy crops"
                 ]
                }
               }
              ]
             }
            },
            "solar energy"
           ]
          }
         }
        ]
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 213,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(tree_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9302baf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"involves adhesion\" in tree_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ad73aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"downloads/loc_topics.json\") as f:\n",
    "    loc = json.loads(f.read())\n",
    "    #print(data['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "68392280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_items(dictionary, parent_key):\n",
    "    for key, value in dictionary.items():\n",
    "        if type(value) is dict:\n",
    "#             yield (key, value)\n",
    "            yield from recursive_items(value, key)\n",
    "        else:\n",
    "            yield (parent_key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a4773f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = recursive_items(loc, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "88254d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_flat = dict(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b8661009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6525"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loc_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02f4c0",
   "metadata": {},
   "source": [
    "### Topics < > LOC merge trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c8512772",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_topics = list(loc_flat.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d3d3dba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode the corpus of 6525... get a coffee in the meantime\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5497f8517f4563abd397e4d167460b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Encode the corpus of {}... get a coffee in the meantime\".format(len(loc_topics)))\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "loc_embs = model.encode(loc_topics, batch_size=64, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f2568e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode the corpus of 27... get a coffee in the meantime\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d72e2ec525484ba7168c76c7d76a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Encode the corpus of {}... get a coffee in the meantime\".format(len(tree_topics)))\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = model.encode(tree_topics, batch_size=64, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5262e637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "99f6c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# d = emb.shape[1]\n",
    "# emb.shape, len(df)\n",
    "# #np.array(df[\"emb\"][1])[:].shape\n",
    "# x = [list(e) for e in emb ]\n",
    "# #df[\"emb\"] = x\n",
    "\n",
    "\n",
    "def create_index(vectors):\n",
    "    vectors = vectors.cpu()\n",
    "    vectors = vectors.numpy()\n",
    "    faiss_index = faiss.IndexFlatL2(len(vectors[0]))\n",
    "    faiss_index.add(vectors)\n",
    "\n",
    "#     print(faiss_index.ntotal)\n",
    "\n",
    "    return faiss_index\n",
    "\n",
    "#export\n",
    "def query_index(text, embedder, target_list, index, with_distance=False, k=10):\n",
    "    embedding = embedder.encode([text])\n",
    "    distances, indices = index.search(embedding, k)\n",
    "    \n",
    "    if with_distance:\n",
    "        #I have no clue why this is double\n",
    "        q = list(set([(target_list[index], distances[0][i]) for i, index in enumerate(indices[0])]))\n",
    "        q.sort(key=lambda x: x[1])\n",
    "        return q\n",
    "    \n",
    "    return list(set([target_list[i] for i in indices[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b7dca886",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = create_index(embeddings)\n",
    "loc_index = create_index(loc_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "92b07580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('soil', 1.512198),\n",
       " ('carbon dioxide', 1.5227774),\n",
       " ('nitrogen deposition', 1.5446441),\n",
       " ('wastewater', 1.6180328),\n",
       " ('heavy metal', 1.6310098),\n",
       " ('phosphorus', 1.6425636),\n",
       " ('marine environment', 1.6485482),\n",
       " ('crucial ecosystem', 1.6501296),\n",
       " ('anaerobic', 1.660001),\n",
       " ('biofuels', 1.688984)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = query_index(\"involves adhesion\", model, tree_topics, index, True, 10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6c419fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hier = hierarchical_tagger.tree.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8cec7a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Biology (General)', 1.1429533),\n",
       " ('Microscopy', 1.1958425),\n",
       " ('Technique and materials', 1.228881)]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = query_index('involves adhesion', model, loc_topics, loc_index, True, 3)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4cfe8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_loc(term):\n",
    "    q = query_index(term, model, loc_topics, loc_index, True, 3)\n",
    "    new_term= q[0][0]\n",
    "    prob=q[0][1]\n",
    "\n",
    "    prob = str(q[0][1])[:4]\n",
    "    return \"{}:{} |{}\".format(term, new_term, prob)\n",
    "\n",
    "\n",
    "def to_loc_tuple(term):\n",
    "    q = query_index(term, model, loc_topics, loc_index, True, 3)\n",
    "    new_term= q[0][0]\n",
    "    prob=q[0][1]\n",
    "\n",
    "    # prob = str(q[0][1])[:4]\n",
    "#   \"{}:{} |{}\".format(term, q[0][0], prob)\n",
    "    return (new_term, prob)\n",
    "\n",
    "\n",
    "#      if children:\n",
    "#             for c in children:\n",
    "#                 if isinstance(c, dict):\n",
    "#                     v[\"children\"] += traverse_t(c,T,k_new)\n",
    "#                 else:\n",
    "#                     v[\"children\"] += to_loc(c)\n",
    "\n",
    "# def enrich_topic(topic):\n",
    "#     d = {}\n",
    "#     loc_topic, prob = to_loc_tuple(k)\n",
    "        \n",
    "#     d[\"loc_topic\"] = loc_topic\n",
    "#     d[\"orig_topic\"] = k\n",
    "#     topic = k if prob > 0.58 else loc_topic\n",
    "#     d[\"topic\"] = topic\n",
    "#     d[\"prob\"] = prob\n",
    "#     d[\"parents\"] = parents\n",
    "#     return d\n",
    "    \n",
    "def traverse_t(tree, T, parent=None, parents=[], depth=0, used_topics=[]):\n",
    "    \"\"\"overwrites and builds a tree where every key is mapped into a new name\"\"\"\n",
    "    tree2 = copy.deepcopy(tree)\n",
    "    for k, v in tree2.items():\n",
    "        #old\n",
    "#         k_new = to_loc(k)\n",
    "        \n",
    "#         tree[k_new] = v\n",
    "        \n",
    "        #new\n",
    "        loc_topic, prob = to_loc_tuple(k)\n",
    "        \n",
    "        tree[\"loc_topic\"] = loc_topic\n",
    "        tree[\"orig_topic\"] = k\n",
    "        topic = loc_topic if depth < 4 and loc_topic not in used_topics else k\n",
    "        tree[\"topic\"] = topic\n",
    "        tree[\"prob\"] = float(prob)\n",
    "        tree[\"parents\"] = parents\n",
    "        children=v.get(\"children\") if isinstance(v, dict) else None\n",
    "        tree[\"children\"] = children\n",
    "        used_topics += [topic]\n",
    "        \n",
    "        del tree[k]\n",
    "        \n",
    "        \n",
    "        if parent:\n",
    "#             print(parent, topic)\n",
    "            T.create_node(topic, topic, parent=parent)\n",
    "            pass\n",
    "        else:\n",
    "            T.create_node(topic, topic) #root\n",
    "            pass\n",
    "#         del tree[k]\n",
    "        if children:\n",
    "            v[\"children\"] = []\n",
    "            for c in children:\n",
    "                if isinstance(c, dict) and not c.get(\"prob\"):\n",
    "#                     print(\"not leaf\")\n",
    "                    v[\"children\"] += [traverse_t(c,T,topic, parents+[topic], depth+1)]\n",
    "                else:\n",
    "                    if not isinstance(c, str):\n",
    "                        print(\"not string\")\n",
    "                    #old---\n",
    "            #                     leaf = to_loc(c)\n",
    "\n",
    "\n",
    "                    #new---\n",
    "                    leaf={}\n",
    "                    loc_l, prob_l = to_loc_tuple(c)\n",
    "\n",
    "            #                     print(leaf, \"leaf\")\n",
    "                    leaf[\"loc_topic\"] = loc_l\n",
    "                    leaf[\"orig_topic\"] = c\n",
    "                    topic_l = loc_l if depth < 4 and loc_l not in used_topics else c \n",
    "                    used_topics += [topic_l]\n",
    "                    leaf[\"topic\"] = topic_l\n",
    "                    leaf[\"prob\"] = float(prob_l)\n",
    "                    leaf[\"parents\"] = parents+[topic]\n",
    "\n",
    "                    if c == \"aortic valve\":\n",
    "                        print(\"found\", leaf,  v[\"children\"], c, \"value\", v, \"tree\", tree)\n",
    "\n",
    "                    #---\n",
    "                    T.create_node(topic_l, topic_l, topic)\n",
    "\n",
    "                    \n",
    "                    v[\"children\"] += [leaf]\n",
    "        \n",
    "#         print(tree, \"tre\", tree2, \"tree2\", \"VAAL___\", v[\"children\"])\n",
    "        tree[\"children\"] = v[\"children\"]\n",
    "        \n",
    "#             tree[\"children\"] = tree2[\"children\"]\n",
    "    return tree            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "39cd936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from treelib import Tree\n",
    "treelib = Tree()\n",
    "\n",
    "hh = copy.deepcopy(tree_dict)\n",
    "ff = traverse_t(hh, treelib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "160d70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON(hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "cae03566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "children": [
        {
         "loc_topic": "Bacteria",
         "orig_topic": "anaerobic",
         "parents": [
          "Environmental pollution"
         ],
         "prob": 1.0656403303146362,
         "topic": "Bacteria"
        },
        {
         "children": [
          {
           "children": [
            {
             "children": [
              {
               "children": [
                {
                 "loc_topic": "Greenhouses and greenhouse culture",
                 "orig_topic": "emission greenhouse",
                 "parents": [
                  "Environmental pollution",
                  "Forest soils",
                  "pollution",
                  "Fuel",
                  "carbon sequestration"
                 ],
                 "prob": 0.810844361782074,
                 "topic": "emission greenhouse"
                }
               ],
               "loc_topic": "Environmental sciences",
               "orig_topic": "carbon sequestration",
               "parents": [
                "Environmental pollution",
                "Forest soils",
                "pollution",
                "Fuel"
               ],
               "prob": 1.1157931089401245,
               "topic": "carbon sequestration"
              },
              {
               "loc_topic": "Fuel",
               "orig_topic": "fossil fuel",
               "parents": [
                "Environmental pollution",
                "Forest soils",
                "pollution",
                "Fuel"
               ],
               "prob": 0.6606592535972595,
               "topic": "fossil fuel"
              }
             ],
             "loc_topic": "Fuel",
             "orig_topic": "carbon dioxide",
             "parents": [
              "Environmental pollution",
              "Forest soils",
              "pollution"
             ],
             "prob": 1.0719544887542725,
             "topic": "Fuel"
            },
            {
             "children": [
              {
               "children": [
                {
                 "loc_topic": "Chemistry",
                 "orig_topic": "phosphorus",
                 "parents": [
                  "Environmental pollution",
                  "Forest soils",
                  "pollution",
                  "Niger",
                  "heavy metal"
                 ],
                 "prob": 0.8710346221923828,
                 "topic": "phosphorus"
                }
               ],
               "loc_topic": "Popular music",
               "orig_topic": "heavy metal",
               "parents": [
                "Environmental pollution",
                "Forest soils",
                "pollution",
                "Niger"
               ],
               "prob": 0.7980169653892517,
               "topic": "heavy metal"
              }
             ],
             "loc_topic": "Niger",
             "orig_topic": "nitrogen deposition",
             "parents": [
              "Environmental pollution",
              "Forest soils",
              "pollution"
             ],
             "prob": 1.2563414573669434,
             "topic": "Niger"
            }
           ],
           "loc_topic": "Environmental pollution",
           "orig_topic": "pollution",
           "parents": [
            "Environmental pollution",
            "Forest soils"
           ],
           "prob": 0.24492231011390686,
           "topic": "pollution"
          },
          {
           "children": [
            {
             "loc_topic": "Irrigation farming",
             "orig_topic": "irrigated agriculture",
             "parents": [
              "Environmental pollution",
              "Forest soils",
              "soil"
             ],
             "prob": 0.35861605405807495,
             "topic": "Irrigation farming"
            },
            {
             "loc_topic": "Organic farming. Organiculture",
             "orig_topic": "soil organic",
             "parents": [
              "Environmental pollution",
              "Forest soils",
              "soil"
             ],
             "prob": 0.6401776075363159,
             "topic": "Organic farming. Organiculture"
            },
            {
             "children": [
              {
               "loc_topic": "Groundwater. Hydrogeology",
               "orig_topic": "groundwater",
               "parents": [
                "Environmental pollution",
                "Forest soils",
                "soil",
                "Sewage collection and disposal systems. Sewerage"
               ],
               "prob": 0.37150031328201294,
               "topic": "Groundwater. Hydrogeology"
              }
             ],
             "loc_topic": "Sewage collection and disposal systems. Sewerage",
             "orig_topic": "wastewater",
             "parents": [
              "Environmental pollution",
              "Forest soils",
              "soil"
             ],
             "prob": 0.7426323890686035,
             "topic": "Sewage collection and disposal systems. Sewerage"
            }
           ],
           "loc_topic": "Forest soils",
           "orig_topic": "soil",
           "parents": [
            "Environmental pollution",
            "Forest soils"
           ],
           "prob": 0.5988481044769287,
           "topic": "soil"
          }
         ],
         "loc_topic": "Forest soils",
         "orig_topic": "carbon soil",
         "parents": [
          "Environmental pollution"
         ],
         "prob": 0.6724587082862854,
         "topic": "Forest soils"
        },
        {
         "children": [
          {
           "loc_topic": "Geography",
           "orig_topic": "climate",
           "parents": [
            "Environmental pollution",
            "Ecology"
           ],
           "prob": 0.6568068861961365,
           "topic": "Geography"
          },
          {
           "loc_topic": "Ecology",
           "orig_topic": "crucial ecosystem",
           "parents": [
            "Environmental pollution",
            "Ecology"
           ],
           "prob": 0.7928881049156189,
           "topic": "crucial ecosystem"
          },
          {
           "loc_topic": "Marine resources. Applied oceanography",
           "orig_topic": "marine environment",
           "parents": [
            "Environmental pollution",
            "Ecology"
           ],
           "prob": 0.5810338258743286,
           "topic": "Marine resources. Applied oceanography"
          },
          {
           "loc_topic": "Ecology",
           "orig_topic": "terrestrial ecosystems",
           "parents": [
            "Environmental pollution",
            "Ecology"
           ],
           "prob": 0.6445196866989136,
           "topic": "terrestrial ecosystems"
          },
          {
           "loc_topic": "Waterways",
           "orig_topic": "wetland",
           "parents": [
            "Environmental pollution",
            "Ecology"
           ],
           "prob": 0.7524715662002563,
           "topic": "Waterways"
          }
         ],
         "loc_topic": "Ecology",
         "orig_topic": "ecosystem",
         "parents": [
          "Environmental pollution"
         ],
         "prob": 0.39733612537384033,
         "topic": "Ecology"
        },
        {
         "children": [
          {
           "children": [
            {
             "children": [
              {
               "loc_topic": "Food crops",
               "orig_topic": "bioenergy crops",
               "parents": [
                "Environmental pollution",
                "Renewable energy sources",
                "biomass",
                "biofuels"
               ],
               "prob": 0.6823639869689941,
               "topic": "Food crops"
              }
             ],
             "loc_topic": "Renewable energy sources",
             "orig_topic": "biofuels",
             "parents": [
              "Environmental pollution",
              "Renewable energy sources",
              "biomass"
             ],
             "prob": 0.7516376972198486,
             "topic": "biofuels"
            }
           ],
           "loc_topic": "Fuel",
           "orig_topic": "biomass",
           "parents": [
            "Environmental pollution",
            "Renewable energy sources"
           ],
           "prob": 0.9424852132797241,
           "topic": "biomass"
          },
          {
           "loc_topic": "Renewable energy sources",
           "orig_topic": "solar energy",
           "parents": [
            "Environmental pollution",
            "Renewable energy sources"
           ],
           "prob": 0.5150365829467773,
           "topic": "solar energy"
          }
         ],
         "loc_topic": "Renewable energy sources",
         "orig_topic": "renewable energy",
         "parents": [
          "Environmental pollution"
         ],
         "prob": 0.23242580890655518,
         "topic": "Renewable energy sources"
        }
       ],
       "loc_topic": "Environmental pollution",
       "orig_topic": "environmental problems",
       "parents": [],
       "prob": 0.5144727230072021,
       "topic": "Environmental pollution"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 232,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "fcf7db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(hier_path, 'w') as f:\n",
    "    json.dump(ff, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7616753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hier_path) as f:\n",
    "    mat_hier = json.load(f)\n",
    "    #print(data['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "960871f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environmental pollution\n",
      "╠══ Bacteria\n",
      "╠══ Ecology\n",
      "║   ╠══ Geography\n",
      "║   ╠══ Marine resources. Applied oceanography\n",
      "║   ╠══ Waterways\n",
      "║   ╠══ crucial ecosystem\n",
      "║   ╚══ terrestrial ecosystems\n",
      "╠══ Forest soils\n",
      "║   ╠══ pollution\n",
      "║   ║   ╠══ Fuel\n",
      "║   ║   ║   ╠══ carbon sequestration\n",
      "║   ║   ║   ║   ╚══ emission greenhouse\n",
      "║   ║   ║   ╚══ fossil fuel\n",
      "║   ║   ╚══ Niger\n",
      "║   ║       ╚══ heavy metal\n",
      "║   ║           ╚══ phosphorus\n",
      "║   ╚══ soil\n",
      "║       ╠══ Irrigation farming\n",
      "║       ╠══ Organic farming. Organiculture\n",
      "║       ╚══ Sewage collection and disposal systems. Sewerage\n",
      "║           ╚══ Groundwater. Hydrogeology\n",
      "╚══ Renewable energy sources\n",
      "    ╠══ biomass\n",
      "    ║   ╚══ biofuels\n",
      "    ║       ╚══ Food crops\n",
      "    ╚══ solar energy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "treelib.show(line_type=\"ascii-em\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e23ad928",
   "metadata": {},
   "outputs": [],
   "source": [
    "treelib.save2file(\"downloads/env_tree2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "143c1584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_tree(tree, memory=[]):\n",
    "    tree2 = copy.deepcopy(tree)\n",
    "    if tree2.get(\"children\"):\n",
    "        del tree2[\"children\"]\n",
    "    memory += [tree2]\n",
    "#     if isinstance(tree, str):\n",
    "#         print(tree, \"str\")\n",
    "    children=tree.get(\"children\")\n",
    "    if children:\n",
    "        for c in children:\n",
    "#             print(c)\n",
    "            memory+=flatten([flatten_tree(c, [])])\n",
    "# #             else:\n",
    "# #                 memory += [tree2]\n",
    "                \n",
    "    return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3b9066c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matsci_topics_flat = flatten_tree(mat_hier, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b83e8a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 27)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics), len(matsci_topics_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "74b2c095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": [
       {
        "loc_topic": "Environmental pollution",
        "orig_topic": "environmental problems",
        "parents": [],
        "prob": 0.5144727230072021,
        "topic": "Environmental pollution"
       },
       {
        "loc_topic": "Bacteria",
        "orig_topic": "anaerobic",
        "parents": [
         "Environmental pollution"
        ],
        "prob": 1.0656403303146362,
        "topic": "Bacteria"
       },
       {
        "loc_topic": "Forest soils",
        "orig_topic": "carbon soil",
        "parents": [
         "Environmental pollution"
        ],
        "prob": 0.6724587082862854,
        "topic": "Forest soils"
       },
       {
        "loc_topic": "Environmental pollution",
        "orig_topic": "pollution",
        "parents": [
         "Environmental pollution",
         "Forest soils"
        ],
        "prob": 0.24492231011390686,
        "topic": "pollution"
       },
       {
        "loc_topic": "Fuel",
        "orig_topic": "carbon dioxide",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution"
        ],
        "prob": 1.0719544887542725,
        "topic": "Fuel"
       },
       {
        "loc_topic": "Environmental sciences",
        "orig_topic": "carbon sequestration",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution",
         "Fuel"
        ],
        "prob": 1.1157931089401245,
        "topic": "carbon sequestration"
       },
       {
        "loc_topic": "Greenhouses and greenhouse culture",
        "orig_topic": "emission greenhouse",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution",
         "Fuel",
         "carbon sequestration"
        ],
        "prob": 0.810844361782074,
        "topic": "emission greenhouse"
       },
       {
        "loc_topic": "Fuel",
        "orig_topic": "fossil fuel",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution",
         "Fuel"
        ],
        "prob": 0.6606592535972595,
        "topic": "fossil fuel"
       },
       {
        "loc_topic": "Niger",
        "orig_topic": "nitrogen deposition",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution"
        ],
        "prob": 1.2563414573669434,
        "topic": "Niger"
       },
       {
        "loc_topic": "Popular music",
        "orig_topic": "heavy metal",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution",
         "Niger"
        ],
        "prob": 0.7980169653892517,
        "topic": "heavy metal"
       },
       {
        "loc_topic": "Chemistry",
        "orig_topic": "phosphorus",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution",
         "Niger",
         "heavy metal"
        ],
        "prob": 0.8710346221923828,
        "topic": "phosphorus"
       },
       {
        "loc_topic": "Forest soils",
        "orig_topic": "soil",
        "parents": [
         "Environmental pollution",
         "Forest soils"
        ],
        "prob": 0.5988481044769287,
        "topic": "soil"
       },
       {
        "loc_topic": "Irrigation farming",
        "orig_topic": "irrigated agriculture",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "soil"
        ],
        "prob": 0.35861605405807495,
        "topic": "Irrigation farming"
       },
       {
        "loc_topic": "Organic farming. Organiculture",
        "orig_topic": "soil organic",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "soil"
        ],
        "prob": 0.6401776075363159,
        "topic": "Organic farming. Organiculture"
       },
       {
        "loc_topic": "Sewage collection and disposal systems. Sewerage",
        "orig_topic": "wastewater",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "soil"
        ],
        "prob": 0.7426323890686035,
        "topic": "Sewage collection and disposal systems. Sewerage"
       },
       {
        "loc_topic": "Groundwater. Hydrogeology",
        "orig_topic": "groundwater",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "soil",
         "Sewage collection and disposal systems. Sewerage"
        ],
        "prob": 0.37150031328201294,
        "topic": "Groundwater. Hydrogeology"
       },
       {
        "loc_topic": "Ecology",
        "orig_topic": "ecosystem",
        "parents": [
         "Environmental pollution"
        ],
        "prob": 0.39733612537384033,
        "topic": "Ecology"
       },
       {
        "loc_topic": "Geography",
        "orig_topic": "climate",
        "parents": [
         "Environmental pollution",
         "Ecology"
        ],
        "prob": 0.6568068861961365,
        "topic": "Geography"
       },
       {
        "loc_topic": "Ecology",
        "orig_topic": "crucial ecosystem",
        "parents": [
         "Environmental pollution",
         "Ecology"
        ],
        "prob": 0.7928881049156189,
        "topic": "crucial ecosystem"
       },
       {
        "loc_topic": "Marine resources. Applied oceanography",
        "orig_topic": "marine environment",
        "parents": [
         "Environmental pollution",
         "Ecology"
        ],
        "prob": 0.5810338258743286,
        "topic": "Marine resources. Applied oceanography"
       },
       {
        "loc_topic": "Ecology",
        "orig_topic": "terrestrial ecosystems",
        "parents": [
         "Environmental pollution",
         "Ecology"
        ],
        "prob": 0.6445196866989136,
        "topic": "terrestrial ecosystems"
       },
       {
        "loc_topic": "Waterways",
        "orig_topic": "wetland",
        "parents": [
         "Environmental pollution",
         "Ecology"
        ],
        "prob": 0.7524715662002563,
        "topic": "Waterways"
       },
       {
        "loc_topic": "Renewable energy sources",
        "orig_topic": "renewable energy",
        "parents": [
         "Environmental pollution"
        ],
        "prob": 0.23242580890655518,
        "topic": "Renewable energy sources"
       },
       {
        "loc_topic": "Fuel",
        "orig_topic": "biomass",
        "parents": [
         "Environmental pollution",
         "Renewable energy sources"
        ],
        "prob": 0.9424852132797241,
        "topic": "biomass"
       },
       {
        "loc_topic": "Renewable energy sources",
        "orig_topic": "biofuels",
        "parents": [
         "Environmental pollution",
         "Renewable energy sources",
         "biomass"
        ],
        "prob": 0.7516376972198486,
        "topic": "biofuels"
       },
       {
        "loc_topic": "Food crops",
        "orig_topic": "bioenergy crops",
        "parents": [
         "Environmental pollution",
         "Renewable energy sources",
         "biomass",
         "biofuels"
        ],
        "prob": 0.6823639869689941,
        "topic": "Food crops"
       },
       {
        "loc_topic": "Renewable energy sources",
        "orig_topic": "solar energy",
        "parents": [
         "Environmental pollution",
         "Renewable energy sources"
        ],
        "prob": 0.5150365829467773,
        "topic": "solar energy"
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 240,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(matsci_topics_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1a23bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi2topic = {}\n",
    "\n",
    "for c in clusters:\n",
    "    doi = c[\"doi\"]\n",
    "    topics = hierarchical_tagger.document_tags[doi]\n",
    "    if len(topics) == 0:\n",
    "        #not LoC_topics because the hits could not be in final hiearchy\n",
    "        topics = query_index(hierarchical_tagger.document_attributes[doi][\"text\"], model, tree_topics, index, True, 3)\n",
    "    doi2topic[doi] = topics\n",
    "    \n",
    "#JSON(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7dbe0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi2onetopic = {}\n",
    "\n",
    "for k,v in doi2topic.items():\n",
    "    doi2onetopic[k] = v[0][0] if v else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "937e5b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9ec85703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": [
       {
        "loc_topic": "Environmental pollution",
        "orig_topic": "environmental problems",
        "parents": [],
        "prob": 0.5144727230072021,
        "topic": "Environmental pollution"
       },
       {
        "loc_topic": "Bacteria",
        "orig_topic": "anaerobic",
        "parents": [
         "Environmental pollution"
        ],
        "prob": 1.0656403303146362,
        "topic": "Bacteria"
       },
       {
        "loc_topic": "Forest soils",
        "orig_topic": "carbon soil",
        "parents": [
         "Environmental pollution"
        ],
        "prob": 0.6724587082862854,
        "topic": "Forest soils"
       },
       {
        "loc_topic": "Environmental pollution",
        "orig_topic": "pollution",
        "parents": [
         "Environmental pollution",
         "Forest soils"
        ],
        "prob": 0.24492231011390686,
        "topic": "pollution"
       },
       {
        "loc_topic": "Fuel",
        "orig_topic": "carbon dioxide",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution"
        ],
        "prob": 1.0719544887542725,
        "topic": "Fuel"
       },
       {
        "loc_topic": "Environmental sciences",
        "orig_topic": "carbon sequestration",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution",
         "Fuel"
        ],
        "prob": 1.1157931089401245,
        "topic": "carbon sequestration"
       },
       {
        "loc_topic": "Greenhouses and greenhouse culture",
        "orig_topic": "emission greenhouse",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution",
         "Fuel",
         "carbon sequestration"
        ],
        "prob": 0.810844361782074,
        "topic": "emission greenhouse"
       },
       {
        "loc_topic": "Fuel",
        "orig_topic": "fossil fuel",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution",
         "Fuel"
        ],
        "prob": 0.6606592535972595,
        "topic": "fossil fuel"
       },
       {
        "loc_topic": "Niger",
        "orig_topic": "nitrogen deposition",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution"
        ],
        "prob": 1.2563414573669434,
        "topic": "Niger"
       },
       {
        "loc_topic": "Popular music",
        "orig_topic": "heavy metal",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution",
         "Niger"
        ],
        "prob": 0.7980169653892517,
        "topic": "heavy metal"
       },
       {
        "loc_topic": "Chemistry",
        "orig_topic": "phosphorus",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "pollution",
         "Niger",
         "heavy metal"
        ],
        "prob": 0.8710346221923828,
        "topic": "phosphorus"
       },
       {
        "loc_topic": "Forest soils",
        "orig_topic": "soil",
        "parents": [
         "Environmental pollution",
         "Forest soils"
        ],
        "prob": 0.5988481044769287,
        "topic": "soil"
       },
       {
        "loc_topic": "Irrigation farming",
        "orig_topic": "irrigated agriculture",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "soil"
        ],
        "prob": 0.35861605405807495,
        "topic": "Irrigation farming"
       },
       {
        "loc_topic": "Organic farming. Organiculture",
        "orig_topic": "soil organic",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "soil"
        ],
        "prob": 0.6401776075363159,
        "topic": "Organic farming. Organiculture"
       },
       {
        "loc_topic": "Sewage collection and disposal systems. Sewerage",
        "orig_topic": "wastewater",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "soil"
        ],
        "prob": 0.7426323890686035,
        "topic": "Sewage collection and disposal systems. Sewerage"
       },
       {
        "loc_topic": "Groundwater. Hydrogeology",
        "orig_topic": "groundwater",
        "parents": [
         "Environmental pollution",
         "Forest soils",
         "soil",
         "Sewage collection and disposal systems. Sewerage"
        ],
        "prob": 0.37150031328201294,
        "topic": "Groundwater. Hydrogeology"
       },
       {
        "loc_topic": "Ecology",
        "orig_topic": "ecosystem",
        "parents": [
         "Environmental pollution"
        ],
        "prob": 0.39733612537384033,
        "topic": "Ecology"
       },
       {
        "loc_topic": "Geography",
        "orig_topic": "climate",
        "parents": [
         "Environmental pollution",
         "Ecology"
        ],
        "prob": 0.6568068861961365,
        "topic": "Geography"
       },
       {
        "loc_topic": "Ecology",
        "orig_topic": "crucial ecosystem",
        "parents": [
         "Environmental pollution",
         "Ecology"
        ],
        "prob": 0.7928881049156189,
        "topic": "crucial ecosystem"
       },
       {
        "loc_topic": "Marine resources. Applied oceanography",
        "orig_topic": "marine environment",
        "parents": [
         "Environmental pollution",
         "Ecology"
        ],
        "prob": 0.5810338258743286,
        "topic": "Marine resources. Applied oceanography"
       },
       {
        "loc_topic": "Ecology",
        "orig_topic": "terrestrial ecosystems",
        "parents": [
         "Environmental pollution",
         "Ecology"
        ],
        "prob": 0.6445196866989136,
        "topic": "terrestrial ecosystems"
       },
       {
        "loc_topic": "Waterways",
        "orig_topic": "wetland",
        "parents": [
         "Environmental pollution",
         "Ecology"
        ],
        "prob": 0.7524715662002563,
        "topic": "Waterways"
       },
       {
        "loc_topic": "Renewable energy sources",
        "orig_topic": "renewable energy",
        "parents": [
         "Environmental pollution"
        ],
        "prob": 0.23242580890655518,
        "topic": "Renewable energy sources"
       },
       {
        "loc_topic": "Fuel",
        "orig_topic": "biomass",
        "parents": [
         "Environmental pollution",
         "Renewable energy sources"
        ],
        "prob": 0.9424852132797241,
        "topic": "biomass"
       },
       {
        "loc_topic": "Renewable energy sources",
        "orig_topic": "biofuels",
        "parents": [
         "Environmental pollution",
         "Renewable energy sources",
         "biomass"
        ],
        "prob": 0.7516376972198486,
        "topic": "biofuels"
       },
       {
        "loc_topic": "Food crops",
        "orig_topic": "bioenergy crops",
        "parents": [
         "Environmental pollution",
         "Renewable energy sources",
         "biomass",
         "biofuels"
        ],
        "prob": 0.6823639869689941,
        "topic": "Food crops"
       },
       {
        "loc_topic": "Renewable energy sources",
        "orig_topic": "solar energy",
        "parents": [
         "Environmental pollution",
         "Renewable energy sources"
        ],
        "prob": 0.5150365829467773,
        "topic": "solar energy"
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 244,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(matsci_topics_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c36b6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matsci_topic_dict = {}\n",
    "\n",
    "# for d in matsci_topics_flat:\n",
    "#     matsci_topic_dict[d[\"doi\"]] = d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5365e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dict = df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a14c7b24",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-a0541e092db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoi2onetopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m734\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "len(doi2onetopic.keys()), df.iloc[734][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "db3e6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_cluster_for_doi(doi, clusters):\n",
    "    clus = None\n",
    "    for c in clusters:\n",
    "        for child in c.get(\"children\"):\n",
    "            if doi == child[\"doi\"]:\n",
    "                clus = c #return last cluster that fits \n",
    "        #TODO: might have multiple DOIs\n",
    "    if clus and clus[\"doi\"] == doi:\n",
    "        return None\n",
    "    return clus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ddc60290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_parent_cluster_for_doi(\"10.1016/J.JOULE.2017.12.001\", clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "553191a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"downloads/matsci_188k_june24.csv\")#.sample(frac=0.6)\n",
    "cluster_dois = [c[\"doi\"] for c in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a61e6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"doi\"])\n",
    "df = df.drop_duplicates(subset=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "80f56d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>parent_problem</th>\n",
       "      <th>doi</th>\n",
       "      <th>fields</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>environmental problems</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thermal groundwater is of great economic and s...</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>10.1007/s12517-021-06632-3</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1007/S11269-010-9654-4, 10.1111/J.1747-659...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>Methane contributes substantially to global wa...</td>\n",
       "      <td>emission greenhouse</td>\n",
       "      <td>10.7892/BORIS.108871</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1023/A:1021175404418, 10.1080/03680770.200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>observations are critical in the validation of...</td>\n",
       "      <td>terrestrial ecosystems</td>\n",
       "      <td>10.1002/vzj2.20033</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.5194/egusphere-egu2020-9782, 10.3390/s1608...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Infiltration based stormwater best management ...</td>\n",
       "      <td>wastewater</td>\n",
       "      <td>10.5897/IJWREE2019.0856</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1016/S0273-1223(99)00328-5, 10.2166/wst.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Frequent escalations in fuel costs, environmen...</td>\n",
       "      <td>With the increasing penetration of wind power,...</td>\n",
       "      <td>10.17159/2413-3051/2020/V31I1A7008</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1109/TPEL.2018.2865710, 10.1016/J.APENERGY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Transformations of plant-derived carbon into s...</td>\n",
       "      <td>Improving current understanding of the factors...</td>\n",
       "      <td>10.1016/J.SOILBIO.2013.11.012</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1007/s10021-016-9977-y, 10.1021/es404352h,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>proper understanding of variability of soil ch...</td>\n",
       "      <td>Soil and topography are widely recognized as i...</td>\n",
       "      <td>10.12944/CARJ.6.3.12</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1016/0341-8162(96)00016-1, 10.3390/land101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Groundwater is a precious natural water resour...</td>\n",
       "      <td>Assessment of water resources at a national sc...</td>\n",
       "      <td>10.4038/JAS.V10I1.8044</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1111/1752-1688.12520, 10.1108/S2040-7262(2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>Natural groundwater droughts originate from re...</td>\n",
       "      <td>Droughts have caused many damages in many coun...</td>\n",
       "      <td>10.1007/978-94-015-9472-1_4</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1007/s11069-020-04394-x, 10.1007/s11069-01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0                                environmental problems   \n",
       "2     Thermal groundwater is of great economic and s...   \n",
       "1050  Methane contributes substantially to global wa...   \n",
       "1066  observations are critical in the validation of...   \n",
       "1086  Infiltration based stormwater best management ...   \n",
       "...                                                 ...   \n",
       "213   Frequent escalations in fuel costs, environmen...   \n",
       "170   Transformations of plant-derived carbon into s...   \n",
       "361   proper understanding of variability of soil ch...   \n",
       "451   Groundwater is a precious natural water resour...   \n",
       "2243  Natural groundwater droughts originate from re...   \n",
       "\n",
       "                                         parent_problem  \\\n",
       "0                                                  None   \n",
       "2                                           groundwater   \n",
       "1050                                emission greenhouse   \n",
       "1066                             terrestrial ecosystems   \n",
       "1086                                         wastewater   \n",
       "...                                                 ...   \n",
       "213   With the increasing penetration of wind power,...   \n",
       "170   Improving current understanding of the factors...   \n",
       "361   Soil and topography are widely recognized as i...   \n",
       "451   Assessment of water resources at a national sc...   \n",
       "2243  Droughts have caused many damages in many coun...   \n",
       "\n",
       "                                     doi                 fields  \\\n",
       "0                                    NaN               Medicine   \n",
       "2             10.1007/s12517-021-06632-3  Environmental Science   \n",
       "1050                10.7892/BORIS.108871  Environmental Science   \n",
       "1066                  10.1002/vzj2.20033  Environmental Science   \n",
       "1086             10.5897/IJWREE2019.0856  Environmental Science   \n",
       "...                                  ...                    ...   \n",
       "213   10.17159/2413-3051/2020/V31I1A7008  Environmental Science   \n",
       "170        10.1016/J.SOILBIO.2013.11.012  Environmental Science   \n",
       "361                 10.12944/CARJ.6.3.12  Environmental Science   \n",
       "451               10.4038/JAS.V10I1.8044  Environmental Science   \n",
       "2243         10.1007/978-94-015-9472-1_4  Environmental Science   \n",
       "\n",
       "                                             references  \n",
       "0                                                   NaN  \n",
       "2     [10.1007/S11269-010-9654-4, 10.1111/J.1747-659...  \n",
       "1050  [10.1023/A:1021175404418, 10.1080/03680770.200...  \n",
       "1066  [10.5194/egusphere-egu2020-9782, 10.3390/s1608...  \n",
       "1086  [10.1016/S0273-1223(99)00328-5, 10.2166/wst.20...  \n",
       "...                                                 ...  \n",
       "213   [10.1109/TPEL.2018.2865710, 10.1016/J.APENERGY...  \n",
       "170   [10.1007/s10021-016-9977-y, 10.1021/es404352h,...  \n",
       "361   [10.1016/0341-8162(96)00016-1, 10.3390/land101...  \n",
       "451   [10.1111/1752-1688.12520, 10.1108/S2040-7262(2...  \n",
       "2243  [10.1007/s11069-020-04394-x, 10.1007/s11069-01...  \n",
       "\n",
       "[265 rows x 5 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "4f8e53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.doi.isin(cluster_dois)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "244c8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_child_dois(clusterdoi, clusters=clusters):\n",
    "    for c in clusters:\n",
    "        if c[\"doi\"] == clusterdoi:\n",
    "            return [child[\"doi\"] for child in c[\"children\"]]\n",
    "\n",
    "get_child_dois(\"10.32474/AOICS.2020.04.000193\", clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ec83305b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_topic</th>\n",
       "      <th>orig_topic</th>\n",
       "      <th>topic</th>\n",
       "      <th>prob</th>\n",
       "      <th>parents</th>\n",
       "      <th>parent_problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Environmental pollution</td>\n",
       "      <td>environmental problems</td>\n",
       "      <td>Environmental pollution</td>\n",
       "      <td>0.514473</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bacteria</td>\n",
       "      <td>anaerobic</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>1.065640</td>\n",
       "      <td>[Environmental pollution]</td>\n",
       "      <td>Environmental pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest soils</td>\n",
       "      <td>carbon soil</td>\n",
       "      <td>Forest soils</td>\n",
       "      <td>0.672459</td>\n",
       "      <td>[Environmental pollution]</td>\n",
       "      <td>Environmental pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Environmental pollution</td>\n",
       "      <td>pollution</td>\n",
       "      <td>pollution</td>\n",
       "      <td>0.244922</td>\n",
       "      <td>[Environmental pollution, Forest soils]</td>\n",
       "      <td>Forest soils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuel</td>\n",
       "      <td>carbon dioxide</td>\n",
       "      <td>Fuel</td>\n",
       "      <td>1.071954</td>\n",
       "      <td>[Environmental pollution, Forest soils, pollut...</td>\n",
       "      <td>pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Environmental sciences</td>\n",
       "      <td>carbon sequestration</td>\n",
       "      <td>carbon sequestration</td>\n",
       "      <td>1.115793</td>\n",
       "      <td>[Environmental pollution, Forest soils, pollut...</td>\n",
       "      <td>Fuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Greenhouses and greenhouse culture</td>\n",
       "      <td>emission greenhouse</td>\n",
       "      <td>emission greenhouse</td>\n",
       "      <td>0.810844</td>\n",
       "      <td>[Environmental pollution, Forest soils, pollut...</td>\n",
       "      <td>carbon sequestration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fuel</td>\n",
       "      <td>fossil fuel</td>\n",
       "      <td>fossil fuel</td>\n",
       "      <td>0.660659</td>\n",
       "      <td>[Environmental pollution, Forest soils, pollut...</td>\n",
       "      <td>Fuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Niger</td>\n",
       "      <td>nitrogen deposition</td>\n",
       "      <td>Niger</td>\n",
       "      <td>1.256341</td>\n",
       "      <td>[Environmental pollution, Forest soils, pollut...</td>\n",
       "      <td>pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Popular music</td>\n",
       "      <td>heavy metal</td>\n",
       "      <td>heavy metal</td>\n",
       "      <td>0.798017</td>\n",
       "      <td>[Environmental pollution, Forest soils, pollut...</td>\n",
       "      <td>Niger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chemistry</td>\n",
       "      <td>phosphorus</td>\n",
       "      <td>phosphorus</td>\n",
       "      <td>0.871035</td>\n",
       "      <td>[Environmental pollution, Forest soils, pollut...</td>\n",
       "      <td>heavy metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Forest soils</td>\n",
       "      <td>soil</td>\n",
       "      <td>soil</td>\n",
       "      <td>0.598848</td>\n",
       "      <td>[Environmental pollution, Forest soils]</td>\n",
       "      <td>Forest soils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Irrigation farming</td>\n",
       "      <td>irrigated agriculture</td>\n",
       "      <td>Irrigation farming</td>\n",
       "      <td>0.358616</td>\n",
       "      <td>[Environmental pollution, Forest soils, soil]</td>\n",
       "      <td>soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Organic farming. Organiculture</td>\n",
       "      <td>soil organic</td>\n",
       "      <td>Organic farming. Organiculture</td>\n",
       "      <td>0.640178</td>\n",
       "      <td>[Environmental pollution, Forest soils, soil]</td>\n",
       "      <td>soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sewage collection and disposal systems. Sewerage</td>\n",
       "      <td>wastewater</td>\n",
       "      <td>Sewage collection and disposal systems. Sewerage</td>\n",
       "      <td>0.742632</td>\n",
       "      <td>[Environmental pollution, Forest soils, soil]</td>\n",
       "      <td>soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Groundwater. Hydrogeology</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>Groundwater. Hydrogeology</td>\n",
       "      <td>0.371500</td>\n",
       "      <td>[Environmental pollution, Forest soils, soil, ...</td>\n",
       "      <td>Sewage collection and disposal systems. Sewerage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ecology</td>\n",
       "      <td>ecosystem</td>\n",
       "      <td>Ecology</td>\n",
       "      <td>0.397336</td>\n",
       "      <td>[Environmental pollution]</td>\n",
       "      <td>Environmental pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Geography</td>\n",
       "      <td>climate</td>\n",
       "      <td>Geography</td>\n",
       "      <td>0.656807</td>\n",
       "      <td>[Environmental pollution, Ecology]</td>\n",
       "      <td>Ecology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ecology</td>\n",
       "      <td>crucial ecosystem</td>\n",
       "      <td>crucial ecosystem</td>\n",
       "      <td>0.792888</td>\n",
       "      <td>[Environmental pollution, Ecology]</td>\n",
       "      <td>Ecology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Marine resources. Applied oceanography</td>\n",
       "      <td>marine environment</td>\n",
       "      <td>Marine resources. Applied oceanography</td>\n",
       "      <td>0.581034</td>\n",
       "      <td>[Environmental pollution, Ecology]</td>\n",
       "      <td>Ecology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ecology</td>\n",
       "      <td>terrestrial ecosystems</td>\n",
       "      <td>terrestrial ecosystems</td>\n",
       "      <td>0.644520</td>\n",
       "      <td>[Environmental pollution, Ecology]</td>\n",
       "      <td>Ecology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Waterways</td>\n",
       "      <td>wetland</td>\n",
       "      <td>Waterways</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>[Environmental pollution, Ecology]</td>\n",
       "      <td>Ecology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Renewable energy sources</td>\n",
       "      <td>renewable energy</td>\n",
       "      <td>Renewable energy sources</td>\n",
       "      <td>0.232426</td>\n",
       "      <td>[Environmental pollution]</td>\n",
       "      <td>Environmental pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fuel</td>\n",
       "      <td>biomass</td>\n",
       "      <td>biomass</td>\n",
       "      <td>0.942485</td>\n",
       "      <td>[Environmental pollution, Renewable energy sou...</td>\n",
       "      <td>Renewable energy sources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Renewable energy sources</td>\n",
       "      <td>biofuels</td>\n",
       "      <td>biofuels</td>\n",
       "      <td>0.751638</td>\n",
       "      <td>[Environmental pollution, Renewable energy sou...</td>\n",
       "      <td>biomass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Food crops</td>\n",
       "      <td>bioenergy crops</td>\n",
       "      <td>Food crops</td>\n",
       "      <td>0.682364</td>\n",
       "      <td>[Environmental pollution, Renewable energy sou...</td>\n",
       "      <td>biofuels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Renewable energy sources</td>\n",
       "      <td>solar energy</td>\n",
       "      <td>solar energy</td>\n",
       "      <td>0.515037</td>\n",
       "      <td>[Environmental pollution, Renewable energy sou...</td>\n",
       "      <td>Renewable energy sources</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           loc_topic              orig_topic  \\\n",
       "0                            Environmental pollution  environmental problems   \n",
       "1                                           Bacteria               anaerobic   \n",
       "2                                       Forest soils             carbon soil   \n",
       "3                            Environmental pollution               pollution   \n",
       "4                                               Fuel          carbon dioxide   \n",
       "5                             Environmental sciences    carbon sequestration   \n",
       "6                 Greenhouses and greenhouse culture     emission greenhouse   \n",
       "7                                               Fuel             fossil fuel   \n",
       "8                                              Niger     nitrogen deposition   \n",
       "9                                      Popular music             heavy metal   \n",
       "10                                         Chemistry              phosphorus   \n",
       "11                                      Forest soils                    soil   \n",
       "12                                Irrigation farming   irrigated agriculture   \n",
       "13                    Organic farming. Organiculture            soil organic   \n",
       "14  Sewage collection and disposal systems. Sewerage              wastewater   \n",
       "15                         Groundwater. Hydrogeology             groundwater   \n",
       "16                                           Ecology               ecosystem   \n",
       "17                                         Geography                 climate   \n",
       "18                                           Ecology       crucial ecosystem   \n",
       "19            Marine resources. Applied oceanography      marine environment   \n",
       "20                                           Ecology  terrestrial ecosystems   \n",
       "21                                         Waterways                 wetland   \n",
       "22                          Renewable energy sources        renewable energy   \n",
       "23                                              Fuel                 biomass   \n",
       "24                          Renewable energy sources                biofuels   \n",
       "25                                        Food crops         bioenergy crops   \n",
       "26                          Renewable energy sources            solar energy   \n",
       "\n",
       "                                               topic      prob  \\\n",
       "0                            Environmental pollution  0.514473   \n",
       "1                                           Bacteria  1.065640   \n",
       "2                                       Forest soils  0.672459   \n",
       "3                                          pollution  0.244922   \n",
       "4                                               Fuel  1.071954   \n",
       "5                               carbon sequestration  1.115793   \n",
       "6                                emission greenhouse  0.810844   \n",
       "7                                        fossil fuel  0.660659   \n",
       "8                                              Niger  1.256341   \n",
       "9                                        heavy metal  0.798017   \n",
       "10                                        phosphorus  0.871035   \n",
       "11                                              soil  0.598848   \n",
       "12                                Irrigation farming  0.358616   \n",
       "13                    Organic farming. Organiculture  0.640178   \n",
       "14  Sewage collection and disposal systems. Sewerage  0.742632   \n",
       "15                         Groundwater. Hydrogeology  0.371500   \n",
       "16                                           Ecology  0.397336   \n",
       "17                                         Geography  0.656807   \n",
       "18                                 crucial ecosystem  0.792888   \n",
       "19            Marine resources. Applied oceanography  0.581034   \n",
       "20                            terrestrial ecosystems  0.644520   \n",
       "21                                         Waterways  0.752472   \n",
       "22                          Renewable energy sources  0.232426   \n",
       "23                                           biomass  0.942485   \n",
       "24                                          biofuels  0.751638   \n",
       "25                                        Food crops  0.682364   \n",
       "26                                      solar energy  0.515037   \n",
       "\n",
       "                                              parents  \\\n",
       "0                                                  []   \n",
       "1                           [Environmental pollution]   \n",
       "2                           [Environmental pollution]   \n",
       "3             [Environmental pollution, Forest soils]   \n",
       "4   [Environmental pollution, Forest soils, pollut...   \n",
       "5   [Environmental pollution, Forest soils, pollut...   \n",
       "6   [Environmental pollution, Forest soils, pollut...   \n",
       "7   [Environmental pollution, Forest soils, pollut...   \n",
       "8   [Environmental pollution, Forest soils, pollut...   \n",
       "9   [Environmental pollution, Forest soils, pollut...   \n",
       "10  [Environmental pollution, Forest soils, pollut...   \n",
       "11            [Environmental pollution, Forest soils]   \n",
       "12      [Environmental pollution, Forest soils, soil]   \n",
       "13      [Environmental pollution, Forest soils, soil]   \n",
       "14      [Environmental pollution, Forest soils, soil]   \n",
       "15  [Environmental pollution, Forest soils, soil, ...   \n",
       "16                          [Environmental pollution]   \n",
       "17                 [Environmental pollution, Ecology]   \n",
       "18                 [Environmental pollution, Ecology]   \n",
       "19                 [Environmental pollution, Ecology]   \n",
       "20                 [Environmental pollution, Ecology]   \n",
       "21                 [Environmental pollution, Ecology]   \n",
       "22                          [Environmental pollution]   \n",
       "23  [Environmental pollution, Renewable energy sou...   \n",
       "24  [Environmental pollution, Renewable energy sou...   \n",
       "25  [Environmental pollution, Renewable energy sou...   \n",
       "26  [Environmental pollution, Renewable energy sou...   \n",
       "\n",
       "                                      parent_problem  \n",
       "0                                               None  \n",
       "1                            Environmental pollution  \n",
       "2                            Environmental pollution  \n",
       "3                                       Forest soils  \n",
       "4                                          pollution  \n",
       "5                                               Fuel  \n",
       "6                               carbon sequestration  \n",
       "7                                               Fuel  \n",
       "8                                          pollution  \n",
       "9                                              Niger  \n",
       "10                                       heavy metal  \n",
       "11                                      Forest soils  \n",
       "12                                              soil  \n",
       "13                                              soil  \n",
       "14                                              soil  \n",
       "15  Sewage collection and disposal systems. Sewerage  \n",
       "16                           Environmental pollution  \n",
       "17                                           Ecology  \n",
       "18                                           Ecology  \n",
       "19                                           Ecology  \n",
       "20                                           Ecology  \n",
       "21                                           Ecology  \n",
       "22                           Environmental pollution  \n",
       "23                          Renewable energy sources  \n",
       "24                                           biomass  \n",
       "25                                          biofuels  \n",
       "26                          Renewable energy sources  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add matsci topic dict to dataframe\n",
    "for m in matsci_topics_flat:\n",
    "    parents = [*reversed(m[\"parents\"])]\n",
    "    m[\"parent_problem\"] = parents[0] if len(parents) > 0 else None\n",
    "topic_df = pd.DataFrame(data=matsci_topics_flat)\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f6b3ff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df[\"is_subcluster\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "aecb3aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    #if doi is not a main_cluster set first parent to it's cluster\n",
    "    \n",
    "    parent_cluster = get_parent_cluster_for_doi(row[\"doi\"], clusters)\n",
    "    \n",
    "    \n",
    "   \n",
    "    p_doi = parent_cluster[\"doi\"] if parent_cluster else row[\"doi\"]\n",
    "    \n",
    "    #get single topic\n",
    "    \n",
    "    topic = doi2onetopic.get(p_doi) #it will find topics even for child Dois\n",
    "    \n",
    "    if parent_cluster:\n",
    "        count += 1\n",
    "        topic= parent_cluster[\"text\"] \n",
    "        df.loc[index, \"is_subcluster\"] = True\n",
    "\n",
    "        \n",
    "        #if a subcluster links to a cluster as parent but that parent isn't in the dataframe (because of some filtering)\n",
    "        if len(df[df.text == topic]) == 0:\n",
    "            print(df[df.text == topic], topic)\n",
    "            break\n",
    "            print(\"killed\", df.text)\n",
    "#             df.loc[index, \"no_link\"] = True\n",
    "#         print(parent_cluster[\"doi\"])\n",
    "\n",
    "    if topic is None:\n",
    "        print(p_doi, row)\n",
    "        \n",
    "    df.loc[index, \"parent_problem\"] = topic\n",
    "\n",
    "    #get parents\n",
    "#         parent_topics = [parent_cluster[\"text\"]] if parent_cluster else []\n",
    "\n",
    "#     parent_topics += reversed(flatten([t[\"parents\"] for t in matsci_topics_flat if t[\"topic\"] == topic]))\n",
    "# #     print(len(parent_topics), parent_topics)\n",
    "# #     parent_topics = list(set(parent_topics))\n",
    "    \n",
    "#     for idx, p in enumerate(parent_topics):\n",
    "#         df.loc[index, \"parent_problem_\" + str(idx + 1)] = p\n",
    "#     if index%500 == 0:\n",
    "#         print(index)\n",
    "#     parent_topics=[]\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "4e2492d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df[\"references\"] = df.doi.map(get_child_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "674863cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df.fields = \"Biomedicine\"\n",
    "df = topic_df.rename(columns={\"topic\":\"text\"}).append(df.sort_values(by=['is_subcluster']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a8855653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.dropna(subset=[\"parent_problem\"])\n",
    "df = df[[\"text\", \"parent_problem\", \"doi\", \"fields\", \"references\"]] #predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cf124ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fields\"] = df[\"fields\"].map(lambda x: x if isinstance(x, str) else \"Medicine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ec7a782d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>parent_problem</th>\n",
       "      <th>doi</th>\n",
       "      <th>fields</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Environmental pollution</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Environmental pollution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest soils</td>\n",
       "      <td>Environmental pollution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pollution</td>\n",
       "      <td>Forest soils</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuel</td>\n",
       "      <td>pollution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Agriculture is a major driver of climate chang...</td>\n",
       "      <td>In arid and populated areas or countries, wate...</td>\n",
       "      <td>10.1007/s13593-014-0267-9</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.5772/28434, 10.1007/978-94-009-5494-6_26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Increasing urbanization rates, particularly in...</td>\n",
       "      <td>With growing population and urbanization, ther...</td>\n",
       "      <td>10.32933/ACTAINNOVATIONS.30.4</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1142/S1464333205002250, 10.1023/A:10066022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Groundwater is a precious natural water resour...</td>\n",
       "      <td>Assessment of water resources at a national sc...</td>\n",
       "      <td>10.4038/JAS.V10I1.8044</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1111/1752-1688.12520, 10.1108/S2040-7262(2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>This special issue of Applied Energy is focuse...</td>\n",
       "      <td>With the objectives of climate change mitigati...</td>\n",
       "      <td>10.1016/J.APENERGY.2011.04.038</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1021/EF700760B, 10.1007/S12649-018-0250-9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>Natural groundwater droughts originate from re...</td>\n",
       "      <td>Droughts have caused many damages in many coun...</td>\n",
       "      <td>10.1007/978-94-015-9472-1_4</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>[10.1007/s11069-020-04394-x, 10.1007/s11069-01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0                               Environmental pollution   \n",
       "1                                              Bacteria   \n",
       "2                                          Forest soils   \n",
       "3                                             pollution   \n",
       "4                                                  Fuel   \n",
       "...                                                 ...   \n",
       "636   Agriculture is a major driver of climate chang...   \n",
       "273   Increasing urbanization rates, particularly in...   \n",
       "451   Groundwater is a precious natural water resour...   \n",
       "1287  This special issue of Applied Energy is focuse...   \n",
       "2243  Natural groundwater droughts originate from re...   \n",
       "\n",
       "                                         parent_problem  \\\n",
       "0                                                  None   \n",
       "1                               Environmental pollution   \n",
       "2                               Environmental pollution   \n",
       "3                                          Forest soils   \n",
       "4                                             pollution   \n",
       "...                                                 ...   \n",
       "636   In arid and populated areas or countries, wate...   \n",
       "273   With growing population and urbanization, ther...   \n",
       "451   Assessment of water resources at a national sc...   \n",
       "1287  With the objectives of climate change mitigati...   \n",
       "2243  Droughts have caused many damages in many coun...   \n",
       "\n",
       "                                 doi                 fields  \\\n",
       "0                                NaN               Medicine   \n",
       "1                                NaN               Medicine   \n",
       "2                                NaN               Medicine   \n",
       "3                                NaN               Medicine   \n",
       "4                                NaN               Medicine   \n",
       "...                              ...                    ...   \n",
       "636        10.1007/s13593-014-0267-9  Environmental Science   \n",
       "273    10.32933/ACTAINNOVATIONS.30.4  Environmental Science   \n",
       "451           10.4038/JAS.V10I1.8044  Environmental Science   \n",
       "1287  10.1016/J.APENERGY.2011.04.038  Environmental Science   \n",
       "2243     10.1007/978-94-015-9472-1_4  Environmental Science   \n",
       "\n",
       "                                             references  \n",
       "0                                                   NaN  \n",
       "1                                                   NaN  \n",
       "2                                                   NaN  \n",
       "3                                                   NaN  \n",
       "4                                                   NaN  \n",
       "...                                                 ...  \n",
       "636   [10.5772/28434, 10.1007/978-94-009-5494-6_26, ...  \n",
       "273   [10.1142/S1464333205002250, 10.1023/A:10066022...  \n",
       "451   [10.1111/1752-1688.12520, 10.1108/S2040-7262(2...  \n",
       "1287  [10.1021/EF700760B, 10.1007/S12649-018-0250-9,...  \n",
       "2243  [10.1007/s11069-020-04394-x, 10.1007/s11069-01...  \n",
       "\n",
       "[291 rows x 5 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv (\"downloads/env_aug13.csv\", index = False, header=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0224794",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonable_doi = {}\n",
    "for k,v in doi2topic.items():\n",
    "    parsed = [(pair[0], float(pair[1])) for pair in v] \n",
    "    jsonable_doi[k] = parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f55181",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(jsonable_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('downloads/doi2topics_env.json', 'w') as f:\n",
    "    json.dump(jsonable_doi, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(matsci_topics_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2eb9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tree_topics), len(loc_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1fbea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install treelib scikit-network\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from dataclasses import dataclass, field\n",
    "from typing import AnyStr, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from sknetwork.clustering import Louvain\n",
    "from treelib import Tree\n",
    "\n",
    "\n",
    "def make_empty_array():\n",
    "    return np.ndarray([])\n",
    "\n",
    "\n",
    "def make_empty_csr_matrix():\n",
    "    return csr_matrix([])\n",
    "\n",
    "\n",
    "DataProperty = namedtuple(\n",
    "    \"DataProperty\", [\"n_terms\", \"n_occurrences\", \"core_terms\", \"term_set\", \"label\"]\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HierarchicalTagger:\n",
    "    \"\"\"\n",
    "    # Basic use:\n",
    "\n",
    "    Data must be dictionaries of the form:\n",
    "    {doc_id : [\"term_1\", \"term_2\", ...]}\n",
    "    DOCS  = {\"1\": [\"Burgers\", \"Vegetarian Diet\"],\n",
    "         \"2\": [\"Britney Spears\", \"Music\", \"Conservatorship\"]}\n",
    "\n",
    "    # Instantiate\n",
    "    hierarchical_tagger = HierarchicalTagger()\n",
    "\n",
    "    # Ingest documents\n",
    "    # Ingest can take time. See below for saving and reloading your object\n",
    "    hierarchical_tagger.ingest(document_terms=DOCS)\n",
    "\n",
    "    # Learn tag tree\n",
    "    hierarchical_tagger.fit_tag_tree()\n",
    "\n",
    "    # Inspect tag tree\n",
    "    hierarchical_tagger.tree.show()   # c.tree is a treelib Tree object\n",
    "\n",
    "    # Tag documents\n",
    "    hierarchical_tagger.tag_documents()\n",
    "\n",
    "    # Inspect document tags\n",
    "    hierarchical_tagger.document_tags # {doc_id : [(tag, score, approximate hierarchy level), ...]}\n",
    "\n",
    "    # Saving to JSON string\n",
    "    serialized = hierarchical_tagger.to_json()\n",
    "\n",
    "    # Loading from JSON string\n",
    "    hierarchical_tagger = HierarchicalTagger.from_json(\n",
    "        serialized,\n",
    "        hydrate_tree=True,\n",
    "        hydrate_tags=True\n",
    "    )\n",
    "\n",
    "    Advanced options:\n",
    "\n",
    "    # Upon document ingestion\n",
    "\n",
    "    term_suggestions: List[AnyStr] = A list of suggested terms to consider when building the tree\n",
    "\n",
    "    filter_geo_terms: bool = A boolean parameter to exclude geographical terms from the term set\n",
    "\n",
    "    document_attributes: Dict[AnyStr, Dict] = A dictionary storing additional arbitrary attributes about the documents.\n",
    "    Expected schema is {doc_id: {attribute_1_name: attribute_1_value, attribute_2_name: attribute_2_value, ... }.\n",
    "    This field is useful to store, for example, document title and text for use in later lookups or comparisons.\n",
    "    This field is also used in the webapp.\n",
    "\n",
    "    # Upon fitting tree\n",
    "\n",
    "    Additional terms can be suggested into the term set (note this can only be done on document\n",
    "    ingestion, see above). As the hierarchical clustering step takes account of the empirical\n",
    "    document frequency in the corpus, suggested terms must also be assigned an estimate/prior of\n",
    "    their likely document frequencies to help guide the breadth of the relevance of each term. In\n",
    "    some cases, it may be useful to estimate these document frequencies from a separate corpus.\n",
    "    -  term_suggestions_doc_freq: List[float] = A prior on doc frequency for terms in\n",
    "    term_suggestions\n",
    "\n",
    "    The user can provide a list of terms to exclude. These terms as well as their synonyms\n",
    "    (precisely, all terms falling into a cluster including a term on the excluion list, see next\n",
    "    paragraph) are removed from the cluster set.\n",
    "    -  term_exclusion_list: List[AnyStr] = A list of suggested terms to exclude when building the\n",
    "    tree. Synonyms are also dropped.\n",
    "\n",
    "    Similar terms are deduplicated using Louvain clustering on embeddings representing the term's\n",
    "    meanings.\n",
    "    -  term_similarity_threshold: float [0,1] = Controls the similarity threshold when constructing\n",
    "    the adjacency matrix for this clustering.\n",
    "\n",
    "    Terms in clusters whose terms have low document frequency across all terms in the cluster are\n",
    "    dropped.\n",
    "    -  min_term_cluster_count: int [1,n_docs] = The minimum count of term occurrences across docs\n",
    "    for all terms in each cluster.\n",
    "\n",
    "    Tree fitting is non-deterministic. Use random_state for replicability.\n",
    "    -  random_state: int = None\n",
    "\n",
    "    # Upon tagging documents\n",
    "\n",
    "    When tagging a document, we want to also ensure a connection is made to broader / more abstract\n",
    "    domains. For example, 'batteries' could be mapped to something like:\n",
    "      'battery storage' > 'electricity systems' > 'renewable energy' > 'energy' > 'sustainability'.\n",
    "    The min_abstraction_similarity parameter gives control over how far removed an abstraction can\n",
    "    be from the original term.\n",
    "    -  min_abstraction_similarity:  float [0,1]= .2\n",
    "\n",
    "    Each tag assigned to a document is also given a score measuring how related it is to that\n",
    "    docuement. From observation, a score of >0.4 is very strong, results are quite decent until\n",
    "    ~0.2 and get patchy below that. The min_tag_score parameter sets the threshold below which tags\n",
    "    will not be assigned to documents.\n",
    "    -  min_tag_score: float = .15\n",
    "    \"\"\"\n",
    "\n",
    "    # INGEST INPUT\n",
    "    document_terms: Dict[AnyStr, List] = field(default_factory=dict)\n",
    "    document_attributes: Dict[AnyStr, Dict] = field(default_factory=dict)\n",
    "    term_suggestions: List[AnyStr] = field(default_factory=list)\n",
    "    filter_geo_terms: bool = False\n",
    "\n",
    "    # DERIVED UPON INGEST\n",
    "    n_docs: int = 0\n",
    "    filtered_terms: List[AnyStr] = field(default_factory=list)\n",
    "    term_pipeline: Dict[AnyStr, Dict] = field(default_factory=dict)\n",
    "    term_counts: Counter = field(default_factory=Counter)\n",
    "    term_doc_freq: Dict[AnyStr, float] = field(default_factory=dict)\n",
    "    _term_embeddings: np.array = field(default_factory=make_empty_array)\n",
    "    _filtered_term_similarity: np.array = field(default_factory=make_empty_array)\n",
    "\n",
    "    # FIT TREE INPUT\n",
    "    term_exclusion_list: List[AnyStr] = field(default_factory=list)\n",
    "    term_suggestions_doc_freq: List[float] = field(default_factory=list)\n",
    "    term_similarity_threshold: float = 0.9\n",
    "    min_term_cluster_count: int = 2\n",
    "    random_state: int = None\n",
    "\n",
    "    # DERIVED UPON FITTING TREE\n",
    "    grouped_terms: Dict = field(default_factory=dict)\n",
    "    _collapsed_term_pipeline: Dict = field(default_factory=dict)\n",
    "    processed_document_terms: Dict[AnyStr, List] = field(default_factory=dict)\n",
    "    selected_terms: List[AnyStr] = field(default_factory=list)\n",
    "    _n_selected_terms: int = 0\n",
    "    _selected_terms_idxs: List = field(default_factory=list)\n",
    "    selected_term_counts: Counter = field(default_factory=Counter)\n",
    "    selected_term_doc_freq: Dict[AnyStr, float] = field(default_factory=dict)\n",
    "\n",
    "    # TAG DOCUMENTS INPUT\n",
    "    min_abstraction_similarity: float = 0.2\n",
    "    min_tag_score: float = 0.15\n",
    "\n",
    "    # CONSTANTS\n",
    "    TERM_DROP_KEY: str = \"---DROP---\"\n",
    "    # From https://www.sbert.net/\n",
    "    ENCODER = SentenceTransformer(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "\n",
    "    # A mapping of output format to list of attribute names for use in serialization.\n",
    "    SERIALIZED_ATTRS = {\n",
    "        \"json_ready\": [\n",
    "            \"document_terms\",\n",
    "            \"document_attributes\",\n",
    "            \"term_exclusion_list\",\n",
    "            \"term_suggestions\",\n",
    "            \"filter_geo_terms\",\n",
    "            \"n_docs\",\n",
    "            \"filtered_terms\",\n",
    "            \"term_pipeline\",\n",
    "            \"term_counts\",\n",
    "            \"term_doc_freq\",\n",
    "            \"term_suggestions_doc_freq\",\n",
    "            \"term_similarity_threshold\",\n",
    "            \"min_term_cluster_count\",\n",
    "            \"random_state\",\n",
    "            \"min_abstraction_similarity\",\n",
    "            \"min_tag_score\",\n",
    "        ],\n",
    "        \"csr_matrix\": [\"_filtered_term_similarity\"],\n",
    "        \"numpy\": [\"_term_embeddings\"],\n",
    "    }\n",
    "\n",
    "    #\n",
    "    # SERIALIZATION METHODS\n",
    "    #\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, serialized_obj, hydrate_tree=False, hydrate_tags=False):\n",
    "\n",
    "        obj_dict = json.loads(serialized_obj)\n",
    "        return cls.from_dict(\n",
    "            obj_dict, hydrate_tree=hydrate_tree, hydrate_tags=hydrate_tags\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, obj_dict, hydrate_tree=False, hydrate_tags=False):\n",
    "\n",
    "        # Convert attributes to target format as per SERIALIZED_ATTRS.\n",
    "        for attr_group, attrs in cls.SERIALIZED_ATTRS.items():\n",
    "            if attr_group == \"numpy\":\n",
    "                for attr in attrs:\n",
    "                    obj_dict[attr] = np.array(obj_dict[attr])\n",
    "            elif attr_group == \"csr_matrix\":\n",
    "                for attr in attrs:\n",
    "                    # csr_matrix is used for serialization, but obj is transformed to dense array\n",
    "                    # for calculations\n",
    "                    obj_dict[attr] = csr_matrix(\n",
    "                        (\n",
    "                            obj_dict[attr][\"data\"],\n",
    "                            (obj_dict[attr][\"row\"], obj_dict[attr][\"col\"]),\n",
    "                        ),\n",
    "                        shape=obj_dict[attr][\"shape\"],\n",
    "                    ).toarray()\n",
    "            elif attr_group == \"set\":\n",
    "                for attr in attrs:\n",
    "                    obj_dict[attr] = set(obj_dict[attr])\n",
    "            else:\n",
    "                # obj_dict[attr] is already of expected type\n",
    "                continue\n",
    "\n",
    "        ht_instance = cls(**obj_dict)\n",
    "\n",
    "        if any([hydrate_tree, hydrate_tags]):\n",
    "            # Recalculate tree with parameter values from serialized object\n",
    "            ht_instance.fit_tag_tree(\n",
    "                **{\n",
    "                    attr: value\n",
    "                    for attr, value in obj_dict.items()\n",
    "                    if attr\n",
    "                    in [\n",
    "                        \"term_suggestions_doc_freq\",\n",
    "                        \"term_similarity_threshold\",\n",
    "                        \"min_term_cluster_count\",\n",
    "                        \"random_state\",\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if hydrate_tags:\n",
    "            # Recalculate document tags with parameter values from serialized object\n",
    "            ht_instance.tag_documents(\n",
    "                **{\n",
    "                    attr: value\n",
    "                    for attr, value in obj_dict.items()\n",
    "                    if attr in [\"min_abstraction_similarity\", \"min_tag_score\"]\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return ht_instance\n",
    "\n",
    "    def to_json(self):\n",
    "\n",
    "        obj_dict = {\n",
    "            attr: getattr(self, attr)\n",
    "            for attrs in self.SERIALIZED_ATTRS.values()\n",
    "            for attr in attrs\n",
    "        }\n",
    "\n",
    "        # Use smaller csr_matrix for serialization\n",
    "        obj_dict[\"_filtered_term_similarity\"] = csr_matrix(\n",
    "            obj_dict[\"_filtered_term_similarity\"]\n",
    "        )\n",
    "\n",
    "        return json.dumps(obj_dict, cls=CustomEncoder)\n",
    "\n",
    "    def ingest(\n",
    "        self,\n",
    "        document_terms: Dict[AnyStr, List],\n",
    "        document_attributes: Dict[AnyStr, Dict] = None,\n",
    "        term_suggestions: List[AnyStr] = None,\n",
    "        filter_geo_terms: bool = False,\n",
    "        term_similarity_minimum: float = 0.6,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The ingest step involves going from the terms as they appear in the documents, to a filtered\n",
    "        set of terms to use as candiates in the successive tree fitting step.\n",
    "\n",
    "        We attempt to reduces the term set by combining plurals with singulars and, optionally,\n",
    "        removing geographical names. We then map all the remining filtered_terms into an embedding\n",
    "        space using a large language model.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set up starting values\n",
    "        self._intialize_ingest(document_terms, document_attributes, term_suggestions)\n",
    "\n",
    "        # Create a clean term set from documents and suggestions\n",
    "        self._clean_up_terms(\n",
    "            filter_geo_terms, term_similarity_minimum=term_similarity_minimum\n",
    "        )\n",
    "\n",
    "    def _intialize_ingest(self, document_terms, document_attributes, term_suggestions):\n",
    "        # Resets attributes to empty containers and/or user arguments.\n",
    "        self.term_pipeline = dict()\n",
    "        self.filtered_terms = set()\n",
    "        self.grouped_terms = dict()\n",
    "        self.selected_terms = list()\n",
    "        self.term_suggestions = (\n",
    "            [t.lower() for t in term_suggestions]\n",
    "            if term_suggestions is not None\n",
    "            else list()\n",
    "        )\n",
    "        self.document_terms = document_terms\n",
    "        self.document_attributes = document_attributes\n",
    "        self.n_docs = len(document_terms)\n",
    "\n",
    "    def _clean_up_terms(self, filter_geo_terms, term_similarity_minimum=0.6):\n",
    "        # Create term set from documents and suggestions\n",
    "        self._create_term_set()\n",
    "        # Remove plurals\n",
    "        self._remove_plurals()\n",
    "        # Exclude geographical terms\n",
    "        self.filter_geo_terms = filter_geo_terms\n",
    "        if self.filter_geo_terms is True:\n",
    "            self._apply_geo_term_filter()\n",
    "        # Map terms to embedding space\n",
    "        self._semantic_term_map()\n",
    "        # Create a term similarity matrix, subject to minimum similarity\n",
    "        self._create_filtered_term_similarity(\n",
    "            term_similarity_minimum=term_similarity_minimum\n",
    "        )\n",
    "\n",
    "    def _create_term_set(self):\n",
    "        # Creates initial set of all terms. Also makes lowercase.\n",
    "        lowercase_terms = [\n",
    "            term.lower()\n",
    "            for document in self.document_terms.values()\n",
    "            for term in document\n",
    "        ]\n",
    "        self.filtered_terms = set(lowercase_terms)\n",
    "\n",
    "        # Add suggestions to filtered_terms set\n",
    "        self.filtered_terms = self.filtered_terms.union(set(self.term_suggestions))\n",
    "\n",
    "        # Term counts and frequencies from docs\n",
    "        self.term_counts = Counter(lowercase_terms)\n",
    "        # Calculate term document frequencies.\n",
    "        # Assumes that a term is not present twice in any document.\n",
    "        self.term_doc_freq = {\n",
    "            term: self.term_counts[term] / self.n_docs for term in self.filtered_terms\n",
    "        }\n",
    "\n",
    "    def _remove_plurals(self):\n",
    "        # Creates a term_pipeline step mapping plural terms to their singular\n",
    "        plurals = set()\n",
    "        remove_plurals_step = dict()\n",
    "        for term in self.filtered_terms:\n",
    "            # For each plural term where singular is also in set\n",
    "            # Drop the plural and move its counts to the singular\n",
    "            if term[-1] == \"s\" and term[0:-1] in self.filtered_terms:\n",
    "                plurals.add(term)\n",
    "                remove_plurals_step[term] = term[0:-1]\n",
    "                self.term_counts[term[0:-1]] += self.term_counts[term]\n",
    "                self.term_counts[term] = 0\n",
    "            if term[-3:] == \"ies\" and term[0:-3] + \"y\" in self.filtered_terms:\n",
    "                plurals.add(term)\n",
    "                remove_plurals_step[term] = term[0:-3] + \"y\"\n",
    "                self.term_counts[term[0:-3] + \"y\"] += self.term_counts[term]\n",
    "                self.term_counts[term] = 0\n",
    "\n",
    "        self.term_pipeline[\"1: Remove Plurals\"] = remove_plurals_step\n",
    "        self.filtered_terms = self.filtered_terms - plurals\n",
    "\n",
    "    def _apply_geo_term_filter(self):\n",
    "        # Creates a term_pipeline step to remove geographical locations from the term set\n",
    "\n",
    "        # Load set of locations\n",
    "        locations = get_locations_set()\n",
    "\n",
    "        # Initialize pipeline step\n",
    "        remove_geo_terms_step = dict()\n",
    "\n",
    "        # Remove all terms that are exact matches to the location set\n",
    "        geo_terms = set(self.filtered_terms).intersection(locations)\n",
    "        for term in geo_terms:\n",
    "            remove_geo_terms_step[term] = self.TERM_DROP_KEY\n",
    "        self.filtered_terms = self.filtered_terms - geo_terms\n",
    "\n",
    "        # Remove terms that contain locations\n",
    "        def _is_sublist(sub_lst, lst):\n",
    "            n = len(sub_lst)\n",
    "            return any((sub_lst == lst[i : i + n]) for i in range(len(lst) - n + 1))\n",
    "\n",
    "        for term in self.filtered_terms:\n",
    "            for location in locations:\n",
    "                if _is_sublist(location.split(), term.split()):\n",
    "                    # Remove if location is a subsequence of words in term\n",
    "                    remove_geo_terms_step[term] = self.TERM_DROP_KEY\n",
    "                    geo_terms.add(term)\n",
    "                    # Break out of inner loop to move to next term\n",
    "                    break\n",
    "\n",
    "        self.term_pipeline[\"2: Remove Geo Terms\"] = remove_geo_terms_step\n",
    "        self.filtered_terms = self.filtered_terms - geo_terms\n",
    "\n",
    "    def _semantic_term_map(self):\n",
    "        # Calculate embeddings for terms that passed initial filtering\n",
    "        self.filtered_terms = list(self.filtered_terms)\n",
    "        self._term_embeddings = self.ENCODER.encode(self.filtered_terms)\n",
    "\n",
    "    def _create_filtered_term_similarity(self, term_similarity_minimum=0.6):\n",
    "        self._filtered_term_similarity = cosine_similarity(self._term_embeddings)\n",
    "        # To reduce memory footprint we set all 'low' similarities to zero and convert to csr_matrix\n",
    "        # upon serialization\n",
    "        if term_similarity_minimum:\n",
    "            self._filtered_term_similarity[\n",
    "                self._filtered_term_similarity < term_similarity_minimum\n",
    "            ] = 0\n",
    "\n",
    "    #\n",
    "    # EXTRACT THE HIERARCHICAL TAG TREE\n",
    "    #\n",
    "\n",
    "    def fit_tag_tree(\n",
    "        self,\n",
    "        term_exclusion_list: List[AnyStr] = None,\n",
    "        term_suggestions_doc_freq: List[float] = None,\n",
    "        term_similarity_threshold: float = 0.9,\n",
    "        min_term_cluster_count: int = 2,\n",
    "        random_state: float = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This step fits the tag tree from the document terms.\n",
    "\n",
    "        Some pre-processing steps are carried out further reduce the candidate term sets. We group\n",
    "        semantically similar terms. Terms in groups with low overall document count are dropped.\n",
    "        Terms included in the user-provided exclusion list, as well as their synonyms, are also\n",
    "        dropped. Finally, we select a single term from each remaining group. Terms passing this\n",
    "        processing step are referred to as selected_terms, because they are selected as candidate\n",
    "        terms to appear in the hierarchical tree.\n",
    "        \"\"\"\n",
    "\n",
    "        self._initialize_fit(\n",
    "            term_exclusion_list,\n",
    "            term_suggestions_doc_freq,\n",
    "            term_similarity_threshold,\n",
    "            min_term_cluster_count,\n",
    "            random_state,\n",
    "        )\n",
    "\n",
    "        self._process_terms()\n",
    "\n",
    "        self._extract_tag_tree()\n",
    "\n",
    "    def _initialize_fit(\n",
    "        self,\n",
    "        term_exclusion_list,\n",
    "        term_suggestions_doc_freq,\n",
    "        term_similarity_threshold,\n",
    "        min_term_cluster_count,\n",
    "        random_state,\n",
    "    ):\n",
    "        \"\"\"Resets attributes to empty containers and/or user arguments.\"\"\"\n",
    "\n",
    "        self.term_exclusion_list = (\n",
    "            list({t.lower() for t in term_exclusion_list})\n",
    "            if term_exclusion_list is not None\n",
    "            else list()\n",
    "        )\n",
    "        self.term_similarity_threshold = term_similarity_threshold\n",
    "        self.min_term_cluster_count = min_term_cluster_count\n",
    "        self.term_suggestions_doc_freq = (\n",
    "            term_suggestions_doc_freq\n",
    "            if term_suggestions_doc_freq is not None\n",
    "            else list()\n",
    "        )\n",
    "        if len(self.term_suggestions) != len(self.term_suggestions_doc_freq):\n",
    "            raise ValueError(\n",
    "                \"term_suggestions and term_suggestions_doc_freq must be of equal length.\"\n",
    "            )\n",
    "        self.random_state = (\n",
    "            random_state if random_state is not None else np.random.randint(5000)\n",
    "        )\n",
    "\n",
    "    def _process_terms(self):\n",
    "        # Ingest term suggestion document frequencies\n",
    "        self._read_term_suggestion_doc_freq()\n",
    "        # Group semantically similar terms\n",
    "        self._group_terms()\n",
    "        # Drop low count term clusters\n",
    "        self._drop_low_count_term_clusters()\n",
    "        # Apply term exclusion list\n",
    "        self._apply_term_exclusion_list()\n",
    "        # Select representative terms\n",
    "        self._select_representative_terms()\n",
    "        # Run pipeline to process documents and select final term set\n",
    "        self._run_term_pipeline()\n",
    "        # Refocus internals on selected terms only\n",
    "        self._set_up_for_selected_terms()\n",
    "\n",
    "    def _read_term_suggestion_doc_freq(self):\n",
    "        \"\"\"Add or overwrite doc_freq and counts for suggestions\"\"\"\n",
    "        for suggestion, suggestion_doc_freq in zip(\n",
    "            self.term_suggestions, self.term_suggestions_doc_freq\n",
    "        ):\n",
    "            self.term_doc_freq[suggestion] = suggestion_doc_freq\n",
    "            self.term_counts[suggestion] = int(\n",
    "                self.term_doc_freq[suggestion] * self.n_docs\n",
    "            )\n",
    "\n",
    "    def _group_terms(self):\n",
    "        \"\"\"\n",
    "        Cluster semantically similar terms using Louvain clustering.\n",
    "        In this step, we are aiming to find synonyms, so term_similarity_threshold should be high\n",
    "        (ex. >=0.9)\n",
    "        \"\"\"\n",
    "\n",
    "        louvain = Louvain(random_state=self.random_state)\n",
    "        adjacency = copy.deepcopy(self._filtered_term_similarity)\n",
    "        adjacency[adjacency < self.term_similarity_threshold] = 0\n",
    "        adjacency = csr_matrix(adjacency)\n",
    "        labels = louvain.fit_transform(adjacency)\n",
    "\n",
    "        # Store clustering in dict mapping cluster_label to list of terms\n",
    "        grouped_terms = defaultdict(list)\n",
    "        for t, l in zip(self.filtered_terms, labels):\n",
    "            grouped_terms[str(l)].append(t)\n",
    "\n",
    "        self.grouped_terms = grouped_terms\n",
    "\n",
    "    def _drop_low_count_term_clusters(self):\n",
    "        \"\"\"Creates a term_pipeline step to drop all terms in clusters with low overall term count\"\"\"\n",
    "\n",
    "        low_term_count_clusters = [\n",
    "            k\n",
    "            for k, v in self.grouped_terms.items()\n",
    "            if sum(self.term_counts[t] for t in v) < self.min_term_cluster_count\n",
    "        ]\n",
    "\n",
    "        low_term_count_step = {\n",
    "            term: self.TERM_DROP_KEY\n",
    "            for cluster_id, terms in self.grouped_terms.items()\n",
    "            for term in terms\n",
    "            if cluster_id in low_term_count_clusters\n",
    "        }\n",
    "        self.term_pipeline[\"3: Remove Low Count Terms\"] = low_term_count_step\n",
    "\n",
    "        self.grouped_terms = {\n",
    "            k: v\n",
    "            for k, v in self.grouped_terms.items()\n",
    "            if k not in low_term_count_clusters\n",
    "        }\n",
    "\n",
    "    def _apply_term_exclusion_list(self):\n",
    "        \"\"\"\n",
    "        Creates a term_pipeline step to drop clusters containing terms in the exclusion list\n",
    "        This means that synonyms of the excluded term will also be dropped.\n",
    "        The exclusion list should therefore list *concepts* not merely specific variants of a term.\n",
    "        \"\"\"\n",
    "\n",
    "        exclusion_clusters = [\n",
    "            cluster_id\n",
    "            for cluster_id, terms in self.grouped_terms.items()\n",
    "            if any((term in self.term_exclusion_list) for term in terms)\n",
    "        ]\n",
    "\n",
    "        exclusion_step = {\n",
    "            term: self.TERM_DROP_KEY\n",
    "            for cluster_id, terms in self.grouped_terms.items()\n",
    "            for term in terms\n",
    "            if cluster_id in exclusion_clusters\n",
    "        }\n",
    "\n",
    "        self.term_pipeline[\"4: Apply Term Exclusion List\"] = exclusion_step\n",
    "\n",
    "        self.grouped_terms = {\n",
    "            k: v for k, v in self.grouped_terms.items() if k not in exclusion_clusters\n",
    "        }\n",
    "\n",
    "    def _select_representative_terms(self):\n",
    "        \"\"\"\n",
    "        Creates a term_pipeline step selecting a representative term for each cluster\n",
    "        The term with the highest average cosine similarity with all other terms in the cluster is\n",
    "        chosen.\n",
    "        \"\"\"\n",
    "\n",
    "        term_to_representative_term_step = {}\n",
    "        selected_terms = []\n",
    "\n",
    "        for terms in self.grouped_terms.values():\n",
    "            if len(terms) > 1:\n",
    "                term_ids = [self.filtered_terms.index(t) for t in terms]\n",
    "                # Numerical errors were leading to non-reproducibility of results.\n",
    "                # Use slower dtype=float64 as in Notes here\n",
    "                # https://numpy.org/doc/stable/reference/generated/numpy.sum.html\n",
    "                central_term_id = term_ids[\n",
    "                    np.argsort(\n",
    "                        -self._filtered_term_similarity[term_ids, :][:, term_ids].sum(\n",
    "                            axis=1, dtype=\"float64\"\n",
    "                        )\n",
    "                    )[0]\n",
    "                ]\n",
    "                central_term = self.filtered_terms[central_term_id]\n",
    "                selected_terms.append(central_term)\n",
    "                for term in terms:\n",
    "                    if term != central_term:\n",
    "                        term_to_representative_term_step[term] = central_term\n",
    "\n",
    "        self.term_pipeline[\n",
    "            \"5: Select Representative Terms\"\n",
    "        ] = term_to_representative_term_step\n",
    "\n",
    "    def _run_term_pipeline(self):\n",
    "        \"\"\"\n",
    "        Having logged all term transformation steps in .term_pipeline, we now run the original\n",
    "        document_terms through the pipeline to generate processed_document_terms: a document\n",
    "        representation using terms that have been fully processed.\n",
    "        \"\"\"\n",
    "\n",
    "        # Collapse all pipeline steps to generate a single DAG showing how each term is transformed\n",
    "        # at each step.\n",
    "        self._collapsed_term_pipeline = dict()\n",
    "        for pipeline_step in self.term_pipeline.values():\n",
    "            self._collapsed_term_pipeline.update(pipeline_step)\n",
    "\n",
    "        # Run all document terms through term pipeline\n",
    "        processed_document_terms = {}\n",
    "        for document, term_list in self.document_terms.items():\n",
    "            processed_terms = []\n",
    "            for t in term_list:\n",
    "                # Run lowercase term through pipeline\n",
    "                processed_term = next(self._run_term_through_pipeline(t.lower()))\n",
    "                if processed_term is not None:\n",
    "                    processed_terms.append(processed_term)\n",
    "\n",
    "            processed_document_terms[document] = list(set(processed_terms))\n",
    "\n",
    "        self.processed_document_terms = processed_document_terms\n",
    "\n",
    "    def _run_term_through_pipeline(self, term):\n",
    "        \"\"\"\n",
    "        Recursively traverse the term transformation DAG and yield the final term, or None if term\n",
    "        is dropped.\n",
    "        \"\"\"\n",
    "        term_result = self._collapsed_term_pipeline.get(term)\n",
    "        if term_result is None:\n",
    "            # No further pipeline steps\n",
    "            yield term\n",
    "        if term_result == self.TERM_DROP_KEY:\n",
    "            # Term should be dropped\n",
    "            yield None\n",
    "        # Continue pipeline\n",
    "        yield from self._run_term_through_pipeline(term_result)\n",
    "\n",
    "    def _set_up_for_selected_terms(self):\n",
    "        \"\"\"Set up the final selected_terms and associated embeddings and similarity matrix\"\"\"\n",
    "\n",
    "        # Create set of selected terms from documents after term processing\n",
    "        doc_selected_terms = [\n",
    "            term\n",
    "            for doc_terms in self.processed_document_terms.values()\n",
    "            for term in doc_terms\n",
    "        ]\n",
    "\n",
    "        # Process suggestion terms, and keep only the ones that pass all filters\n",
    "        processed_suggested_terms = [\n",
    "            next(self._run_term_through_pipeline(t)) for t in self.term_suggestions\n",
    "        ]\n",
    "        processed_suggested_terms = [\n",
    "            t for t in processed_suggested_terms if t is not None\n",
    "        ]\n",
    "        suggested_selected_terms = set(self.filtered_terms).intersection(\n",
    "            set(processed_suggested_terms)\n",
    "        )\n",
    "\n",
    "        # Combine into final selected_terms\n",
    "        self.selected_terms = list(\n",
    "            set(doc_selected_terms).union(suggested_selected_terms)\n",
    "        )\n",
    "        self._n_selected_terms = len(self.selected_terms)\n",
    "\n",
    "        # Overwrite count data considering only selected term\n",
    "        self.selected_term_counts = Counter(doc_selected_terms)\n",
    "        self.selected_term_doc_freq = {\n",
    "            term: self.selected_term_counts[term] / self.n_docs\n",
    "            for term in set(doc_selected_terms)\n",
    "        }\n",
    "\n",
    "        # Add or overwrite doc_freq for suggestions\n",
    "        for suggestion, suggestion_doc_freq in zip(\n",
    "            self.term_suggestions, self.term_suggestions_doc_freq\n",
    "        ):\n",
    "            if suggestion in suggested_selected_terms:\n",
    "                self.selected_term_doc_freq[suggestion] = suggestion_doc_freq\n",
    "                self.selected_term_counts[suggestion] = int(\n",
    "                    self.selected_term_doc_freq[suggestion] * self.n_docs\n",
    "                )\n",
    "\n",
    "        # Slice embeddings matrix to focus on selected terms\n",
    "        self._selected_terms_idxs = [\n",
    "            self.filtered_terms.index(t) for t in self.selected_terms\n",
    "        ]\n",
    "        self._selected_terms_embeddings = copy.deepcopy(\n",
    "            self._term_embeddings[self._selected_terms_idxs]\n",
    "        )\n",
    "\n",
    "        # Calculate similarity across selected terms\n",
    "        self._selected_terms_similarity = cosine_similarity(\n",
    "            self._selected_terms_embeddings\n",
    "        )\n",
    "\n",
    "    def _extract_tag_tree(self):\n",
    "\n",
    "        # Run hierarchical clustering on terms\n",
    "        self._build_term_hierarchy()\n",
    "\n",
    "        # Build tree from hierarchy\n",
    "        self._build_tag_tree()\n",
    "\n",
    "    def _build_term_hierarchy(self):\n",
    "        self.hierarchy = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            affinity=\"cosine\",\n",
    "            memory=None,\n",
    "            connectivity=None,\n",
    "            compute_full_tree=\"auto\",\n",
    "            linkage=\"average\",\n",
    "            distance_threshold=0,\n",
    "            compute_distances=False,\n",
    "        )\n",
    "        self.hierarchy.fit(self._selected_terms_embeddings)\n",
    "\n",
    "    def _build_tag_tree(self):\n",
    "        \"\"\"\n",
    "        Build tree downwards starting from highest node\n",
    "        AgglomerativeClustering.hierarchy.children_ stores the ways in which terms are aggregated\n",
    "        hierarchically we build a tree from these relationships, adding some custom logic and\n",
    "        descriptive data in the process.\n",
    "        \"\"\"\n",
    "\n",
    "        self.tree = Tree()\n",
    "        node_id = self.hierarchy.children_.max() + 1\n",
    "        self._build_term_tree_from_node(\n",
    "            node_id, parent_node_id=None, parent_node_term=None\n",
    "        )\n",
    "\n",
    "        # Filter to core nodes, ie ensuring node labels are unique\n",
    "        self._define_core_nodes()\n",
    "\n",
    "        # Build tag tree from core nodes only\n",
    "        self._build_pruned_tree()\n",
    "\n",
    "        # Replace tree with pruned_tree\n",
    "        self.tree = copy.deepcopy(self.pruned_tree)\n",
    "        self.pruned_tree = None\n",
    "\n",
    "    def _build_term_tree_from_node(self, node_id, parent_node_id, parent_node_term):\n",
    "        \"\"\"\n",
    "        Starting from node_id, recursively traverses all downstream nodes and leaves of\n",
    "        self.hierarchy. At each step computes information about the node/leave in terms of the\n",
    "        downstream nodes and, importantly, selects the most central term to be the name of this\n",
    "        node.\n",
    "        \"\"\"\n",
    "\n",
    "        # Find all terms that contained in this node (i.e. are downstream leaves)\n",
    "        term_ids = list()\n",
    "        self._find_node_term_ids(term_ids, node_id)\n",
    "\n",
    "        # Number of terms and their occurrences in the documents\n",
    "        n_terms = len(term_ids)\n",
    "        n_occurrences = sum(self.term_counts[self.selected_terms[i]] for i in term_ids)\n",
    "\n",
    "        # Represent the node via its contained terms, centrality ranking, and scores\n",
    "        ranked_term_ids, ranked_term_id_scores = self._extract_ranked_term_ids(term_ids)\n",
    "        ranked_terms = [self.selected_terms[i] for i in ranked_term_ids]\n",
    "        terms_set = [\n",
    "            (term, score) for term, score in zip(ranked_terms, ranked_term_id_scores)\n",
    "        ]\n",
    "\n",
    "        # Find all downstream elements\n",
    "        leaves, nodes = self._find_node_children(node_id)\n",
    "\n",
    "        if ranked_terms[0] != parent_node_term:\n",
    "            # If central term for this node different from parent node\n",
    "            # Create a new node with associated term and other metadata\n",
    "            node_term = ranked_terms[0]\n",
    "            self.tree.create_node(\n",
    "                node_term,\n",
    "                node_id,\n",
    "                parent=parent_node_id,\n",
    "                data=DataProperty(\n",
    "                    n_terms,\n",
    "                    n_occurrences,\n",
    "                    ranked_terms[:3],\n",
    "                    terms_set,\n",
    "                    f\"{node_term} - {n_occurrences}\",\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            # If central term for this node is the same a parent node\n",
    "            # Don't create new node and pass parent node id and term downstream\n",
    "            node_id = parent_node_id\n",
    "            node_term = parent_node_term\n",
    "\n",
    "        # Proceed down into the tree, handling nodes and leaves differently\n",
    "\n",
    "        # Recursively move to the downstream nodes, passing this node as parent\n",
    "        for node in nodes:\n",
    "            self._build_term_tree_from_node(node, node_id, node_term)\n",
    "\n",
    "        # Create nodes directly for all immediate downstream leaves\n",
    "        for leaf in leaves:\n",
    "            leaf_term = self.selected_terms[leaf]\n",
    "            if leaf_term != node_term:\n",
    "                # Create leaf nodes if leaf is a different term\n",
    "                self.tree.create_node(\n",
    "                    leaf_term,\n",
    "                    leaf,\n",
    "                    parent=node_id,\n",
    "                    data=DataProperty(\n",
    "                        1,\n",
    "                        self.term_counts[leaf_term],\n",
    "                        [leaf_term],\n",
    "                        [leaf_term],\n",
    "                        f\"{leaf_term} - {self.term_counts[leaf_term]}\",\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "    def _find_node_children(self, node_id):\n",
    "        \"\"\"\n",
    "        Find downstream nodes and leaves for a given node_id\n",
    "        See https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\n",
    "        Section: Attributes -> children_\n",
    "        \"\"\"\n",
    "        if node_id < self._n_selected_terms:\n",
    "            # Leaf node\n",
    "            return [node_id], []\n",
    "        children = self.hierarchy.children_[node_id - self._n_selected_terms]\n",
    "        leaves = [child for child in children if child < self._n_selected_terms]\n",
    "        nodes = [child for child in children if child >= self._n_selected_terms]\n",
    "        return leaves, nodes\n",
    "\n",
    "    def _find_node_term_ids(self, term_ids, node_id):\n",
    "        \"\"\"\n",
    "        Recursively traverse to tree down to the leaves, collecting term_ids for all downstream\n",
    "        terms.\n",
    "        \"\"\"\n",
    "        leaves, nodes = self._find_node_children(node_id)\n",
    "        term_ids.extend(leaves)\n",
    "        for node in nodes:\n",
    "            self._find_node_term_ids(term_ids, node)\n",
    "\n",
    "    def _extract_ranked_term_ids(self, term_ids):\n",
    "        \"\"\"\n",
    "        Rank selected term_ids by (descending) measure of centrality\n",
    "        Centrality is measured by the average term similarity across all terms in the set\n",
    "        weighted by the term document frequencies: semantic similarity to a frequent term will count\n",
    "        more.\n",
    "        \"\"\"\n",
    "\n",
    "        # Similarities in the term set\n",
    "        sim_subgraph = self._selected_terms_similarity[term_ids, :][:, term_ids]\n",
    "        # Term document frequencies\n",
    "        weights = np.array(\n",
    "            [self.selected_term_doc_freq[self.selected_terms[i]] for i in term_ids]\n",
    "        )\n",
    "        # Weighted average term similarity\n",
    "        term_scores = (sim_subgraph * weights.T).sum(axis=1)\n",
    "\n",
    "        # Rankings\n",
    "        ranked_term_ids = [term_ids[i] for i in np.argsort(-term_scores)]\n",
    "        ranked_term_id_scores = -np.sort(-term_scores)\n",
    "        return ranked_term_ids, ranked_term_id_scores\n",
    "\n",
    "    def _define_core_nodes(self, min_n_terms=1):\n",
    "        \"\"\"\n",
    "        Defines set of core_nodes.\n",
    "        If two nodes have the same central term (node.tag), choose the node with the higher document\n",
    "        frequency.\n",
    "        Can also limit nodes to those containing a min_n_terms.\n",
    "        \"\"\"\n",
    "\n",
    "        descending_nodes = sorted(\n",
    "            self.tree.all_nodes(), key=lambda x: x.data.n_occurrences, reverse=True\n",
    "        )\n",
    "\n",
    "        used_terms = set()\n",
    "        core_nodes = []\n",
    "        for node in descending_nodes:\n",
    "            if node.tag not in used_terms and node.data.n_terms > min_n_terms:\n",
    "                core_nodes.append(node)\n",
    "                used_terms.add(node.tag)\n",
    "\n",
    "        self._core_nodes = core_nodes\n",
    "\n",
    "    def _build_pruned_tree(self):\n",
    "        \"\"\"Builds a tree that only exists of nodes in the core nodes\"\"\"\n",
    "        core_node_ids = {x.identifier for x in self._core_nodes}\n",
    "        self.pruned_tree = Tree()\n",
    "        for node in self._core_nodes:\n",
    "            found_parent = False\n",
    "            # Documentation for .predecessor does not exist (yet?)\n",
    "            # See: https://github.com/caesar0301/treelib/blob/master/treelib/node.py#L129\n",
    "            # See: https://github.com/caesar0301/treelib/issues/158\n",
    "            old_tree_parent = node.predecessor(self.tree.identifier)\n",
    "            if not old_tree_parent:\n",
    "                # No parent found -> Add as root node\n",
    "                self.pruned_tree.add_node(node)\n",
    "                found_parent = True\n",
    "            while not found_parent:\n",
    "                # Look until we find ancestor in set of core nodes, and add to pruned_tree.\n",
    "                if old_tree_parent in core_node_ids:\n",
    "                    self.pruned_tree.add_node(node, parent=old_tree_parent)\n",
    "                    found_parent = True\n",
    "                else:\n",
    "                    not_found_node = self.tree.nodes[old_tree_parent]\n",
    "                    old_tree_parent = not_found_node.predecessor(self.tree.identifier)\n",
    "        return self.pruned_tree\n",
    "\n",
    "    #\n",
    "    # TAG DOCUMENTS\n",
    "    #\n",
    "\n",
    "    def tag_documents(\n",
    "        self, min_abstraction_similarity: float = 0.2, min_tag_score: float = 0.15\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Maps document topics to hierarchical tags.\n",
    "\n",
    "        We have a set of candidate tags, represented as nodes in the hierarchical tree, and stored\n",
    "        in core_nodes.\n",
    "\n",
    "        Each node has a unique label (node.tag) and its meaning is represented as a weighted\n",
    "        combination of the children terms (node.data.term_set).\n",
    "\n",
    "        We want to match each of the document topics to the closest candidate node.\n",
    "        Ex 'batteries' -> 'battery storage'.\n",
    "        Additioanlly, we want to also ensure a connection is made to broader / more abstract\n",
    "        domains.\n",
    "        Ex 'batteries' -> 'battery storage' > 'electricity systems' > 'renewable energy' >\n",
    "        'energy' > 'sustainability', ideally with a declining relatedness score as we move further\n",
    "        up the abstractions.\n",
    "\n",
    "        We carry out the following steps to achieve this:\n",
    "            1. Convert core_nodes into a node X term matrix representation\n",
    "            2. Calculate semantic similarity scores across nodes (accounting for the semantic\n",
    "                similarity across terms).\n",
    "            3. Find each node's 'abstractions'. For a node J, 'abstractions' are defined as other\n",
    "                nodes K appearing higher up in the tree, weighted by the similarity between J and K\n",
    "                to capture the increasing remoteness of the abstraction.\n",
    "            4. For each document topic, we map a) closest node (step 1) and b) the node's\n",
    "                abstractions (step 3).\n",
    "            5. We aggregate the topic to abstraction mapping a document level. This yields a\n",
    "                document X node matrix.\n",
    "            6. To account for the fact that higher level abstractions are going to show up more\n",
    "                often, we run this final matrix through a tfidf transformation.\n",
    "        \"\"\"\n",
    "        # Set values\n",
    "        self.min_abstraction_similarity = min_abstraction_similarity\n",
    "        self.min_tag_score = min_tag_score\n",
    "\n",
    "        # Set up a node x term matrix\n",
    "        self._build_node_term_matrix()  # Step 1; nodes X terms matrix\n",
    "        self._build_node_similarity_matrix()  # Step 2; nodes X nodes matrix\n",
    "        self._build_node_abstraction_matrix()  # Step 3 node X nodes matrix\n",
    "        self._match_terms_to_nodes()  # Step 4a; dict term -> closest node\n",
    "\n",
    "        # Match all documents to tags and abstractions\n",
    "        self.document_tag_matrix = np.vstack(\n",
    "            [\n",
    "                self._document_topics_to_tags(document_terms)  # Step 4a, 4b and 5\n",
    "                for document_terms in self.processed_document_terms.values()\n",
    "            ]\n",
    "        )  # documents x nodes matrix\n",
    "\n",
    "        tfidf = TfidfTransformer()  # Step 6\n",
    "        self.document_tags_tfidf = tfidf.fit_transform(self.document_tag_matrix)\n",
    "\n",
    "        self.document_tags = defaultdict(list)\n",
    "        doc_ids = list(self.processed_document_terms.keys())\n",
    "\n",
    "        # Convert documents x nodes matrix to document_id -> tags dictionary\n",
    "        cx = self.document_tags_tfidf.tocoo()\n",
    "        for idx, i, v in zip(cx.row, cx.col, cx.data):\n",
    "            if v > self.min_tag_score:\n",
    "                self.document_tags[doc_ids[idx]].append(\n",
    "                    tuple([self._core_nodes[i].tag, v, self._core_nodes[i].identifier])\n",
    "                )\n",
    "\n",
    "        # Sort document tags by relevance score\n",
    "        for doc_id, tags in self.document_tags.items():\n",
    "            self.document_tags[doc_id] = sorted(tags, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    def _build_node_term_matrix(self):\n",
    "        \"\"\"\n",
    "        Build a matrix mapping core nodes (rows) to their contained terms (columns), and their\n",
    "        measure of centrality.\n",
    "        \"\"\"\n",
    "\n",
    "        # Populate as sparse matrix\n",
    "        rows = list()\n",
    "        cols = list()\n",
    "        data = list()\n",
    "        for i, core_node in enumerate(self._core_nodes):\n",
    "            row = np.array(\n",
    "                [i] * core_node.data.n_terms\n",
    "            )  # Rows in same order as _core_nodes\n",
    "            terms, datum = zip(*core_node.data.term_set)\n",
    "            col = np.array([self.selected_terms.index(term) for term in terms])\n",
    "            rows.extend(row)\n",
    "            cols.extend(col)\n",
    "            data.extend(datum)\n",
    "\n",
    "        rows = np.array(rows)\n",
    "        cols = np.array(cols)\n",
    "        data = np.array(data)\n",
    "\n",
    "        node_term_matrix = csr_matrix(\n",
    "            (data, (rows, cols)),\n",
    "            shape=(len(self._core_nodes), len(self.selected_terms)),\n",
    "        )\n",
    "        node_term_matrix = normalize(node_term_matrix)\n",
    "\n",
    "        self._node_term_matrix = node_term_matrix\n",
    "\n",
    "        # Mapping of node identifier to node index in node_term_matrix rows\n",
    "        self._node_id_to_idx = {\n",
    "            core_node.identifier: i for i, core_node in enumerate(self._core_nodes)\n",
    "        }\n",
    "        self._node_idx_to_id = {\n",
    "            i: core_node.identifier for i, core_node in enumerate(self._core_nodes)\n",
    "        }\n",
    "\n",
    "    def _build_node_similarity_matrix(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Calculate a matrix of cosine similarity across all nodes, but weighted to allow similar\n",
    "        terms to count, at least partially, towards the similarity.\n",
    "\n",
    "        See https://en.wikipedia.org/wiki/Cosine_similarity#Soft_cosine_measure\n",
    "\n",
    "        Two docs [\"electric cars\", \"urban mobility\"] & [\"electric vehicles\", \"urban mobility\"]\n",
    "        should have a similarity of almost 1 and not of just 0.5 as would be the case if we only\n",
    "        consider the exact terms.\n",
    "        To achieve this, we weigh the contribution of the \"electric cars\" <-> \"electric vehicles\"\n",
    "        by their term as estimates by based on their language model embedding vectors.\n",
    "\n",
    "        Normally we would construct a document pairwise similarity matrix using cosine similarity.\n",
    "        For unit vectors, this is just the dot product of all vector pairs:\n",
    "\n",
    "        raw_similarity_matrix = entity_set_A_features * entity_set_B_features.T\n",
    "\n",
    "        However, we want for similar terms (electric car vs elecrtic vehicles) to count towards the\n",
    "        similarity. We can do this by weighing the product by the similarity across terms.\n",
    "        So we do this instead:\n",
    "        raw_similarity_matrix = entity_set_A_features * term_similarity * entity_set_B_features.T\n",
    "\n",
    "        However, this similarity score will not be bounded to 1. It will increase arbitrarily with\n",
    "        the number of terms present in a document, and will include some double counting if a\n",
    "        document itself is tagged with two similar terms, which then will be 'doubly' similar when\n",
    "        matched to the terms in the other document.\n",
    "\n",
    "        To remove this effect we aim to normalize similarity by the geometric mean of the\n",
    "        non-normalized similarity scores of entities in set A and set B with themselves.\n",
    "\n",
    "        We take diagonal from the non-normalized similarity matrices of sets A and B and take the\n",
    "        product of all pairs. Then take the sqrt to get geometric mean.\n",
    "\n",
    "        non_normalized_set_A_similarity_matrix =\n",
    "            entity_set_A_features * term_similarity * entity_set_A_features.T\n",
    "\n",
    "        non_normalized_set_B_similarity_matrix =\n",
    "            entity_set_B_features * term_similarity * entity_set_B_features.T\n",
    "\n",
    "        normalization_denominator =\n",
    "            np.sqrt(\n",
    "                non_normalized_set_A_similarity_matrix.diagonal()[:,None] *\n",
    "                non_normalized_set_B_similarity_matrix.diagonal()\n",
    "            )\n",
    "\n",
    "        We then divide the raw_similarity_matrix by the normalization_denominator to get a\n",
    "        similarity_matrix (approximately) bounded by 0 and 1.\n",
    "        Note: Approximately as in practice we've seen values bounded by 1 but going slightly below\n",
    "        0, although we have not investigated why.\n",
    "\n",
    "        The normalization_denominator may have some 0 entries (unless all terms are used) as some\n",
    "        documents may have 0 for all features. These docs will have 0 self-similarity and we get\n",
    "        division by zero. This is not an issue as the numerator is bound to be 0 too, so we just\n",
    "        skip these cells in the division.\n",
    "\n",
    "        similarity_matrix[normalization_denominator>0] = (\n",
    "            raw_similarity_matrix[normalization_denominator>0] /\n",
    "            normalization_denominator[normalization_denominator>0]\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        raw_node_sim = (\n",
    "            self._node_term_matrix\n",
    "            * self._selected_terms_similarity\n",
    "            * self._node_term_matrix.T\n",
    "        )\n",
    "        normalization_denominator = np.sqrt(\n",
    "            raw_node_sim.diagonal()[:, None] * raw_node_sim.diagonal()\n",
    "        )\n",
    "        node_similarity_matrix = copy.deepcopy(raw_node_sim)\n",
    "        node_similarity_matrix[normalization_denominator > 0] = (\n",
    "            raw_node_sim[normalization_denominator > 0]\n",
    "            / normalization_denominator[normalization_denominator > 0]\n",
    "        )\n",
    "\n",
    "        self._node_similarity_matrix = node_similarity_matrix\n",
    "\n",
    "    def _build_node_abstraction_matrix(self):\n",
    "        \"\"\"Matrix mapping nodes (rows) to all related higher-order nodes (ie abstractions).\"\"\"\n",
    "\n",
    "        rows = list()\n",
    "        cols = list()\n",
    "        data = list()\n",
    "        for i in range(len(self._core_nodes)):\n",
    "            _, col, scores = zip(*self._get_node_abstractions(i))\n",
    "            row = np.array([i] * len(scores))\n",
    "            rows.extend(row)\n",
    "            cols.extend(col)\n",
    "            data.extend(scores)\n",
    "\n",
    "        rows = np.array(rows)\n",
    "        cols = np.array(cols)\n",
    "        data = np.array(data)\n",
    "\n",
    "        node_abstraction_matrix = csr_matrix(\n",
    "            (data, (rows, cols)), shape=(len(self._core_nodes), len(self._core_nodes))\n",
    "        )\n",
    "\n",
    "        self._node_abstraction_matrix = node_abstraction_matrix\n",
    "\n",
    "    def _get_node_abstractions(self, node_idx):\n",
    "        \"\"\"\n",
    "        Look up all higher-order nodes for given node_id and collect node.identifier and similarity\n",
    "        score.\n",
    "        \"\"\"\n",
    "        lineage = self._show_term_lineage(self._core_nodes[node_idx].identifier)\n",
    "\n",
    "        abstractions = [\n",
    "            (\n",
    "                l.tag,\n",
    "                self._node_id_to_idx[l.identifier],\n",
    "                self._node_similarity_matrix[\n",
    "                    node_idx, self._node_id_to_idx[l.identifier]\n",
    "                ],\n",
    "            )\n",
    "            for l in lineage\n",
    "            if self._node_id_to_idx.get(l.identifier) is not None\n",
    "        ]\n",
    "\n",
    "        return abstractions\n",
    "\n",
    "    def _show_term_lineage(self, node_id):\n",
    "        # Return all the parent nodes up to the top\n",
    "\n",
    "        lineage = [self.tree.nodes[node_id]]\n",
    "\n",
    "        while self.tree.parent(node_id) is not None:\n",
    "            lineage.append(self.tree.parent(node_id))\n",
    "            node_id = self.tree.parent(node_id).identifier\n",
    "\n",
    "        lineage.reverse()\n",
    "        return lineage\n",
    "\n",
    "    def _match_terms_to_nodes(self):\n",
    "        # Refer to discussion in _build_node_similarity_matrix\n",
    "        # Here we are matching the terms themselves to the nodes. The matrix in the left of\n",
    "        # selected_term_similarity would just be the identity matrix.\n",
    "        raw_term_to_node_sim = (\n",
    "            self._selected_terms_similarity * self._node_term_matrix.T\n",
    "        )\n",
    "\n",
    "        # non_normalized_single_term_similarity_matrix =\n",
    "        # identity x selected_term_similarity x identity -->\n",
    "        # selected_term_similarity (diagonal is one...)\n",
    "        non_normalized_node_similarity_matrix = (\n",
    "            self._node_term_matrix\n",
    "            * self._selected_terms_similarity\n",
    "            * self._node_term_matrix.T\n",
    "        )\n",
    "        normalization_denominator = np.sqrt(\n",
    "            self._selected_terms_similarity.diagonal()[:, None]\n",
    "            * non_normalized_node_similarity_matrix.diagonal()\n",
    "        )\n",
    "        term_to_node_sim = copy.deepcopy(raw_term_to_node_sim)\n",
    "        term_to_node_sim[normalization_denominator > 0] = (\n",
    "            raw_term_to_node_sim[normalization_denominator > 0]\n",
    "            / normalization_denominator[normalization_denominator > 0]\n",
    "        )\n",
    "        # Closest node to term. Matrix to dictionary.\n",
    "        term_to_node_matches = np.argmax(term_to_node_sim, axis=1)\n",
    "        self._term_to_node_idx = {\n",
    "            term: node_idx\n",
    "            for term, node_idx in zip(self.selected_terms, term_to_node_matches)\n",
    "        }\n",
    "\n",
    "    def _document_topics_to_tags(self, document_terms):\n",
    "        # For all document terms find matching closest node ids\n",
    "        node_ids = [self._term_to_node_idx[term] for term in document_terms]\n",
    "        # Look up nodes and their abstractions in node_abstraction_matrix\n",
    "        node_abstractions = self._node_abstraction_matrix[node_ids]\n",
    "        # Silence all abstractions below threshold similarity value\n",
    "        node_abstractions[node_abstractions <= self.min_abstraction_similarity] = 0\n",
    "        # Sum across to get document to tags match with weights\n",
    "        return node_abstractions.sum(axis=0)\n",
    "\n",
    "\n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, csr_matrix):\n",
    "            obj_coo = obj.tocoo()\n",
    "            return {\n",
    "                \"data\": obj_coo.data,\n",
    "                \"row\": obj_coo.row,\n",
    "                \"col\": obj_coo.col,\n",
    "                \"shape\": obj_coo.shape,\n",
    "            }\n",
    "        elif isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        else:\n",
    "            return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "def get_locations_set():\n",
    "    \"\"\"\n",
    "    Collects a standard set of locations to allow filtering these from the term set.\n",
    "    This is useful if clustering documents around location is not of interest.\n",
    "    As the step of filtering location names is computationally demanding,\n",
    "    we restrict the set to countries, capitals, and US states and cites\n",
    "    \"\"\"\n",
    "\n",
    "    # Continents, counties and capitals\n",
    "    # Reference: https://gist.github.com/pamelafox/986163\n",
    "    file_path = os.path.join(os.path.dirname(__file__), \"data/countries.json\")\n",
    "    with open(file_path) as f:\n",
    "        countries = json.load(f)\n",
    "\n",
    "    continents = set()\n",
    "    country_names = set()\n",
    "    capitals = set()\n",
    "    for country in countries:\n",
    "        continents.add(country[\"continent\"].lower())\n",
    "        country_names.add(country[\"name\"].lower())\n",
    "        capitals.add(country[\"capital\"].lower())\n",
    "\n",
    "    # US states\n",
    "    file_path = os.path.join(os.path.dirname(__file__), \"data/us_states.json\")\n",
    "    with open(file_path) as f:\n",
    "        state_names = json.load(f)\n",
    "    state_names = {s.lower() for s in state_names}\n",
    "\n",
    "    # Cities list; limit to US to restrict the set\n",
    "    # Reference: https://datahub.io/core/world-cities, which itself sources the data from https://www.geonames.org/.\n",
    "    file_path = os.path.join(os.path.dirname(__file__), \"data/world-cities.json\")\n",
    "    with open(file_path) as f:\n",
    "        world_cities = json.load(f)\n",
    "\n",
    "    us_cities_list = {\n",
    "        c[\"name\"] for c in world_cities if c[\"country\"] == \"United States\"\n",
    "    }\n",
    "\n",
    "    locations = continents | country_names | capitals | state_names | us_cities_list\n",
    "\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb380a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_averaging(sample):\n",
    "    topics = {}\n",
    "    all_kws = []\n",
    "    for s in sample:\n",
    "        all_kws += get_kws(s[\"text\"])\n",
    "    \n",
    "    #average\n",
    "    topic_mem = []\n",
    "    for kws in all_kws:\n",
    "        topic, prob = kws\n",
    "        topic_mem += [topic]\n",
    "        if topics.get(topic):\n",
    "            topics[topic] += prob\n",
    "        else:\n",
    "            topics[topic] = prob\n",
    "                \n",
    "    for topic, prob in topics.items():\n",
    "        #normalize topic probability\n",
    "        topics[topic] = topics[topic] / len([t for t in topic_mem if t == topic])\n",
    "    sort_ = {k: v for k, v in sorted(topics.items(), key=lambda item: item[1])}\n",
    "    return topics\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7538da",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_map = {}\n",
    "for tt in tree_topics:\n",
    "    q = query_index(tt, model, loc_topics, loc_index, True, 3)\n",
    "    if q[0][1] < 0.35:\n",
    "        loc_map[tt] = dict(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_index(\"acoustic\", model, loc_topics, loc_index, True, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea7e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
