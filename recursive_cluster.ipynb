{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fef4a14",
   "metadata": {},
   "source": [
    "# Recursive Clustering and Summarization\n",
    "\n",
    "Plan:\n",
    "- recursively cluster collections\n",
    "- create tree of clusters (the HDBSCAN does this anyways but likely not as we want)\n",
    "- cluster until max-depth is reached or (better) until each leaf only has one \"plausible\" cluster (based on thresholds or probabilities)\n",
    "- try summarizing to get \"main idea\" out of cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b4f8f7",
   "metadata": {},
   "source": [
    "## Recursively cluster \n",
    "\n",
    "Based on the topic_clustering notebook, we will try with Agglomerative Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efca2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"downloads/40k_balanced_pm_acl.csv\")#.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e2a65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = df[df.labels == 1]\n",
    "sentences = list(pos[\"text\"]) #otherwise key error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47dc1fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode the corpus ... get a coffee in the meantime\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd2af09177c492eafd0e791891e65cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "print(\"Encode the corpus ... get a coffee in the meantime\")\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = model.encode(sentences, batch_size=64, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c30526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "\n",
    "def cluster(embeddings, **kwargs):\n",
    "    embeddings = embeddings.cpu()\n",
    "    # Normalize the embeddings to unit length\n",
    "    corpus_embeddings = embeddings /  np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "    # Perform kmean clustering\n",
    "    clustering_model = AgglomerativeClustering(**kwargs) #, affinity='cosine', linkage='average', distance_threshold=0.4)\n",
    "    clustering_model.fit(corpus_embeddings)\n",
    "   # cluster_assignment = clustering_model.labels_\n",
    "    return clustering_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8ba55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(clustering_model):\n",
    "    \n",
    "    clusters = {}\n",
    "    for sentence_id, cluster_id in enumerate(clustering_model.labels_):\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        clusters[cluster_id].append(sentences[sentence_id])\n",
    "    return clusters\n",
    "   \n",
    "#     for i, cluster in clustered_sentences.items():\n",
    "#         print(\"Cluster \", i+1)\n",
    "#         print(cluster)\n",
    "#         print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c22001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = embeddings[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e088ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model = cluster(sample,n_clusters=None, distance_threshold=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca3ca33",
   "metadata": {},
   "source": [
    "Cluster Model attributes\n",
    "\n",
    "   n_clusters_ : int\n",
    "        The number of clusters found by the algorithm. If\n",
    "        ``distance_threshold=None``, it will be equal to the given\n",
    "        ``n_clusters``.\n",
    "\n",
    "    labels_\n",
    "    n_leaves_\n",
    "\n",
    "    n_connected_components_ : The estimated number of connected components in the graph.\n",
    "\n",
    "    children_ : array-like of shape (n_samples-1, 2)\n",
    "        The children of each non-leaf node. Values less than `n_samples`\n",
    "        correspond to leaves of the tree which are the original samples.\n",
    "        A node `i` greater than or equal to `n_samples` is a non-leaf\n",
    "        node and has children `children_[i - n_samples]`. Alternatively\n",
    "        at the i-th iteration, children[i][0] and children[i][1]\n",
    "        are merged to form node `n_samples + i`\n",
    "\n",
    "    distances_ : array-like of shape (n_nodes-1,)\n",
    "        Distances between nodes in the corresponding place in `children_`.\n",
    "        Only computed if `distance_threshold` is used or `compute_distances`\n",
    "        is set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c20e743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 175,  243],\n",
       "       [2079, 2652],\n",
       "       [4746, 4862],\n",
       "       ...,\n",
       "       [9987, 9992],\n",
       "       [9995, 9996],\n",
       "       [9994, 9997]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_model.children_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d84677b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'node_id': 1000, 'left': 175, 'right': 243},\n",
       " {'node_id': 1001, 'left': 506, 'right': 770},\n",
       " {'node_id': 1002, 'left': 41, 'right': 70},\n",
       " {'node_id': 1003, 'left': 599, 'right': 676},\n",
       " {'node_id': 1004, 'left': 425, 'right': 460},\n",
       " {'node_id': 1005, 'left': 556, 'right': 620},\n",
       " {'node_id': 1006, 'left': 110, 'right': 172},\n",
       " {'node_id': 1007, 'left': 616, 'right': 956},\n",
       " {'node_id': 1008, 'left': 644, 'right': 767},\n",
       " {'node_id': 1009, 'left': 835, 'right': 916},\n",
       " {'node_id': 1010, 'left': 868, 'right': 1008},\n",
       " {'node_id': 1011, 'left': 726, 'right': 727},\n",
       " {'node_id': 1012, 'left': 827, 'right': 936},\n",
       " {'node_id': 1013, 'left': 187, 'right': 189},\n",
       " {'node_id': 1014, 'left': 31, 'right': 436},\n",
       " {'node_id': 1015, 'left': 545, 'right': 575},\n",
       " {'node_id': 1016, 'left': 647, 'right': 659},\n",
       " {'node_id': 1017, 'left': 267, 'right': 403},\n",
       " {'node_id': 1018, 'left': 816, 'right': 944},\n",
       " {'node_id': 1019, 'left': 803, 'right': 838},\n",
       " {'node_id': 1020, 'left': 592, 'right': 924},\n",
       " {'node_id': 1021, 'left': 351, 'right': 378},\n",
       " {'node_id': 1022, 'left': 624, 'right': 823},\n",
       " {'node_id': 1023, 'left': 517, 'right': 585},\n",
       " {'node_id': 1024, 'left': 571, 'right': 1019},\n",
       " {'node_id': 1025, 'left': 589, 'right': 852},\n",
       " {'node_id': 1026, 'left': 520, 'right': 700},\n",
       " {'node_id': 1027, 'left': 103, 'right': 157},\n",
       " {'node_id': 1028, 'left': 388, 'right': 1021},\n",
       " {'node_id': 1029, 'left': 801, 'right': 833},\n",
       " {'node_id': 1030, 'left': 927, 'right': 955},\n",
       " {'node_id': 1031, 'left': 744, 'right': 781},\n",
       " {'node_id': 1032, 'left': 900, 'right': 986},\n",
       " {'node_id': 1033, 'left': 794, 'right': 856},\n",
       " {'node_id': 1034, 'left': 684, 'right': 793},\n",
       " {'node_id': 1035, 'left': 13, 'right': 126},\n",
       " {'node_id': 1036, 'left': 558, 'right': 694},\n",
       " {'node_id': 1037, 'left': 65, 'right': 109},\n",
       " {'node_id': 1038, 'left': 202, 'right': 370},\n",
       " {'node_id': 1039, 'left': 469, 'right': 1017},\n",
       " {'node_id': 1040, 'left': 696, 'right': 743},\n",
       " {'node_id': 1041, 'left': 582, 'right': 965},\n",
       " {'node_id': 1042, 'left': 14, 'right': 19},\n",
       " {'node_id': 1043, 'left': 685, 'right': 881},\n",
       " {'node_id': 1044, 'left': 10, 'right': 272},\n",
       " {'node_id': 1045, 'left': 152, 'right': 156},\n",
       " {'node_id': 1046, 'left': 882, 'right': 923},\n",
       " {'node_id': 1047, 'left': 348, 'right': 369},\n",
       " {'node_id': 1048, 'left': 498, 'right': 820},\n",
       " {'node_id': 1049, 'left': 710, 'right': 996},\n",
       " {'node_id': 1050, 'left': 150, 'right': 327},\n",
       " {'node_id': 1051, 'left': 241, 'right': 449},\n",
       " {'node_id': 1052, 'left': 240, 'right': 301},\n",
       " {'node_id': 1053, 'left': 786, 'right': 914},\n",
       " {'node_id': 1054, 'left': 124, 'right': 292},\n",
       " {'node_id': 1055, 'left': 839, 'right': 995},\n",
       " {'node_id': 1056, 'left': 768, 'right': 849},\n",
       " {'node_id': 1057, 'left': 967, 'right': 971},\n",
       " {'node_id': 1058, 'left': 594, 'right': 893},\n",
       " {'node_id': 1059, 'left': 636, 'right': 677},\n",
       " {'node_id': 1060, 'left': 739, 'right': 844},\n",
       " {'node_id': 1061, 'left': 966, 'right': 1034},\n",
       " {'node_id': 1062, 'left': 715, 'right': 951},\n",
       " {'node_id': 1063, 'left': 745, 'right': 939},\n",
       " {'node_id': 1064, 'left': 338, 'right': 447},\n",
       " {'node_id': 1065, 'left': 654, 'right': 683},\n",
       " {'node_id': 1066, 'left': 75, 'right': 119},\n",
       " {'node_id': 1067, 'left': 151, 'right': 1045},\n",
       " {'node_id': 1068, 'left': 69, 'right': 121},\n",
       " {'node_id': 1069, 'left': 418, 'right': 456},\n",
       " {'node_id': 1070, 'left': 717, 'right': 948},\n",
       " {'node_id': 1071, 'left': 15, 'right': 57},\n",
       " {'node_id': 1072, 'left': 591, 'right': 614},\n",
       " {'node_id': 1073, 'left': 600, 'right': 718},\n",
       " {'node_id': 1074, 'left': 433, 'right': 467},\n",
       " {'node_id': 1075, 'left': 999, 'right': 1060},\n",
       " {'node_id': 1076, 'left': 729, 'right': 1001},\n",
       " {'node_id': 1077, 'left': 101, 'right': 123},\n",
       " {'node_id': 1078, 'left': 213, 'right': 262},\n",
       " {'node_id': 1079, 'left': 915, 'right': 989},\n",
       " {'node_id': 1080, 'left': 497, 'right': 499},\n",
       " {'node_id': 1081, 'left': 27, 'right': 229},\n",
       " {'node_id': 1082, 'left': 111, 'right': 200},\n",
       " {'node_id': 1083, 'left': 513, 'right': 521},\n",
       " {'node_id': 1084, 'left': 341, 'right': 395},\n",
       " {'node_id': 1085, 'left': 361, 'right': 473},\n",
       " {'node_id': 1086, 'left': 755, 'right': 870},\n",
       " {'node_id': 1087, 'left': 204, 'right': 265},\n",
       " {'node_id': 1088, 'left': 800, 'right': 979},\n",
       " {'node_id': 1089, 'left': 334, 'right': 1054},\n",
       " {'node_id': 1090, 'left': 437, 'right': 1028},\n",
       " {'node_id': 1091, 'left': 3, 'right': 342},\n",
       " {'node_id': 1092, 'left': 28, 'right': 446},\n",
       " {'node_id': 1093, 'left': 194, 'right': 1051},\n",
       " {'node_id': 1094, 'left': 39, 'right': 415},\n",
       " {'node_id': 1095, 'left': 160, 'right': 411},\n",
       " {'node_id': 1096, 'left': 655, 'right': 901},\n",
       " {'node_id': 1097, 'left': 252, 'right': 1027},\n",
       " {'node_id': 1098, 'left': 77, 'right': 458},\n",
       " {'node_id': 1099, 'left': 812, 'right': 815},\n",
       " {'node_id': 1100, 'left': 24, 'right': 404},\n",
       " {'node_id': 1101, 'left': 525, 'right': 1007},\n",
       " {'node_id': 1102, 'left': 162, 'right': 432},\n",
       " {'node_id': 1103, 'left': 35, 'right': 357},\n",
       " {'node_id': 1104, 'left': 6, 'right': 89},\n",
       " {'node_id': 1105, 'left': 784, 'right': 859},\n",
       " {'node_id': 1106, 'left': 163, 'right': 230},\n",
       " {'node_id': 1107, 'left': 271, 'right': 329},\n",
       " {'node_id': 1108, 'left': 286, 'right': 314},\n",
       " {'node_id': 1109, 'left': 44, 'right': 239},\n",
       " {'node_id': 1110, 'left': 165, 'right': 1038},\n",
       " {'node_id': 1111, 'left': 625, 'right': 920},\n",
       " {'node_id': 1112, 'left': 90, 'right': 289},\n",
       " {'node_id': 1113, 'left': 224, 'right': 464},\n",
       " {'node_id': 1114, 'left': 290, 'right': 406},\n",
       " {'node_id': 1115, 'left': 153, 'right': 256},\n",
       " {'node_id': 1116, 'left': 528, 'right': 588},\n",
       " {'node_id': 1117, 'left': 7, 'right': 371},\n",
       " {'node_id': 1118, 'left': 142, 'right': 269},\n",
       " {'node_id': 1119, 'left': 112, 'right': 197},\n",
       " {'node_id': 1120, 'left': 822, 'right': 980},\n",
       " {'node_id': 1121, 'left': 79, 'right': 1098},\n",
       " {'node_id': 1122, 'left': 777, 'right': 988},\n",
       " {'node_id': 1123, 'left': 420, 'right': 448},\n",
       " {'node_id': 1124, 'left': 761, 'right': 962},\n",
       " {'node_id': 1125, 'left': 21, 'right': 1069},\n",
       " {'node_id': 1126, 'left': 67, 'right': 482},\n",
       " {'node_id': 1127, 'left': 836, 'right': 973},\n",
       " {'node_id': 1128, 'left': 645, 'right': 661},\n",
       " {'node_id': 1129, 'left': 138, 'right': 372},\n",
       " {'node_id': 1130, 'left': 127, 'right': 336},\n",
       " {'node_id': 1131, 'left': 20, 'right': 169},\n",
       " {'node_id': 1132, 'left': 626, 'right': 635},\n",
       " {'node_id': 1133, 'left': 1, 'right': 11},\n",
       " {'node_id': 1134, 'left': 164, 'right': 191},\n",
       " {'node_id': 1135, 'left': 610, 'right': 630},\n",
       " {'node_id': 1136, 'left': 16, 'right': 494},\n",
       " {'node_id': 1137, 'left': 787, 'right': 1026},\n",
       " {'node_id': 1138, 'left': 377, 'right': 478},\n",
       " {'node_id': 1139, 'left': 4, 'right': 108},\n",
       " {'node_id': 1140, 'left': 668, 'right': 795},\n",
       " {'node_id': 1141, 'left': 195, 'right': 274},\n",
       " {'node_id': 1142, 'left': 261, 'right': 387},\n",
       " {'node_id': 1143, 'left': 297, 'right': 366},\n",
       " {'node_id': 1144, 'left': 143, 'right': 413},\n",
       " {'node_id': 1145, 'left': 139, 'right': 237},\n",
       " {'node_id': 1146, 'left': 353, 'right': 475},\n",
       " {'node_id': 1147, 'left': 226, 'right': 440},\n",
       " {'node_id': 1148, 'left': 578, 'right': 738},\n",
       " {'node_id': 1149, 'left': 305, 'right': 355},\n",
       " {'node_id': 1150, 'left': 83, 'right': 330},\n",
       " {'node_id': 1151, 'left': 746, 'right': 880},\n",
       " {'node_id': 1152, 'left': 527, 'right': 576},\n",
       " {'node_id': 1153, 'left': 1068, 'right': 1095},\n",
       " {'node_id': 1154, 'left': 553, 'right': 918},\n",
       " {'node_id': 1155, 'left': 579, 'right': 937},\n",
       " {'node_id': 1156, 'left': 492, 'right': 1134},\n",
       " {'node_id': 1157, 'left': 560, 'right': 1116},\n",
       " {'node_id': 1158, 'left': 788, 'right': 1018},\n",
       " {'node_id': 1159, 'left': 711, 'right': 1056},\n",
       " {'node_id': 1160, 'left': 496, 'right': 1067},\n",
       " {'node_id': 1161, 'left': 479, 'right': 1071},\n",
       " {'node_id': 1162, 'left': 875, 'right': 898},\n",
       " {'node_id': 1163, 'left': 38, 'right': 427},\n",
       " {'node_id': 1164, 'left': 287, 'right': 359},\n",
       " {'node_id': 1165, 'left': 615, 'right': 818},\n",
       " {'node_id': 1166, 'left': 550, 'right': 617},\n",
       " {'node_id': 1167, 'left': 438, 'right': 488},\n",
       " {'node_id': 1168, 'left': 298, 'right': 495},\n",
       " {'node_id': 1169, 'left': 332, 'right': 1087},\n",
       " {'node_id': 1170, 'left': 876, 'right': 907},\n",
       " {'node_id': 1171, 'left': 349, 'right': 426},\n",
       " {'node_id': 1172, 'left': 315, 'right': 316},\n",
       " {'node_id': 1173, 'left': 231, 'right': 266},\n",
       " {'node_id': 1174, 'left': 185, 'right': 247},\n",
       " {'node_id': 1175, 'left': 294, 'right': 379},\n",
       " {'node_id': 1176, 'left': 149, 'right': 210},\n",
       " {'node_id': 1177, 'left': 42, 'right': 323},\n",
       " {'node_id': 1178, 'left': 511, 'right': 532},\n",
       " {'node_id': 1179, 'left': 802, 'right': 1033},\n",
       " {'node_id': 1180, 'left': 728, 'right': 1043},\n",
       " {'node_id': 1181, 'left': 308, 'right': 374},\n",
       " {'node_id': 1182, 'left': 270, 'right': 1139},\n",
       " {'node_id': 1183, 'left': 889, 'right': 941},\n",
       " {'node_id': 1184, 'left': 105, 'right': 365},\n",
       " {'node_id': 1185, 'left': 580, 'right': 808},\n",
       " {'node_id': 1186, 'left': 593, 'right': 925},\n",
       " {'node_id': 1187, 'left': 522, 'right': 535},\n",
       " {'node_id': 1188, 'left': 670, 'right': 695},\n",
       " {'node_id': 1189, 'left': 212, 'right': 257},\n",
       " {'node_id': 1190, 'left': 805, 'right': 913},\n",
       " {'node_id': 1191, 'left': 131, 'right': 173},\n",
       " {'node_id': 1192, 'left': 762, 'right': 774},\n",
       " {'node_id': 1193, 'left': 188, 'right': 1113},\n",
       " {'node_id': 1194, 'left': 487, 'right': 1108},\n",
       " {'node_id': 1195, 'left': 264, 'right': 468},\n",
       " {'node_id': 1196, 'left': 681, 'right': 853},\n",
       " {'node_id': 1197, 'left': 343, 'right': 1119},\n",
       " {'node_id': 1198, 'left': 536, 'right': 568},\n",
       " {'node_id': 1199, 'left': 192, 'right': 347},\n",
       " {'node_id': 1200, 'left': 66, 'right': 434},\n",
       " {'node_id': 1201, 'left': 791, 'right': 1053},\n",
       " {'node_id': 1202, 'left': 43, 'right': 155},\n",
       " {'node_id': 1203, 'left': 326, 'right': 1131},\n",
       " {'node_id': 1204, 'left': 106, 'right': 249},\n",
       " {'node_id': 1205, 'left': 87, 'right': 179},\n",
       " {'node_id': 1206, 'left': 376, 'right': 397},\n",
       " {'node_id': 1207, 'left': 86, 'right': 255},\n",
       " {'node_id': 1208, 'left': 674, 'right': 964},\n",
       " {'node_id': 1209, 'left': 76, 'right': 435},\n",
       " {'node_id': 1210, 'left': 1089, 'right': 1156},\n",
       " {'node_id': 1211, 'left': 825, 'right': 977},\n",
       " {'node_id': 1212, 'left': 878, 'right': 950},\n",
       " {'node_id': 1213, 'left': 414, 'right': 1047},\n",
       " {'node_id': 1214, 'left': 40, 'right': 168},\n",
       " {'node_id': 1215, 'left': 510, 'right': 692},\n",
       " {'node_id': 1216, 'left': 640, 'right': 1030},\n",
       " {'node_id': 1217, 'left': 910, 'right': 926},\n",
       " {'node_id': 1218, 'left': 178, 'right': 1100},\n",
       " {'node_id': 1219, 'left': 260, 'right': 345},\n",
       " {'node_id': 1220, 'left': 102, 'right': 288},\n",
       " {'node_id': 1221, 'left': 36, 'right': 214},\n",
       " {'node_id': 1222, 'left': 867, 'right': 938},\n",
       " {'node_id': 1223, 'left': 573, 'right': 721},\n",
       " {'node_id': 1224, 'left': 735, 'right': 769},\n",
       " {'node_id': 1225, 'left': 17, 'right': 268},\n",
       " {'node_id': 1226, 'left': 166, 'right': 285},\n",
       " {'node_id': 1227, 'left': 789, 'right': 946},\n",
       " {'node_id': 1228, 'left': 392, 'right': 423},\n",
       " {'node_id': 1229, 'left': 634, 'right': 1065},\n",
       " {'node_id': 1230, 'left': 97, 'right': 246},\n",
       " {'node_id': 1231, 'left': 23, 'right': 381},\n",
       " {'node_id': 1232, 'left': 81, 'right': 408},\n",
       " {'node_id': 1233, 'left': 211, 'right': 328},\n",
       " {'node_id': 1234, 'left': 873, 'right': 885},\n",
       " {'node_id': 1235, 'left': 766, 'right': 963},\n",
       " {'node_id': 1236, 'left': 555, 'right': 976},\n",
       " {'node_id': 1237, 'left': 799, 'right': 892},\n",
       " {'node_id': 1238, 'left': 754, 'right': 922},\n",
       " {'node_id': 1239, 'left': 662, 'right': 680},\n",
       " {'node_id': 1240, 'left': 544, 'right': 1178},\n",
       " {'node_id': 1241, 'left': 48, 'right': 245},\n",
       " {'node_id': 1242, 'left': 227, 'right': 459},\n",
       " {'node_id': 1243, 'left': 810, 'right': 919},\n",
       " {'node_id': 1244, 'left': 612, 'right': 749},\n",
       " {'node_id': 1245, 'left': 310, 'right': 340},\n",
       " {'node_id': 1246, 'left': 154, 'right': 228},\n",
       " {'node_id': 1247, 'left': 95, 'right': 222},\n",
       " {'node_id': 1248, 'left': 542, 'right': 577},\n",
       " {'node_id': 1249, 'left': 64, 'right': 463},\n",
       " {'node_id': 1250, 'left': 304, 'right': 1078},\n",
       " {'node_id': 1251, 'left': 405, 'right': 1150},\n",
       " {'node_id': 1252, 'left': 826, 'right': 906},\n",
       " {'node_id': 1253, 'left': 391, 'right': 410},\n",
       " {'node_id': 1254, 'left': 760, 'right': 970},\n",
       " {'node_id': 1255, 'left': 562, 'right': 669},\n",
       " {'node_id': 1256, 'left': 107, 'right': 350},\n",
       " {'node_id': 1257, 'left': 734, 'right': 1046},\n",
       " {'node_id': 1258, 'left': 129, 'right': 1044},\n",
       " {'node_id': 1259, 'left': 508, 'right': 994},\n",
       " {'node_id': 1260, 'left': 523, 'right': 691},\n",
       " {'node_id': 1261, 'left': 55, 'right': 364},\n",
       " {'node_id': 1262, 'left': 235, 'right': 373},\n",
       " {'node_id': 1263, 'left': 284, 'right': 1102},\n",
       " {'node_id': 1264, 'left': 824, 'right': 933},\n",
       " {'node_id': 1265, 'left': 723, 'right': 851},\n",
       " {'node_id': 1266, 'left': 778, 'right': 1029},\n",
       " {'node_id': 1267, 'left': 34, 'right': 299},\n",
       " {'node_id': 1268, 'left': 419, 'right': 486},\n",
       " {'node_id': 1269, 'left': 831, 'right': 1049},\n",
       " {'node_id': 1270, 'left': 572, 'right': 699},\n",
       " {'node_id': 1271, 'left': 394, 'right': 1169},\n",
       " {'node_id': 1272, 'left': 346, 'right': 1082},\n",
       " {'node_id': 1273, 'left': 280, 'right': 318},\n",
       " {'node_id': 1274, 'left': 417, 'right': 1052},\n",
       " {'node_id': 1275, 'left': 282, 'right': 363},\n",
       " {'node_id': 1276, 'left': 302, 'right': 1181},\n",
       " {'node_id': 1277, 'left': 276, 'right': 306},\n",
       " {'node_id': 1278, 'left': 94, 'right': 1125},\n",
       " {'node_id': 1279, 'left': 949, 'right': 954},\n",
       " {'node_id': 1280, 'left': 82, 'right': 130},\n",
       " {'node_id': 1281, 'left': 445, 'right': 471},\n",
       " {'node_id': 1282, 'left': 29, 'right': 1173},\n",
       " {'node_id': 1283, 'left': 333, 'right': 465},\n",
       " {'node_id': 1284, 'left': 113, 'right': 773},\n",
       " {'node_id': 1285, 'left': 140, 'right': 254},\n",
       " {'node_id': 1286, 'left': 54, 'right': 1142},\n",
       " {'node_id': 1287, 'left': 621, 'right': 701},\n",
       " {'node_id': 1288, 'left': 100, 'right': 360},\n",
       " {'node_id': 1289, 'left': 763, 'right': 814},\n",
       " {'node_id': 1290, 'left': 367, 'right': 1191},\n",
       " {'node_id': 1291, 'left': 258, 'right': 322},\n",
       " {'node_id': 1292, 'left': 500, 'right': 908},\n",
       " {'node_id': 1293, 'left': 96, 'right': 421},\n",
       " {'node_id': 1294, 'left': 537, 'right': 1132},\n",
       " {'node_id': 1295, 'left': 33, 'right': 389},\n",
       " {'node_id': 1296, 'left': 26, 'right': 1039},\n",
       " {'node_id': 1297, 'left': 45, 'right': 319},\n",
       " {'node_id': 1298, 'left': 9, 'right': 51},\n",
       " {'node_id': 1299, 'left': 1093, 'right': 1213},\n",
       " {'node_id': 1300, 'left': 321, 'right': 1085},\n",
       " {'node_id': 1301, 'left': 98, 'right': 390},\n",
       " {'node_id': 1302, 'left': 368, 'right': 430},\n",
       " {'node_id': 1303, 'left': 566, 'right': 1059},\n",
       " {'node_id': 1304, 'left': 1141, 'right': 1176},\n",
       " {'node_id': 1305, 'left': 565, 'right': 891},\n",
       " {'node_id': 1306, 'left': 1091, 'right': 1123},\n",
       " {'node_id': 1307, 'left': 325, 'right': 1117},\n",
       " {'node_id': 1308, 'left': 529, 'right': 931},\n",
       " {'node_id': 1309, 'left': 958, 'right': 1244},\n",
       " {'node_id': 1310, 'left': 84, 'right': 477},\n",
       " {'node_id': 1311, 'left': 146, 'right': 225},\n",
       " {'node_id': 1312, 'left': 232, 'right': 291},\n",
       " {'node_id': 1313, 'left': 50, 'right': 1258},\n",
       " {'node_id': 1314, 'left': 205, 'right': 1110},\n",
       " {'node_id': 1315, 'left': 120, 'right': 1107},\n",
       " {'node_id': 1316, 'left': 0, 'right': 1214},\n",
       " {'node_id': 1317, 'left': 470, 'right': 1133},\n",
       " {'node_id': 1318, 'left': 184, 'right': 1129},\n",
       " {'node_id': 1319, 'left': 1163, 'right': 1167},\n",
       " {'node_id': 1320, 'left': 416, 'right': 443},\n",
       " {'node_id': 1321, 'left': 561, 'right': 897},\n",
       " {'node_id': 1322, 'left': 790, 'right': 890},\n",
       " {'node_id': 1323, 'left': 606, 'right': 854},\n",
       " {'node_id': 1324, 'left': 181, 'right': 309},\n",
       " {'node_id': 1325, 'left': 472, 'right': 1200},\n",
       " {'node_id': 1326, 'left': 596, 'right': 682},\n",
       " {'node_id': 1327, 'left': 236, 'right': 476},\n",
       " {'node_id': 1328, 'left': 864, 'right': 1236},\n",
       " {'node_id': 1329, 'left': 846, 'right': 904},\n",
       " {'node_id': 1330, 'left': 335, 'right': 1177},\n",
       " {'node_id': 1331, 'left': 656, 'right': 887},\n",
       " {'node_id': 1332, 'left': 806, 'right': 1011},\n",
       " {'node_id': 1333, 'left': 190, 'right': 375},\n",
       " {'node_id': 1334, 'left': 719, 'right': 843},\n",
       " {'node_id': 1335, 'left': 895, 'right': 1079},\n",
       " {'node_id': 1336, 'left': 862, 'right': 1222},\n",
       " {'node_id': 1337, 'left': 12, 'right': 171},\n",
       " {'node_id': 1338, 'left': 58, 'right': 1144},\n",
       " {'node_id': 1339, 'left': 830, 'right': 1180},\n",
       " {'node_id': 1340, 'left': 145, 'right': 401},\n",
       " {'node_id': 1341, 'left': 5, 'right': 161},\n",
       " {'node_id': 1342, 'left': 538, 'right': 1254},\n",
       " {'node_id': 1343, 'left': 253, 'right': 452},\n",
       " {'node_id': 1344, 'left': 52, 'right': 1246},\n",
       " {'node_id': 1345, 'left': 278, 'right': 1138},\n",
       " {'node_id': 1346, 'left': 618, 'right': 623},\n",
       " {'node_id': 1347, 'left': 92, 'right': 331},\n",
       " {'node_id': 1348, 'left': 312, 'right': 385},\n",
       " {'node_id': 1349, 'left': 811, 'right': 842},\n",
       " {'node_id': 1350, 'left': 118, 'right': 462},\n",
       " {'node_id': 1351, 'left': 114, 'right': 250},\n",
       " {'node_id': 1352, 'left': 514, 'right': 518},\n",
       " {'node_id': 1353, 'left': 344, 'right': 1203},\n",
       " {'node_id': 1354, 'left': 295, 'right': 380},\n",
       " {'node_id': 1355, 'left': 174, 'right': 461},\n",
       " {'node_id': 1356, 'left': 167, 'right': 1112},\n",
       " {'node_id': 1357, 'left': 72, 'right': 317},\n",
       " {'node_id': 1358, 'left': 489, 'right': 1193},\n",
       " {'node_id': 1359, 'left': 943, 'right': 1235},\n",
       " {'node_id': 1360, 'left': 848, 'right': 1287},\n",
       " {'node_id': 1361, 'left': 117, 'right': 183},\n",
       " {'node_id': 1362, 'left': 217, 'right': 407},\n",
       " {'node_id': 1363, 'left': 741, 'right': 935},\n",
       " {'node_id': 1364, 'left': 584, 'right': 708},\n",
       " {'node_id': 1365, 'left': 716, 'right': 1105},\n",
       " {'node_id': 1366, 'left': 1114, 'right': 1283},\n",
       " {'node_id': 1367, 'left': 837, 'right': 1120},\n",
       " {'node_id': 1368, 'left': 78, 'right': 1199},\n",
       " {'node_id': 1369, 'left': 339, 'right': 431},\n",
       " {'node_id': 1370, 'left': 554, 'right': 796},\n",
       " {'node_id': 1371, 'left': 551, 'right': 797},\n",
       " {'node_id': 1372, 'left': 601, 'right': 934},\n",
       " {'node_id': 1373, 'left': 68, 'right': 134},\n",
       " {'node_id': 1374, 'left': 273, 'right': 441},\n",
       " {'node_id': 1375, 'left': 604, 'right': 972},\n",
       " {'node_id': 1376, 'left': 176, 'right': 275},\n",
       " {'node_id': 1377, 'left': 637, 'right': 1183},\n",
       " {'node_id': 1378, 'left': 454, 'right': 1249},\n",
       " {'node_id': 1379, 'left': 732, 'right': 886},\n",
       " {'node_id': 1380, 'left': 649, 'right': 807},\n",
       " {'node_id': 1381, 'left': 122, 'right': 485},\n",
       " {'node_id': 1382, 'left': 384, 'right': 490},\n",
       " {'node_id': 1383, 'left': 147, 'right': 457},\n",
       " {'node_id': 1384, 'left': 828, 'right': 877},\n",
       " {'node_id': 1385, 'left': 730, 'right': 771},\n",
       " {'node_id': 1386, 'left': 1137, 'right': 1212},\n",
       " {'node_id': 1387, 'left': 639, 'right': 660},\n",
       " {'node_id': 1388, 'left': 845, 'right': 1188},\n",
       " {'node_id': 1389, 'left': 667, 'right': 930},\n",
       " {'node_id': 1390, 'left': 759, 'right': 985},\n",
       " {'node_id': 1391, 'left': 991, 'right': 1058},\n",
       " {'node_id': 1392, 'left': 53, 'right': 1194},\n",
       " {'node_id': 1393, 'left': 144, 'right': 393},\n",
       " {'node_id': 1394, 'left': 450, 'right': 1230},\n",
       " {'node_id': 1395, 'left': 358, 'right': 1204},\n",
       " {'node_id': 1396, 'left': 1097, 'right': 1182},\n",
       " {'node_id': 1397, 'left': 1092, 'right': 1143},\n",
       " {'node_id': 1398, 'left': 80, 'right': 193},\n",
       " {'node_id': 1399, 'left': 629, 'right': 929},\n",
       " {'node_id': 1400, 'left': 491, 'right': 1160},\n",
       " {'node_id': 1401, 'left': 595, 'right': 1088},\n",
       " {'node_id': 1402, 'left': 1259, 'right': 1264},\n",
       " {'node_id': 1403, 'left': 559, 'right': 1185},\n",
       " {'node_id': 1404, 'left': 104, 'right': 1242},\n",
       " {'node_id': 1405, 'left': 125, 'right': 444},\n",
       " {'node_id': 1406, 'left': 244, 'right': 1318},\n",
       " {'node_id': 1407, 'left': 515, 'right': 737},\n",
       " {'node_id': 1408, 'left': 1109, 'right': 1207},\n",
       " {'node_id': 1409, 'left': 702, 'right': 819},\n",
       " {'node_id': 1410, 'left': 570, 'right': 857},\n",
       " {'node_id': 1411, 'left': 141, 'right': 451},\n",
       " {'node_id': 1412, 'left': 952, 'right': 1335},\n",
       " {'node_id': 1413, 'left': 724, 'right': 829},\n",
       " {'node_id': 1414, 'left': 879, 'right': 1055},\n",
       " {'node_id': 1415, 'left': 675, 'right': 840},\n",
       " {'node_id': 1416, 'left': 115, 'right': 1268},\n",
       " {'node_id': 1417, 'left': 780, 'right': 865},\n",
       " {'node_id': 1418, 'left': 1232, 'right': 1300},\n",
       " {'node_id': 1419, 'left': 779, 'right': 855},\n",
       " {'node_id': 1420, 'left': 137, 'right': 1298},\n",
       " {'node_id': 1421, 'left': 608, 'right': 671},\n",
       " {'node_id': 1422, 'left': 1086, 'right': 1252},\n",
       " {'node_id': 1423, 'left': 821, 'right': 975},\n",
       " {'node_id': 1424, 'left': 158, 'right': 1035},\n",
       " {'node_id': 1425, 'left': 484, 'right': 1299},\n",
       " {'node_id': 1426, 'left': 731, 'right': 1025},\n",
       " {'node_id': 1427, 'left': 1130, 'right': 1225},\n",
       " {'node_id': 1428, 'left': 509, 'right': 516},\n",
       " {'node_id': 1429, 'left': 277, 'right': 1301},\n",
       " {'node_id': 1430, 'left': 539, 'right': 622},\n",
       " {'node_id': 1431, 'left': 483, 'right': 747},\n",
       " {'node_id': 1432, 'left': 2, 'right': 1136},\n",
       " {'node_id': 1433, 'left': 1263, 'right': 1302},\n",
       " {'node_id': 1434, 'left': 638, 'right': 758},\n",
       " {'node_id': 1435, 'left': 792, 'right': 884},\n",
       " {'node_id': 1436, 'left': 234, 'right': 1348},\n",
       " {'node_id': 1437, 'left': 206, 'right': 281},\n",
       " {'node_id': 1438, 'left': 541, 'right': 863},\n",
       " {'node_id': 1439, 'left': 25, 'right': 1195},\n",
       " {'node_id': 1440, 'left': 928, 'right': 1157},\n",
       " {'node_id': 1441, 'left': 1210, 'right': 1274},\n",
       " {'node_id': 1442, 'left': 1121, 'right': 1126},\n",
       " {'node_id': 1443, 'left': 1261, 'right': 1277},\n",
       " {'node_id': 1444, 'left': 501, 'right': 1190},\n",
       " {'node_id': 1445, 'left': 524, 'right': 888},\n",
       " {'node_id': 1446, 'left': 698, 'right': 871},\n",
       " {'node_id': 1447, 'left': 354, 'right': 740},\n",
       " {'node_id': 1448, 'left': 177, 'right': 196},\n",
       " {'node_id': 1449, 'left': 128, 'right': 242},\n",
       " {'node_id': 1450, 'left': 1115, 'right': 1221},\n",
       " {'node_id': 1451, 'left': 88, 'right': 1354},\n",
       " {'node_id': 1452, 'left': 148, 'right': 1168},\n",
       " {'node_id': 1453, 'left': 507, 'right': 894},\n",
       " {'node_id': 1454, 'left': 834, 'right': 1279},\n",
       " {'node_id': 1455, 'left': 707, 'right': 912},\n",
       " {'node_id': 1456, 'left': 320, 'right': 382},\n",
       " {'node_id': 1457, 'left': 982, 'right': 1265},\n",
       " {'node_id': 1458, 'left': 386, 'right': 1146},\n",
       " {'node_id': 1459, 'left': 804, 'right': 847},\n",
       " {'node_id': 1460, 'left': 911, 'right': 1152},\n",
       " {'node_id': 1461, 'left': 552, 'right': 899},\n",
       " {'node_id': 1462, 'left': 135, 'right': 1233},\n",
       " {'node_id': 1463, 'left': 689, 'right': 753},\n",
       " {'node_id': 1464, 'left': 409, 'right': 1273},\n",
       " {'node_id': 1465, 'left': 60, 'right': 1351},\n",
       " {'node_id': 1466, 'left': 8, 'right': 422},\n",
       " {'node_id': 1467, 'left': 658, 'right': 756},\n",
       " {'node_id': 1468, 'left': 567, 'right': 1096},\n",
       " {'node_id': 1469, 'left': 978, 'right': 1155},\n",
       " {'node_id': 1470, 'left': 37, 'right': 186},\n",
       " {'node_id': 1471, 'left': 549, 'right': 605},\n",
       " {'node_id': 1472, 'left': 633, 'right': 798},\n",
       " {'node_id': 1473, 'left': 619, 'right': 666},\n",
       " {'node_id': 1474, 'left': 233, 'right': 402},\n",
       " {'node_id': 1475, 'left': 776, 'right': 866},\n",
       " {'node_id': 1476, 'left': 429, 'right': 1355},\n",
       " {'node_id': 1477, 'left': 613, 'right': 648},\n",
       " {'node_id': 1478, 'left': 540, 'right': 706},\n",
       " {'node_id': 1479, 'left': 1247, 'right': 1272},\n",
       " {'node_id': 1480, 'left': 203, 'right': 1362},\n",
       " {'node_id': 1481, 'left': 71, 'right': 424},\n",
       " {'node_id': 1482, 'left': 832, 'right': 874},\n",
       " {'node_id': 1483, 'left': 32, 'right': 493},\n",
       " {'node_id': 1484, 'left': 99, 'right': 399},\n",
       " {'node_id': 1485, 'left': 598, 'right': 765},\n",
       " {'node_id': 1486, 'left': 1227, 'right': 1469},\n",
       " {'node_id': 1487, 'left': 199, 'right': 1343},\n",
       " {'node_id': 1488, 'left': 990, 'right': 1248},\n",
       " {'node_id': 1489, 'left': 653, 'right': 809},\n",
       " {'node_id': 1490, 'left': 611, 'right': 1422},\n",
       " {'node_id': 1491, 'left': 1037, 'right': 1425},\n",
       " {'node_id': 1492, 'left': 1280, 'right': 1291},\n",
       " {'node_id': 1493, 'left': 531, 'right': 665},\n",
       " {'node_id': 1494, 'left': 564, 'right': 1326},\n",
       " {'node_id': 1495, 'left': 504, 'right': 543},\n",
       " {'node_id': 1496, 'left': 720, 'right': 1215},\n",
       " {'node_id': 1497, 'left': 182, 'right': 1226},\n",
       " {'node_id': 1498, 'left': 1219, 'right': 1394},\n",
       " {'node_id': 1499, 'left': 439, 'right': 1175},\n",
       " {'node_id': 1500, 'left': 704, 'right': 1388},\n",
       " {'node_id': 1501, 'left': 1220, 'right': 1361},\n",
       " {'node_id': 1502, 'left': 533, 'right': 1211},\n",
       " {'node_id': 1503, 'left': 902, 'right': 957},\n",
       " {'node_id': 1504, 'left': 1189, 'right': 1347},\n",
       " {'node_id': 1505, 'left': 503, 'right': 693},\n",
       " {'node_id': 1506, 'left': 563, 'right': 1380},\n",
       " {'node_id': 1507, 'left': 883, 'right': 1426},\n",
       " {'node_id': 1508, 'left': 679, 'right': 772},\n",
       " {'node_id': 1509, 'left': 872, 'right': 932},\n",
       " {'node_id': 1510, 'left': 466, 'right': 1149},\n",
       " {'node_id': 1511, 'left': 1074, 'right': 1356},\n",
       " {'node_id': 1512, 'left': 73, 'right': 1382},\n",
       " {'node_id': 1513, 'left': 74, 'right': 296},\n",
       " {'node_id': 1514, 'left': 248, 'right': 303},\n",
       " {'node_id': 1515, 'left': 1341, 'right': 1449},\n",
       " {'node_id': 1516, 'left': 628, 'right': 657},\n",
       " {'node_id': 1517, 'left': 687, 'right': 921},\n",
       " {'node_id': 1518, 'left': 652, 'right': 1057},\n",
       " {'node_id': 1519, 'left': 1122, 'right': 1329},\n",
       " {'node_id': 1520, 'left': 1161, 'right': 1358},\n",
       " {'node_id': 1521, 'left': 1042, 'right': 1378},\n",
       " {'node_id': 1522, 'left': 481, 'right': 1411},\n",
       " {'node_id': 1523, 'left': 969, 'right': 1187},\n",
       " {'node_id': 1524, 'left': 783, 'right': 1352},\n",
       " {'node_id': 1525, 'left': 981, 'right': 1342},\n",
       " {'node_id': 1526, 'left': 1000, 'right': 1324},\n",
       " {'node_id': 1527, 'left': 1172, 'right': 1241},\n",
       " {'node_id': 1528, 'left': 1197, 'right': 1383},\n",
       " {'node_id': 1529, 'left': 947, 'right': 968},\n",
       " {'node_id': 1530, 'left': 383, 'right': 1312},\n",
       " {'node_id': 1531, 'left': 643, 'right': 764},\n",
       " {'node_id': 1532, 'left': 502, 'right': 1255},\n",
       " {'node_id': 1533, 'left': 548, 'right': 686},\n",
       " {'node_id': 1534, 'left': 474, 'right': 1209},\n",
       " {'node_id': 1535, 'left': 858, 'right': 992},\n",
       " {'node_id': 1536, 'left': 1081, 'right': 1404},\n",
       " {'node_id': 1537, 'left': 209, 'right': 238},\n",
       " {'node_id': 1538, 'left': 93, 'right': 1218},\n",
       " {'node_id': 1539, 'left': 180, 'right': 1118},\n",
       " {'node_id': 1540, 'left': 1319, 'right': 1462},\n",
       " {'node_id': 1541, 'left': 998, 'right': 1364},\n",
       " {'node_id': 1542, 'left': 722, 'right': 959},\n",
       " {'node_id': 1543, 'left': 136, 'right': 1492},\n",
       " {'node_id': 1544, 'left': 1344, 'right': 1405},\n",
       " {'node_id': 1545, 'left': 917, 'right': 1421},\n",
       " {'node_id': 1546, 'left': 293, 'right': 1202},\n",
       " {'node_id': 1547, 'left': 400, 'right': 1373},\n",
       " {'node_id': 1548, 'left': 646, 'right': 953},\n",
       " {'node_id': 1549, 'left': 159, 'right': 412},\n",
       " {'node_id': 1550, 'left': 85, 'right': 220},\n",
       " {'node_id': 1551, 'left': 860, 'right': 945},\n",
       " {'node_id': 1552, 'left': 208, 'right': 1316},\n",
       " {'node_id': 1553, 'left': 632, 'right': 1140},\n",
       " {'node_id': 1554, 'left': 1066, 'right': 1452},\n",
       " {'node_id': 1555, 'left': 324, 'right': 1296},\n",
       " {'node_id': 1556, 'left': 1148, 'right': 1477},\n",
       " {'node_id': 1557, 'left': 1024, 'right': 1321},\n",
       " {'node_id': 1558, 'left': 455, 'right': 1145},\n",
       " {'node_id': 1559, 'left': 586, 'right': 627},\n",
       " {'node_id': 1560, 'left': 1271, 'right': 1353},\n",
       " {'node_id': 1561, 'left': 1290, 'right': 1408},\n",
       " {'node_id': 1562, 'left': 557, 'right': 752},\n",
       " {'node_id': 1563, 'left': 1171, 'right': 1205},\n",
       " {'node_id': 1564, 'left': 1077, 'right': 1104},\n",
       " {'node_id': 1565, 'left': 221, 'right': 396},\n",
       " {'node_id': 1566, 'left': 62, 'right': 442},\n",
       " {'node_id': 1567, 'left': 984, 'right': 1243},\n",
       " {'node_id': 1568, 'left': 590, 'right': 1384},\n",
       " {'node_id': 1569, 'left': 47, 'right': 1374},\n",
       " {'node_id': 1570, 'left': 983, 'right': 1461},\n",
       " {'node_id': 1571, 'left': 688, 'right': 1031},\n",
       " {'node_id': 1572, 'left': 534, 'right': 1552},\n",
       " {'node_id': 1573, 'left': 49, 'right': 1333},\n",
       " {'node_id': 1574, 'left': 736, 'right': 1375},\n",
       " {'node_id': 1575, 'left': 1023, 'right': 1186},\n",
       " {'node_id': 1576, 'left': 841, 'right': 903},\n",
       " {'node_id': 1577, 'left': 170, 'right': 1418},\n",
       " {'node_id': 1578, 'left': 1372, 'right': 1403},\n",
       " {'node_id': 1579, 'left': 690, 'right': 703},\n",
       " {'node_id': 1580, 'left': 547, 'right': 663},\n",
       " {'node_id': 1581, 'left': 201, 'right': 352},\n",
       " {'node_id': 1582, 'left': 530, 'right': 1438},\n",
       " {'node_id': 1583, 'left': 748, 'right': 1328},\n",
       " {'node_id': 1584, 'left': 1253, 'right': 1474},\n",
       " {'node_id': 1585, 'left': 1393, 'right': 1499},\n",
       " {'node_id': 1586, 'left': 1013, 'right': 1317},\n",
       " {'node_id': 1587, 'left': 607, 'right': 1410},\n",
       " {'node_id': 1588, 'left': 1311, 'right': 1376},\n",
       " {'node_id': 1589, 'left': 1282, 'right': 1304},\n",
       " {'node_id': 1590, 'left': 18, 'right': 1451},\n",
       " {'node_id': 1591, 'left': 519, 'right': 861},\n",
       " {'node_id': 1592, 'left': 813, 'right': 869},\n",
       " {'node_id': 1593, 'left': 300, 'right': 1432},\n",
       " {'node_id': 1594, 'left': 216, 'right': 398},\n",
       " {'node_id': 1595, 'left': 713, 'right': 1435},\n",
       " {'node_id': 1596, 'left': 1314, 'right': 1479},\n",
       " {'node_id': 1597, 'left': 46, 'right': 116},\n",
       " {'node_id': 1598, 'left': 1184, 'right': 1487},\n",
       " {'node_id': 1599, 'left': 1201, 'right': 1401},\n",
       " {'node_id': 1600, 'left': 215, 'right': 1231},\n",
       " {'node_id': 1601, 'left': 583, 'right': 641},\n",
       " {'node_id': 1602, 'left': 91, 'right': 1206},\n",
       " {'node_id': 1603, 'left': 283, 'right': 1325},\n",
       " {'node_id': 1604, 'left': 1512, 'right': 1573},\n",
       " {'node_id': 1605, 'left': 356, 'right': 1431},\n",
       " {'node_id': 1606, 'left': 1128, 'right': 1517},\n",
       " {'node_id': 1607, 'left': 1106, 'right': 1395},\n",
       " {'node_id': 1608, 'left': 651, 'right': 1294},\n",
       " {'node_id': 1609, 'left': 1166, 'right': 1402},\n",
       " {'node_id': 1610, 'left': 22, 'right': 1275},\n",
       " {'node_id': 1611, 'left': 1005, 'right': 1370},\n",
       " {'node_id': 1612, 'left': 505, 'right': 1434},\n",
       " {'node_id': 1613, 'left': 1240, 'right': 1493},\n",
       " {'node_id': 1614, 'left': 1338, 'right': 1544},\n",
       " {'node_id': 1615, 'left': 631, 'right': 1459},\n",
       " {'node_id': 1616, 'left': 207, 'right': 480},\n",
       " {'node_id': 1617, 'left': 63, 'right': 1549},\n",
       " {'node_id': 1618, 'left': 1313, 'right': 1441},\n",
       " {'node_id': 1619, 'left': 1276, 'right': 1436},\n",
       " {'node_id': 1620, 'left': 942, 'right': 1495},\n",
       " {'node_id': 1621, 'left': 650, 'right': 1496},\n",
       " {'node_id': 1622, 'left': 712, 'right': 896},\n",
       " {'node_id': 1623, 'left': 705, 'right': 757},\n",
       " {'node_id': 1624, 'left': 61, 'right': 311},\n",
       " {'node_id': 1625, 'left': 1153, 'right': 1433},\n",
       " {'node_id': 1626, 'left': 1084, 'right': 1256},\n",
       " {'node_id': 1627, 'left': 428, 'right': 1420},\n",
       " {'node_id': 1628, 'left': 581, 'right': 1216},\n",
       " {'node_id': 1629, 'left': 697, 'right': 960},\n",
       " {'node_id': 1630, 'left': 1416, 'right': 1581},\n",
       " {'node_id': 1631, 'left': 574, 'right': 1472},\n",
       " {'node_id': 1632, 'left': 1041, 'right': 1391},\n",
       " {'node_id': 1633, 'left': 742, 'right': 1407},\n",
       " {'node_id': 1634, 'left': 1228, 'right': 1281},\n",
       " {'node_id': 1635, 'left': 785, 'right': 1208},\n",
       " {'node_id': 1636, 'left': 1015, 'right': 1099},\n",
       " {'node_id': 1637, 'left': 1458, 'right': 1588},\n",
       " {'node_id': 1638, 'left': 251, 'right': 1286},\n",
       " {'node_id': 1639, 'left': 1330, 'right': 1443},\n",
       " {'node_id': 1640, 'left': 1310, 'right': 1534},\n",
       " {'node_id': 1641, 'left': 750, 'right': 961},\n",
       " {'node_id': 1642, 'left': 1050, 'right': 1315},\n",
       " {'node_id': 1643, 'left': 597, 'right': 1506},\n",
       " {'node_id': 1644, 'left': 223, 'right': 1594},\n",
       " {'node_id': 1645, 'left': 546, 'right': 993},\n",
       " {'node_id': 1646, 'left': 987, 'right': 1127},\n",
       " {'node_id': 1647, 'left': 1010, 'right': 1440},\n",
       " {'node_id': 1648, 'left': 1234, 'right': 1413},\n",
       " {'node_id': 1649, 'left': 1164, 'right': 1366},\n",
       " {'node_id': 1650, 'left': 1346, 'right': 1463},\n",
       " {'node_id': 1651, 'left': 1369, 'right': 1439},\n",
       " {'node_id': 1652, 'left': 263, 'right': 1357},\n",
       " {'node_id': 1653, 'left': 609, 'right': 1409},\n",
       " {'node_id': 1654, 'left': 1192, 'right': 1331},\n",
       " {'node_id': 1655, 'left': 642, 'right': 1545},\n",
       " {'node_id': 1656, 'left': 1385, 'right': 1455},\n",
       " {'node_id': 1657, 'left': 313, 'right': 974},\n",
       " {'node_id': 1658, 'left': 817, 'right': 850},\n",
       " {'node_id': 1659, 'left': 1251, 'right': 1634},\n",
       " {'node_id': 1660, 'left': 587, 'right': 905},\n",
       " {'node_id': 1661, 'left': 337, 'right': 1327},\n",
       " {'node_id': 1662, 'left': 1381, 'right': 1483},\n",
       " {'node_id': 1663, 'left': 1063, 'right': 1568},\n",
       " {'node_id': 1664, 'left': 997, 'right': 1508},\n",
       " {'node_id': 1665, 'left': 1453, 'right': 1541},\n",
       " {'node_id': 1666, 'left': 1456, 'right': 1538},\n",
       " {'node_id': 1667, 'left': 1020, 'right': 1334},\n",
       " {'node_id': 1668, 'left': 219, 'right': 1527},\n",
       " {'node_id': 1669, 'left': 1424, 'right': 1510},\n",
       " {'node_id': 1670, 'left': 218, 'right': 1174},\n",
       " {'node_id': 1671, 'left': 733, 'right': 1471},\n",
       " {'node_id': 1672, 'left': 1476, 'right': 1537},\n",
       " {'node_id': 1673, 'left': 1239, 'right': 1505},\n",
       " {'node_id': 1674, 'left': 672, 'right': 1531},\n",
       " {'node_id': 1675, 'left': 1387, 'right': 1533},\n",
       " {'node_id': 1676, 'left': 725, 'right': 1371},\n",
       " {'node_id': 1677, 'left': 1048, 'right': 1165},\n",
       " {'node_id': 1678, 'left': 664, 'right': 709},\n",
       " {'node_id': 1679, 'left': 1399, 'right': 1532},\n",
       " {'node_id': 1680, 'left': 1094, 'right': 1465},\n",
       " {'node_id': 1681, 'left': 132, 'right': 1565},\n",
       " {'node_id': 1682, 'left': 1365, 'right': 1570},\n",
       " {'node_id': 1683, 'left': 603, 'right': 678},\n",
       " {'node_id': 1684, 'left': 673, 'right': 1523},\n",
       " {'node_id': 1685, 'left': 198, 'right': 1295},\n",
       " {'node_id': 1686, 'left': 1481, 'right': 1627},\n",
       " {'node_id': 1687, 'left': 1389, 'right': 1482},\n",
       " {'node_id': 1688, 'left': 1135, 'right': 1257},\n",
       " {'node_id': 1689, 'left': 1530, 'right': 1585},\n",
       " {'node_id': 1690, 'left': 30, 'right': 1515},\n",
       " {'node_id': 1691, 'left': 602, 'right': 1643},\n",
       " {'node_id': 1692, 'left': 259, 'right': 1427},\n",
       " {'node_id': 1693, 'left': 133, 'right': 362},\n",
       " {'node_id': 1694, 'left': 1415, 'right': 1444},\n",
       " {'node_id': 1695, 'left': 1245, 'right': 1600},\n",
       " {'node_id': 1696, 'left': 1467, 'right': 1535},\n",
       " {'node_id': 1697, 'left': 1198, 'right': 1562},\n",
       " {'node_id': 1698, 'left': 1285, 'right': 1625},\n",
       " {'node_id': 1699, 'left': 307, 'right': 1267},\n",
       " {'node_id': 1700, 'left': 751, 'right': 1578},\n",
       " {'node_id': 1701, 'left': 59, 'right': 279},\n",
       " {'node_id': 1702, 'left': 1486, 'right': 1525},\n",
       " {'node_id': 1703, 'left': 1448, 'right': 1550},\n",
       " {'node_id': 1704, 'left': 1340, 'right': 1547},\n",
       " {'node_id': 1705, 'left': 1392, 'right': 1511},\n",
       " {'node_id': 1706, 'left': 1270, 'right': 1446},\n",
       " {'node_id': 1707, 'left': 1466, 'right': 1546},\n",
       " {'node_id': 1708, 'left': 1379, 'right': 1548},\n",
       " {'node_id': 1709, 'left': 1489, 'right': 1663},\n",
       " {'node_id': 1710, 'left': 1513, 'right': 1668},\n",
       " {'node_id': 1711, 'left': 1516, 'right': 1574},\n",
       " {'node_id': 1712, 'left': 1322, 'right': 1363},\n",
       " {'node_id': 1713, 'left': 1237, 'right': 1423},\n",
       " {'node_id': 1714, 'left': 453, 'right': 782},\n",
       " {'node_id': 1715, 'left': 1429, 'right': 1644},\n",
       " {'node_id': 1716, 'left': 569, 'right': 1478},\n",
       " {'node_id': 1717, 'left': 1162, 'right': 1500},\n",
       " {'node_id': 1718, 'left': 1485, 'right': 1641},\n",
       " {'node_id': 1719, 'left': 1262, 'right': 1563},\n",
       " {'node_id': 1720, 'left': 1297, 'right': 1589},\n",
       " {'node_id': 1721, 'left': 909, 'right': 1524},\n",
       " {'node_id': 1722, 'left': 1473, 'right': 1646},\n",
       " {'node_id': 1723, 'left': 1368, 'right': 1616},\n",
       " {'node_id': 1724, 'left': 1320, 'right': 1569},\n",
       " {'node_id': 1725, 'left': 1260, 'right': 1430},\n",
       " {'node_id': 1726, 'left': 714, 'right': 1657},\n",
       " {'node_id': 1727, 'left': 1437, 'right': 1670},\n",
       " {'node_id': 1728, 'left': 1397, 'right': 1626},\n",
       " {'node_id': 1729, 'left': 1360, 'right': 1684},\n",
       " {'node_id': 1730, 'left': 1484, 'right': 1604},\n",
       " {'node_id': 1731, 'left': 1542, 'right': 1622},\n",
       " {'node_id': 1732, 'left': 1223, 'right': 1648},\n",
       " {'node_id': 1733, 'left': 1090, 'right': 1491},\n",
       " {'node_id': 1734, 'left': 1289, 'right': 1623},\n",
       " {'node_id': 1735, 'left': 1576, 'right': 1629},\n",
       " {'node_id': 1736, 'left': 1528, 'right': 1649},\n",
       " {'node_id': 1737, 'left': 1293, 'right': 1690},\n",
       " {'node_id': 1738, 'left': 1551, 'right': 1633},\n",
       " {'node_id': 1739, 'left': 1154, 'right': 1620},\n",
       " {'node_id': 1740, 'left': 1064, 'right': 1566},\n",
       " {'node_id': 1741, 'left': 1170, 'right': 1305},\n",
       " {'node_id': 1742, 'left': 775, 'right': 1612},\n",
       " {'node_id': 1743, 'left': 1450, 'right': 1642},\n",
       " {'node_id': 1744, 'left': 1445, 'right': 1488},\n",
       " {'node_id': 1745, 'left': 1522, 'right': 1651},\n",
       " {'node_id': 1746, 'left': 1579, 'right': 1671},\n",
       " {'node_id': 1747, 'left': 1350, 'right': 1480},\n",
       " {'node_id': 1748, 'left': 1601, 'right': 1645},\n",
       " {'node_id': 1749, 'left': 1454, 'right': 1660},\n",
       " {'node_id': 1750, 'left': 1652, 'right': 1699},\n",
       " {'node_id': 1751, 'left': 1580, 'right': 1592},\n",
       " {'node_id': 1752, 'left': 1406, 'right': 1685},\n",
       " {'node_id': 1753, 'left': 1497, 'right': 1539},\n",
       " {'node_id': 1754, 'left': 1036, 'right': 1591},\n",
       " {'node_id': 1755, 'left': 1377, 'right': 1417},\n",
       " {'node_id': 1756, 'left': 1428, 'right': 1447},\n",
       " {'node_id': 1757, 'left': 940, 'right': 1016},\n",
       " {'node_id': 1758, 'left': 1536, 'right': 1593},\n",
       " {'node_id': 1759, 'left': 1501, 'right': 1680},\n",
       " {'node_id': 1760, 'left': 1624, 'right': 1689},\n",
       " {'node_id': 1761, 'left': 1503, 'right': 1621},\n",
       " {'node_id': 1762, 'left': 1390, 'right': 1687},\n",
       " {'node_id': 1763, 'left': 1083, 'right': 1615},\n",
       " {'node_id': 1764, 'left': 1613, 'right': 1706},\n",
       " {'node_id': 1765, 'left': 1502, 'right': 1553},\n",
       " {'node_id': 1766, 'left': 1307, 'right': 1614},\n",
       " {'node_id': 1767, 'left': 1266, 'right': 1567},\n",
       " {'node_id': 1768, 'left': 1288, 'right': 1747},\n",
       " {'node_id': 1769, 'left': 1658, 'right': 1726},\n",
       " {'node_id': 1770, 'left': 1284, 'right': 1504},\n",
       " {'node_id': 1771, 'left': 1655, 'right': 1732},\n",
       " {'node_id': 1772, 'left': 1475, 'right': 1665},\n",
       " {'node_id': 1773, 'left': 1521, 'right': 1704},\n",
       " {'node_id': 1774, 'left': 1529, 'right': 1678},\n",
       " {'node_id': 1775, 'left': 1124, 'right': 1238},\n",
       " {'node_id': 1776, 'left': 1558, 'right': 1662},\n",
       " {'node_id': 1777, 'left': 1577, 'right': 1720},\n",
       " {'node_id': 1778, 'left': 1040, 'right': 1292},\n",
       " {'node_id': 1779, 'left': 1610, 'right': 1681},\n",
       " {'node_id': 1780, 'left': 1250, 'right': 1396},\n",
       " {'node_id': 1781, 'left': 1598, 'right': 1659},\n",
       " {'node_id': 1782, 'left': 56, 'right': 1718},\n",
       " {'node_id': 1783, 'left': 1306, 'right': 1540},\n",
       " {'node_id': 1784, 'left': 1179, 'right': 1677},\n",
       " {'node_id': 1785, 'left': 526, 'right': 1308},\n",
       " {'node_id': 1786, 'left': 1419, 'right': 1676},\n",
       " {'node_id': 1787, 'left': 512, 'right': 1605},\n",
       " {'node_id': 1788, 'left': 1269, 'right': 1653},\n",
       " {'node_id': 1789, 'left': 1494, 'right': 1722},\n",
       " {'node_id': 1790, 'left': 1147, 'right': 1619},\n",
       " {'node_id': 1791, 'left': 1398, 'right': 1710},\n",
       " {'node_id': 1792, 'left': 1683, 'right': 1716},\n",
       " {'node_id': 1793, 'left': 1002, 'right': 1693},\n",
       " {'node_id': 1794, 'left': 1323, 'right': 1664},\n",
       " {'node_id': 1795, 'left': 1111, 'right': 1650},\n",
       " {'node_id': 1796, 'left': 1564, 'right': 1759},\n",
       " {'node_id': 1797, 'left': 1367, 'right': 1609},\n",
       " {'node_id': 1798, 'left': 1571, 'right': 1599},\n",
       " {'node_id': 1799, 'left': 1543, 'right': 1723},\n",
       " {'node_id': 1800, 'left': 1070, 'right': 1217},\n",
       " {'node_id': 1801, 'left': 1617, 'right': 1770},\n",
       " {'node_id': 1802, 'left': 1073, 'right': 1739},\n",
       " {'node_id': 1803, 'left': 1022, 'right': 1635},\n",
       " {'node_id': 1804, 'left': 1009, 'right': 1628},\n",
       " {'node_id': 1805, 'left': 1224, 'right': 1696},\n",
       " {'node_id': 1806, 'left': 1509, 'right': 1717},\n",
       " {'node_id': 1807, 'left': 1151, 'right': 1762},\n",
       " {'node_id': 1808, 'left': 1349, 'right': 1700},\n",
       " {'node_id': 1809, 'left': 1697, 'right': 1754},\n",
       " {'node_id': 1810, 'left': 1630, 'right': 1714},\n",
       " {'node_id': 1811, 'left': 1032, 'right': 1805},\n",
       " {'node_id': 1812, 'left': 1602, 'right': 1715},\n",
       " {'node_id': 1813, 'left': 1498, 'right': 1695},\n",
       " {'node_id': 1814, 'left': 1751, 'right': 1794},\n",
       " {'node_id': 1815, 'left': 1400, 'right': 1607},\n",
       " {'node_id': 1816, 'left': 1464, 'right': 1603},\n",
       " {'node_id': 1817, 'left': 1638, 'right': 1640},\n",
       " {'node_id': 1818, 'left': 1673, 'right': 1744},\n",
       " {'node_id': 1819, 'left': 1514, 'right': 1661},\n",
       " {'node_id': 1820, 'left': 1103, 'right': 1737},\n",
       " {'node_id': 1821, 'left': 1708, 'right': 1731},\n",
       " {'node_id': 1822, 'left': 1278, 'right': 1758},\n",
       " {'node_id': 1823, 'left': 1012, 'right': 1775},\n",
       " {'node_id': 1824, 'left': 1639, 'right': 1666},\n",
       " {'node_id': 1825, 'left': 1692, 'right': 1743},\n",
       " {'node_id': 1826, 'left': 1587, 'right': 1742},\n",
       " {'node_id': 1827, 'left': 1584, 'right': 1810},\n",
       " {'node_id': 1828, 'left': 1412, 'right': 1746},\n",
       " {'node_id': 1829, 'left': 1337, 'right': 1813},\n",
       " {'node_id': 1830, 'left': 1468, 'right': 1795},\n",
       " {'node_id': 1831, 'left': 1554, 'right': 1597},\n",
       " {'node_id': 1832, 'left': 1339, 'right': 1457},\n",
       " {'node_id': 1833, 'left': 1595, 'right': 1788},\n",
       " {'node_id': 1834, 'left': 1773, 'right': 1820},\n",
       " {'node_id': 1835, 'left': 1336, 'right': 1507},\n",
       " {'node_id': 1836, 'left': 1701, 'right': 1740},\n",
       " {'node_id': 1837, 'left': 1691, 'right': 1755},\n",
       " {'node_id': 1838, 'left': 1072, 'right': 1711},\n",
       " {'node_id': 1839, 'left': 1470, 'right': 1760},\n",
       " {'node_id': 1840, 'left': 1080, 'right': 1721},\n",
       " {'node_id': 1841, 'left': 1442, 'right': 1596},\n",
       " {'node_id': 1842, 'left': 1520, 'right': 1815},\n",
       " {'node_id': 1843, 'left': 1460, 'right': 1735},\n",
       " {'node_id': 1844, 'left': 1753, 'right': 1801},\n",
       " {'node_id': 1845, 'left': 1606, 'right': 1725},\n",
       " {'node_id': 1846, 'left': 1062, 'right': 1656},\n",
       " {'node_id': 1847, 'left': 1196, 'right': 1582},\n",
       " {'node_id': 1848, 'left': 1560, 'right': 1727},\n",
       " {'node_id': 1849, 'left': 1738, 'right': 1785},\n",
       " {'node_id': 1850, 'left': 1590, 'right': 1768},\n",
       " {'node_id': 1851, 'left': 1345, 'right': 1779},\n",
       " {'node_id': 1852, 'left': 1749, 'right': 1798},\n",
       " {'node_id': 1853, 'left': 1637, 'right': 1707},\n",
       " {'node_id': 1854, 'left': 1076, 'right': 1694},\n",
       " {'node_id': 1855, 'left': 1572, 'right': 1812},\n",
       " {'node_id': 1856, 'left': 1736, 'right': 1783},\n",
       " {'node_id': 1857, 'left': 1559, 'right': 1792},\n",
       " {'node_id': 1858, 'left': 1675, 'right': 1847},\n",
       " {'node_id': 1859, 'left': 1101, 'right': 1557},\n",
       " {'node_id': 1860, 'left': 1819, 'right': 1839},\n",
       " {'node_id': 1861, 'left': 1724, 'right': 1776},\n",
       " {'node_id': 1862, 'left': 1730, 'right': 1766},\n",
       " {'node_id': 1863, 'left': 1734, 'right': 1782},\n",
       " {'node_id': 1864, 'left': 1229, 'right': 1767},\n",
       " {'node_id': 1865, 'left': 1756, 'right': 1840},\n",
       " {'node_id': 1866, 'left': 1679, 'right': 1713},\n",
       " {'node_id': 1867, 'left': 1750, 'right': 1777},\n",
       " {'node_id': 1868, 'left': 1672, 'right': 1752},\n",
       " {'node_id': 1869, 'left': 1586, 'right': 1728},\n",
       " {'node_id': 1870, 'left': 1014, 'right': 1850},\n",
       " {'node_id': 1871, 'left': 1765, 'right': 1818},\n",
       " {'node_id': 1872, 'left': 1682, 'right': 1800},\n",
       " {'node_id': 1873, 'left': 1771, 'right': 1806},\n",
       " {'node_id': 1874, 'left': 1608, 'right': 1631},\n",
       " {'node_id': 1875, 'left': 1705, 'right': 1831},\n",
       " {'node_id': 1876, 'left': 1825, 'right': 1841},\n",
       " {'node_id': 1877, 'left': 1674, 'right': 1748},\n",
       " {'node_id': 1878, 'left': 1763, 'right': 1866},\n",
       " {'node_id': 1879, 'left': 1006, 'right': 1781},\n",
       " {'node_id': 1880, 'left': 1332, 'right': 1804},\n",
       " {'node_id': 1881, 'left': 1733, 'right': 1817},\n",
       " {'node_id': 1882, 'left': 1004, 'right': 1853},\n",
       " {'node_id': 1883, 'left': 1490, 'right': 1778},\n",
       " {'node_id': 1884, 'left': 1003, 'right': 1061},\n",
       " {'node_id': 1885, 'left': 1561, 'right': 1780},\n",
       " {'node_id': 1886, 'left': 1808, 'right': 1826},\n",
       " {'node_id': 1887, 'left': 1309, 'right': 1823},\n",
       " {'node_id': 1888, 'left': 1158, 'right': 1802},\n",
       " {'node_id': 1889, 'left': 1741, 'right': 1877},\n",
       " {'node_id': 1890, 'left': 1719, 'right': 1834},\n",
       " {'node_id': 1891, 'left': 1769, 'right': 1827},\n",
       " {'node_id': 1892, 'left': 1556, 'right': 1833},\n",
       " {'node_id': 1893, 'left': 1757, 'right': 1846},\n",
       " {'node_id': 1894, 'left': 1303, 'right': 1838},\n",
       " {'node_id': 1895, 'left': 1774, 'right': 1786},\n",
       " {'node_id': 1896, 'left': 1075, 'right': 1807},\n",
       " {'node_id': 1897, 'left': 1526, 'right': 1799},\n",
       " {'node_id': 1898, 'left': 1703, 'right': 1860},\n",
       " {'node_id': 1899, 'left': 1836, 'right': 1882},\n",
       " {'node_id': 1900, 'left': 1667, 'right': 1803},\n",
       " {'node_id': 1901, 'left': 1518, 'right': 1864},\n",
       " {'node_id': 1902, 'left': 1745, 'right': 1862},\n",
       " {'node_id': 1903, 'left': 1583, 'right': 1709},\n",
       " {'node_id': 1904, 'left': 1519, 'right': 1849},\n",
       " {'node_id': 1905, 'left': 1669, 'right': 1791},\n",
       " {'node_id': 1906, 'left': 1712, 'right': 1772},\n",
       " {'node_id': 1907, 'left': 1702, 'right': 1888},\n",
       " {'node_id': 1908, 'left': 1790, 'right': 1844},\n",
       " {'node_id': 1909, 'left': 1811, 'right': 1821},\n",
       " {'node_id': 1910, 'left': 1814, 'right': 1843},\n",
       " {'node_id': 1911, 'left': 1875, 'right': 1897},\n",
       " {'node_id': 1912, 'left': 1698, 'right': 1885},\n",
       " {'node_id': 1913, 'left': 1555, 'right': 1870},\n",
       " {'node_id': 1914, 'left': 1359, 'right': 1900},\n",
       " {'node_id': 1915, 'left': 1824, 'right': 1861},\n",
       " {'node_id': 1916, 'left': 1159, 'right': 1892},\n",
       " {'node_id': 1917, 'left': 1688, 'right': 1852},\n",
       " {'node_id': 1918, 'left': 1857, 'right': 1895},\n",
       " {'node_id': 1919, 'left': 1787, 'right': 1828},\n",
       " {'node_id': 1920, 'left': 1793, 'right': 1868},\n",
       " {'node_id': 1921, 'left': 1414, 'right': 1863},\n",
       " {'node_id': 1922, 'left': 1654, 'right': 1886},\n",
       " {'node_id': 1923, 'left': 1618, 'right': 1867},\n",
       " {'node_id': 1924, 'left': 1848, 'right': 1879},\n",
       " {'node_id': 1925, 'left': 1386, 'right': 1764},\n",
       " {'node_id': 1926, 'left': 1851, 'right': 1898},\n",
       " {'node_id': 1927, 'left': 1884, 'right': 1910},\n",
       " {'node_id': 1928, 'left': 1575, 'right': 1858},\n",
       " {'node_id': 1929, 'left': 1761, 'right': 1871},\n",
       " {'node_id': 1930, 'left': 1842, 'right': 1905},\n",
       " {'node_id': 1931, 'left': 1809, 'right': 1887},\n",
       " {'node_id': 1932, 'left': 1873, 'right': 1894},\n",
       " {'node_id': 1933, 'left': 1908, 'right': 1924},\n",
       " {'node_id': 1934, 'left': 1686, 'right': 1926},\n",
       " {'node_id': 1935, 'left': 1816, 'right': 1920},\n",
       " {'node_id': 1936, 'left': 1636, 'right': 1874},\n",
       " {'node_id': 1937, 'left': 1835, 'right': 1837},\n",
       " {'node_id': 1938, 'left': 1896, 'right': 1919},\n",
       " {'node_id': 1939, 'left': 1796, 'right': 1829},\n",
       " {'node_id': 1940, 'left': 1854, 'right': 1889},\n",
       " {'node_id': 1941, 'left': 1901, 'right': 1932},\n",
       " {'node_id': 1942, 'left': 1891, 'right': 1913},\n",
       " {'node_id': 1943, 'left': 1890, 'right': 1942},\n",
       " {'node_id': 1944, 'left': 1832, 'right': 1917},\n",
       " {'node_id': 1945, 'left': 1872, 'right': 1893},\n",
       " {'node_id': 1946, 'left': 1909, 'right': 1937},\n",
       " {'node_id': 1947, 'left': 1869, 'right': 1935},\n",
       " {'node_id': 1948, 'left': 1927, 'right': 1928},\n",
       " {'node_id': 1949, 'left': 1830, 'right': 1931},\n",
       " {'node_id': 1950, 'left': 1789, 'right': 1903},\n",
       " {'node_id': 1951, 'left': 1611, 'right': 1941},\n",
       " {'node_id': 1952, 'left': 1856, 'right': 1933},\n",
       " {'node_id': 1953, 'left': 1904, 'right': 1907},\n",
       " {'node_id': 1954, 'left': 1845, 'right': 1906},\n",
       " {'node_id': 1955, 'left': 1859, 'right': 1922},\n",
       " {'node_id': 1956, 'left': 1876, 'right': 1881},\n",
       " {'node_id': 1957, 'left': 1729, 'right': 1940},\n",
       " {'node_id': 1958, 'left': 1632, 'right': 1936},\n",
       " {'node_id': 1959, 'left': 1822, 'right': 1947},\n",
       " {'node_id': 1960, 'left': 1797, 'right': 1883},\n",
       " {'node_id': 1961, 'left': 1916, 'right': 1921},\n",
       " {'node_id': 1962, 'left': 1912, 'right': 1956},\n",
       " {'node_id': 1963, 'left': 1915, 'right': 1934},\n",
       " {'node_id': 1964, 'left': 1647, 'right': 1958},\n",
       " {'node_id': 1965, 'left': 1784, 'right': 1945},\n",
       " {'node_id': 1966, 'left': 1911, 'right': 1930},\n",
       " {'node_id': 1967, 'left': 1918, 'right': 1961},\n",
       " {'node_id': 1968, 'left': 1878, 'right': 1954},\n",
       " {'node_id': 1969, 'left': 1925, 'right': 1949},\n",
       " {'node_id': 1970, 'left': 1902, 'right': 1923},\n",
       " {'node_id': 1971, 'left': 1855, 'right': 1939},\n",
       " {'node_id': 1972, 'left': 1914, 'right': 1944},\n",
       " {'node_id': 1973, 'left': 1952, 'right': 1959},\n",
       " {'node_id': 1974, 'left': 1865, 'right': 1953},\n",
       " {'node_id': 1975, 'left': 1957, 'right': 1968},\n",
       " {'node_id': 1976, 'left': 1899, 'right': 1963},\n",
       " {'node_id': 1977, 'left': 1938, 'right': 1960},\n",
       " {'node_id': 1978, 'left': 1948, 'right': 1964},\n",
       " {'node_id': 1979, 'left': 1971, 'right': 1973},\n",
       " {'node_id': 1980, 'left': 1880, 'right': 1929},\n",
       " {'node_id': 1981, 'left': 1965, 'right': 1967},\n",
       " {'node_id': 1982, 'left': 1955, 'right': 1977},\n",
       " {'node_id': 1983, 'left': 1950, 'right': 1981},\n",
       " {'node_id': 1984, 'left': 1966, 'right': 1976},\n",
       " {'node_id': 1985, 'left': 1946, 'right': 1978},\n",
       " {'node_id': 1986, 'left': 1975, 'right': 1980},\n",
       " {'node_id': 1987, 'left': 1974, 'right': 1982},\n",
       " {'node_id': 1988, 'left': 1969, 'right': 1986},\n",
       " {'node_id': 1989, 'left': 1962, 'right': 1970},\n",
       " {'node_id': 1990, 'left': 1951, 'right': 1983},\n",
       " {'node_id': 1991, 'left': 1979, 'right': 1989},\n",
       " {'node_id': 1992, 'left': 1943, 'right': 1984},\n",
       " {'node_id': 1993, 'left': 1972, 'right': 1990},\n",
       " {'node_id': 1994, 'left': 1985, 'right': 1988},\n",
       " {'node_id': 1995, 'left': 1993, 'right': 1994},\n",
       " {'node_id': 1996, 'left': 1987, 'right': 1995},\n",
       " {'node_id': 1997, 'left': 1991, 'right': 1992},\n",
       " {'node_id': 1998, 'left': 1996, 'right': 1997}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "ii = itertools.count(sample.shape[0])\n",
    "[{'node_id': next(ii), 'left': x[0], 'right':x[1]} for x in cluster_model.children_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b842ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: array([175, 243]),\n",
       " 6: array([506, 770]),\n",
       " 7: array([41, 70]),\n",
       " 8: array([599, 676]),\n",
       " 9: array([425, 460]),\n",
       " 10: array([556, 620]),\n",
       " 11: array([110, 172]),\n",
       " 12: array([616, 956]),\n",
       " 13: array([644, 767]),\n",
       " 14: array([835, 916]),\n",
       " 15: array([ 868, 1008]),\n",
       " 16: array([726, 727]),\n",
       " 17: array([827, 936]),\n",
       " 18: array([187, 189]),\n",
       " 19: array([ 31, 436]),\n",
       " 20: array([545, 575]),\n",
       " 21: array([647, 659]),\n",
       " 22: array([267, 403]),\n",
       " 23: array([816, 944]),\n",
       " 24: array([803, 838]),\n",
       " 25: array([592, 924]),\n",
       " 26: array([351, 378]),\n",
       " 27: array([624, 823]),\n",
       " 28: array([517, 585]),\n",
       " 29: array([ 571, 1019]),\n",
       " 30: array([589, 852]),\n",
       " 31: array([520, 700]),\n",
       " 32: array([103, 157]),\n",
       " 33: array([ 388, 1021]),\n",
       " 34: array([801, 833]),\n",
       " 35: array([927, 955]),\n",
       " 36: array([744, 781]),\n",
       " 37: array([900, 986]),\n",
       " 38: array([794, 856]),\n",
       " 39: array([684, 793]),\n",
       " 40: array([ 13, 126]),\n",
       " 41: array([558, 694]),\n",
       " 42: array([ 65, 109]),\n",
       " 43: array([202, 370]),\n",
       " 44: array([ 469, 1017]),\n",
       " 45: array([696, 743]),\n",
       " 46: array([582, 965]),\n",
       " 47: array([14, 19]),\n",
       " 48: array([685, 881]),\n",
       " 49: array([ 10, 272]),\n",
       " 50: array([152, 156]),\n",
       " 51: array([882, 923]),\n",
       " 52: array([348, 369]),\n",
       " 53: array([498, 820]),\n",
       " 54: array([710, 996]),\n",
       " 55: array([150, 327]),\n",
       " 56: array([241, 449]),\n",
       " 57: array([240, 301]),\n",
       " 58: array([786, 914]),\n",
       " 59: array([124, 292]),\n",
       " 60: array([839, 995]),\n",
       " 61: array([768, 849]),\n",
       " 62: array([967, 971]),\n",
       " 63: array([594, 893]),\n",
       " 64: array([636, 677]),\n",
       " 65: array([739, 844]),\n",
       " 66: array([ 966, 1034]),\n",
       " 67: array([715, 951]),\n",
       " 68: array([745, 939]),\n",
       " 69: array([338, 447]),\n",
       " 70: array([654, 683]),\n",
       " 71: array([ 75, 119]),\n",
       " 72: array([ 151, 1045]),\n",
       " 73: array([ 69, 121]),\n",
       " 74: array([418, 456]),\n",
       " 75: array([717, 948]),\n",
       " 76: array([15, 57]),\n",
       " 77: array([591, 614]),\n",
       " 78: array([600, 718]),\n",
       " 79: array([433, 467]),\n",
       " 80: array([ 999, 1060]),\n",
       " 81: array([ 729, 1001]),\n",
       " 82: array([101, 123]),\n",
       " 83: array([213, 262]),\n",
       " 84: array([915, 989]),\n",
       " 85: array([497, 499]),\n",
       " 86: array([ 27, 229]),\n",
       " 87: array([111, 200]),\n",
       " 88: array([513, 521]),\n",
       " 89: array([341, 395]),\n",
       " 90: array([361, 473]),\n",
       " 91: array([755, 870]),\n",
       " 92: array([204, 265]),\n",
       " 93: array([800, 979]),\n",
       " 94: array([ 334, 1054]),\n",
       " 95: array([ 437, 1028]),\n",
       " 96: array([  3, 342]),\n",
       " 97: array([ 28, 446]),\n",
       " 98: array([ 194, 1051]),\n",
       " 99: array([ 39, 415]),\n",
       " 100: array([160, 411]),\n",
       " 101: array([655, 901]),\n",
       " 102: array([ 252, 1027]),\n",
       " 103: array([ 77, 458]),\n",
       " 104: array([812, 815]),\n",
       " 105: array([ 24, 404]),\n",
       " 106: array([ 525, 1007]),\n",
       " 107: array([162, 432]),\n",
       " 108: array([ 35, 357]),\n",
       " 109: array([ 6, 89]),\n",
       " 110: array([784, 859]),\n",
       " 111: array([163, 230]),\n",
       " 112: array([271, 329]),\n",
       " 113: array([286, 314]),\n",
       " 114: array([ 44, 239]),\n",
       " 115: array([ 165, 1038]),\n",
       " 116: array([625, 920]),\n",
       " 117: array([ 90, 289]),\n",
       " 118: array([224, 464]),\n",
       " 119: array([290, 406]),\n",
       " 120: array([153, 256]),\n",
       " 121: array([528, 588]),\n",
       " 122: array([  7, 371]),\n",
       " 123: array([142, 269]),\n",
       " 124: array([112, 197]),\n",
       " 125: array([822, 980]),\n",
       " 126: array([  79, 1098]),\n",
       " 127: array([777, 988]),\n",
       " 128: array([420, 448]),\n",
       " 129: array([761, 962]),\n",
       " 130: array([  21, 1069]),\n",
       " 131: array([ 67, 482]),\n",
       " 132: array([836, 973]),\n",
       " 133: array([645, 661]),\n",
       " 134: array([138, 372]),\n",
       " 135: array([127, 336]),\n",
       " 136: array([ 20, 169]),\n",
       " 137: array([626, 635]),\n",
       " 138: array([ 1, 11]),\n",
       " 139: array([164, 191]),\n",
       " 140: array([610, 630]),\n",
       " 141: array([ 16, 494]),\n",
       " 142: array([ 787, 1026]),\n",
       " 143: array([377, 478]),\n",
       " 144: array([  4, 108]),\n",
       " 145: array([668, 795]),\n",
       " 146: array([195, 274]),\n",
       " 147: array([261, 387]),\n",
       " 148: array([297, 366]),\n",
       " 149: array([143, 413]),\n",
       " 150: array([139, 237]),\n",
       " 151: array([353, 475]),\n",
       " 152: array([226, 440]),\n",
       " 153: array([578, 738]),\n",
       " 154: array([305, 355]),\n",
       " 155: array([ 83, 330]),\n",
       " 156: array([746, 880]),\n",
       " 157: array([527, 576]),\n",
       " 158: array([1068, 1095]),\n",
       " 159: array([553, 918]),\n",
       " 160: array([579, 937]),\n",
       " 161: array([ 492, 1134]),\n",
       " 162: array([ 560, 1116]),\n",
       " 163: array([ 788, 1018]),\n",
       " 164: array([ 711, 1056]),\n",
       " 165: array([ 496, 1067]),\n",
       " 166: array([ 479, 1071]),\n",
       " 167: array([875, 898]),\n",
       " 168: array([ 38, 427]),\n",
       " 169: array([287, 359]),\n",
       " 170: array([615, 818]),\n",
       " 171: array([550, 617]),\n",
       " 172: array([438, 488]),\n",
       " 173: array([298, 495]),\n",
       " 174: array([ 332, 1087]),\n",
       " 175: array([876, 907]),\n",
       " 176: array([349, 426]),\n",
       " 177: array([315, 316]),\n",
       " 178: array([231, 266]),\n",
       " 179: array([185, 247]),\n",
       " 180: array([294, 379]),\n",
       " 181: array([149, 210]),\n",
       " 182: array([ 42, 323]),\n",
       " 183: array([511, 532]),\n",
       " 184: array([ 802, 1033]),\n",
       " 185: array([ 728, 1043]),\n",
       " 186: array([308, 374]),\n",
       " 187: array([ 270, 1139]),\n",
       " 188: array([889, 941]),\n",
       " 189: array([105, 365]),\n",
       " 190: array([580, 808]),\n",
       " 191: array([593, 925]),\n",
       " 192: array([522, 535]),\n",
       " 193: array([670, 695]),\n",
       " 194: array([212, 257]),\n",
       " 195: array([805, 913]),\n",
       " 196: array([131, 173]),\n",
       " 197: array([762, 774]),\n",
       " 198: array([ 188, 1113]),\n",
       " 199: array([ 487, 1108]),\n",
       " 200: array([264, 468]),\n",
       " 201: array([681, 853]),\n",
       " 202: array([ 343, 1119]),\n",
       " 203: array([536, 568]),\n",
       " 204: array([192, 347]),\n",
       " 205: array([ 66, 434]),\n",
       " 206: array([ 791, 1053]),\n",
       " 207: array([ 43, 155]),\n",
       " 208: array([ 326, 1131]),\n",
       " 209: array([106, 249]),\n",
       " 210: array([ 87, 179]),\n",
       " 211: array([376, 397]),\n",
       " 212: array([ 86, 255]),\n",
       " 213: array([674, 964]),\n",
       " 214: array([ 76, 435]),\n",
       " 215: array([1089, 1156]),\n",
       " 216: array([825, 977]),\n",
       " 217: array([878, 950]),\n",
       " 218: array([ 414, 1047]),\n",
       " 219: array([ 40, 168]),\n",
       " 220: array([510, 692]),\n",
       " 221: array([ 640, 1030]),\n",
       " 222: array([910, 926]),\n",
       " 223: array([ 178, 1100]),\n",
       " 224: array([260, 345]),\n",
       " 225: array([102, 288]),\n",
       " 226: array([ 36, 214]),\n",
       " 227: array([867, 938]),\n",
       " 228: array([573, 721]),\n",
       " 229: array([735, 769]),\n",
       " 230: array([ 17, 268]),\n",
       " 231: array([166, 285]),\n",
       " 232: array([789, 946]),\n",
       " 233: array([392, 423]),\n",
       " 234: array([ 634, 1065]),\n",
       " 235: array([ 97, 246]),\n",
       " 236: array([ 23, 381]),\n",
       " 237: array([ 81, 408]),\n",
       " 238: array([211, 328]),\n",
       " 239: array([873, 885]),\n",
       " 240: array([766, 963]),\n",
       " 241: array([555, 976]),\n",
       " 242: array([799, 892]),\n",
       " 243: array([754, 922]),\n",
       " 244: array([662, 680]),\n",
       " 245: array([ 544, 1178]),\n",
       " 246: array([ 48, 245]),\n",
       " 247: array([227, 459]),\n",
       " 248: array([810, 919]),\n",
       " 249: array([612, 749]),\n",
       " 250: array([310, 340]),\n",
       " 251: array([154, 228]),\n",
       " 252: array([ 95, 222]),\n",
       " 253: array([542, 577]),\n",
       " 254: array([ 64, 463]),\n",
       " 255: array([ 304, 1078]),\n",
       " 256: array([ 405, 1150]),\n",
       " 257: array([826, 906]),\n",
       " 258: array([391, 410]),\n",
       " 259: array([760, 970]),\n",
       " 260: array([562, 669]),\n",
       " 261: array([107, 350]),\n",
       " 262: array([ 734, 1046]),\n",
       " 263: array([ 129, 1044]),\n",
       " 264: array([508, 994]),\n",
       " 265: array([523, 691]),\n",
       " 266: array([ 55, 364]),\n",
       " 267: array([235, 373]),\n",
       " 268: array([ 284, 1102]),\n",
       " 269: array([824, 933]),\n",
       " 270: array([723, 851]),\n",
       " 271: array([ 778, 1029]),\n",
       " 272: array([ 34, 299]),\n",
       " 273: array([419, 486]),\n",
       " 274: array([ 831, 1049]),\n",
       " 275: array([572, 699]),\n",
       " 276: array([ 394, 1169]),\n",
       " 277: array([ 346, 1082]),\n",
       " 278: array([280, 318]),\n",
       " 279: array([ 417, 1052]),\n",
       " 280: array([282, 363]),\n",
       " 281: array([ 302, 1181]),\n",
       " 282: array([276, 306]),\n",
       " 283: array([  94, 1125]),\n",
       " 284: array([949, 954]),\n",
       " 285: array([ 82, 130]),\n",
       " 286: array([445, 471]),\n",
       " 287: array([  29, 1173]),\n",
       " 288: array([333, 465]),\n",
       " 289: array([113, 773]),\n",
       " 290: array([140, 254]),\n",
       " 291: array([  54, 1142]),\n",
       " 292: array([621, 701]),\n",
       " 293: array([100, 360]),\n",
       " 294: array([763, 814]),\n",
       " 295: array([ 367, 1191]),\n",
       " 296: array([258, 322]),\n",
       " 297: array([500, 908]),\n",
       " 298: array([ 96, 421]),\n",
       " 299: array([ 537, 1132]),\n",
       " 300: array([ 33, 389]),\n",
       " 301: array([  26, 1039]),\n",
       " 302: array([ 45, 319]),\n",
       " 303: array([ 9, 51]),\n",
       " 304: array([1093, 1213]),\n",
       " 305: array([ 321, 1085]),\n",
       " 306: array([ 98, 390]),\n",
       " 307: array([368, 430]),\n",
       " 308: array([ 566, 1059]),\n",
       " 309: array([1141, 1176]),\n",
       " 310: array([565, 891]),\n",
       " 311: array([1091, 1123]),\n",
       " 312: array([ 325, 1117]),\n",
       " 313: array([529, 931]),\n",
       " 314: array([ 958, 1244]),\n",
       " 315: array([ 84, 477]),\n",
       " 316: array([146, 225]),\n",
       " 317: array([232, 291]),\n",
       " 318: array([  50, 1258]),\n",
       " 319: array([ 205, 1110]),\n",
       " 320: array([ 120, 1107]),\n",
       " 321: array([   0, 1214]),\n",
       " 322: array([ 470, 1133]),\n",
       " 323: array([ 184, 1129]),\n",
       " 324: array([1163, 1167]),\n",
       " 325: array([416, 443]),\n",
       " 326: array([561, 897]),\n",
       " 327: array([790, 890]),\n",
       " 328: array([606, 854]),\n",
       " 329: array([181, 309]),\n",
       " 330: array([ 472, 1200]),\n",
       " 331: array([596, 682]),\n",
       " 332: array([236, 476]),\n",
       " 333: array([ 864, 1236]),\n",
       " 334: array([846, 904]),\n",
       " 335: array([ 335, 1177]),\n",
       " 336: array([656, 887]),\n",
       " 337: array([ 806, 1011]),\n",
       " 338: array([190, 375]),\n",
       " 339: array([719, 843]),\n",
       " 340: array([ 895, 1079]),\n",
       " 341: array([ 862, 1222]),\n",
       " 342: array([ 12, 171]),\n",
       " 343: array([  58, 1144]),\n",
       " 344: array([ 830, 1180]),\n",
       " 345: array([145, 401]),\n",
       " 346: array([  5, 161]),\n",
       " 347: array([ 538, 1254]),\n",
       " 348: array([253, 452]),\n",
       " 349: array([  52, 1246]),\n",
       " 350: array([ 278, 1138]),\n",
       " 351: array([618, 623]),\n",
       " 352: array([ 92, 331]),\n",
       " 353: array([312, 385]),\n",
       " 354: array([811, 842]),\n",
       " 355: array([118, 462]),\n",
       " 356: array([114, 250]),\n",
       " 357: array([514, 518]),\n",
       " 358: array([ 344, 1203]),\n",
       " 359: array([295, 380]),\n",
       " 360: array([174, 461]),\n",
       " 361: array([ 167, 1112]),\n",
       " 362: array([ 72, 317]),\n",
       " 363: array([ 489, 1193]),\n",
       " 364: array([ 943, 1235]),\n",
       " 365: array([ 848, 1287]),\n",
       " 366: array([117, 183]),\n",
       " 367: array([217, 407]),\n",
       " 368: array([741, 935]),\n",
       " 369: array([584, 708]),\n",
       " 370: array([ 716, 1105]),\n",
       " 371: array([1114, 1283]),\n",
       " 372: array([ 837, 1120]),\n",
       " 373: array([  78, 1199]),\n",
       " 374: array([339, 431]),\n",
       " 375: array([554, 796]),\n",
       " 376: array([551, 797]),\n",
       " 377: array([601, 934]),\n",
       " 378: array([ 68, 134]),\n",
       " 379: array([273, 441]),\n",
       " 380: array([604, 972]),\n",
       " 381: array([176, 275]),\n",
       " 382: array([ 637, 1183]),\n",
       " 383: array([ 454, 1249]),\n",
       " 384: array([732, 886]),\n",
       " 385: array([649, 807]),\n",
       " 386: array([122, 485]),\n",
       " 387: array([384, 490]),\n",
       " 388: array([147, 457]),\n",
       " 389: array([828, 877]),\n",
       " 390: array([730, 771]),\n",
       " 391: array([1137, 1212]),\n",
       " 392: array([639, 660]),\n",
       " 393: array([ 845, 1188]),\n",
       " 394: array([667, 930]),\n",
       " 395: array([759, 985]),\n",
       " 396: array([ 991, 1058]),\n",
       " 397: array([  53, 1194]),\n",
       " 398: array([144, 393]),\n",
       " 399: array([ 450, 1230]),\n",
       " 400: array([ 358, 1204]),\n",
       " 401: array([1097, 1182]),\n",
       " 402: array([1092, 1143]),\n",
       " 403: array([ 80, 193]),\n",
       " 404: array([629, 929]),\n",
       " 405: array([ 491, 1160]),\n",
       " 406: array([ 595, 1088]),\n",
       " 407: array([1259, 1264]),\n",
       " 408: array([ 559, 1185]),\n",
       " 409: array([ 104, 1242]),\n",
       " 410: array([125, 444]),\n",
       " 411: array([ 244, 1318]),\n",
       " 412: array([515, 737]),\n",
       " 413: array([1109, 1207]),\n",
       " 414: array([702, 819]),\n",
       " 415: array([570, 857]),\n",
       " 416: array([141, 451]),\n",
       " 417: array([ 952, 1335]),\n",
       " 418: array([724, 829]),\n",
       " 419: array([ 879, 1055]),\n",
       " 420: array([675, 840]),\n",
       " 421: array([ 115, 1268]),\n",
       " 422: array([780, 865]),\n",
       " 423: array([1232, 1300]),\n",
       " 424: array([779, 855]),\n",
       " 425: array([ 137, 1298]),\n",
       " 426: array([608, 671]),\n",
       " 427: array([1086, 1252]),\n",
       " 428: array([821, 975]),\n",
       " 429: array([ 158, 1035]),\n",
       " 430: array([ 484, 1299]),\n",
       " 431: array([ 731, 1025]),\n",
       " 432: array([1130, 1225]),\n",
       " 433: array([509, 516]),\n",
       " 434: array([ 277, 1301]),\n",
       " 435: array([539, 622]),\n",
       " 436: array([483, 747]),\n",
       " 437: array([   2, 1136]),\n",
       " 438: array([1263, 1302]),\n",
       " 439: array([638, 758]),\n",
       " 440: array([792, 884]),\n",
       " 441: array([ 234, 1348]),\n",
       " 442: array([206, 281]),\n",
       " 443: array([541, 863]),\n",
       " 444: array([  25, 1195]),\n",
       " 445: array([ 928, 1157]),\n",
       " 446: array([1210, 1274]),\n",
       " 447: array([1121, 1126]),\n",
       " 448: array([1261, 1277]),\n",
       " 449: array([ 501, 1190]),\n",
       " 450: array([524, 888]),\n",
       " 451: array([698, 871]),\n",
       " 452: array([354, 740]),\n",
       " 453: array([177, 196]),\n",
       " 454: array([128, 242]),\n",
       " 455: array([1115, 1221]),\n",
       " 456: array([  88, 1354]),\n",
       " 457: array([ 148, 1168]),\n",
       " 458: array([507, 894]),\n",
       " 459: array([ 834, 1279]),\n",
       " 460: array([707, 912]),\n",
       " 461: array([320, 382]),\n",
       " 462: array([ 982, 1265]),\n",
       " 463: array([ 386, 1146]),\n",
       " 464: array([804, 847]),\n",
       " 465: array([ 911, 1152]),\n",
       " 466: array([552, 899]),\n",
       " 467: array([ 135, 1233]),\n",
       " 468: array([689, 753]),\n",
       " 469: array([ 409, 1273]),\n",
       " 470: array([  60, 1351]),\n",
       " 471: array([  8, 422]),\n",
       " 472: array([658, 756]),\n",
       " 473: array([ 567, 1096]),\n",
       " 474: array([ 978, 1155]),\n",
       " 475: array([ 37, 186]),\n",
       " 476: array([549, 605]),\n",
       " 477: array([633, 798]),\n",
       " 478: array([619, 666]),\n",
       " 479: array([233, 402]),\n",
       " 480: array([776, 866]),\n",
       " 481: array([ 429, 1355]),\n",
       " 482: array([613, 648]),\n",
       " 483: array([540, 706]),\n",
       " 484: array([1247, 1272]),\n",
       " 485: array([ 203, 1362]),\n",
       " 486: array([ 71, 424]),\n",
       " 487: array([832, 874]),\n",
       " 488: array([ 32, 493]),\n",
       " 489: array([ 99, 399]),\n",
       " 490: array([598, 765]),\n",
       " 491: array([1227, 1469]),\n",
       " 492: array([ 199, 1343]),\n",
       " 493: array([ 990, 1248]),\n",
       " 494: array([653, 809]),\n",
       " 495: array([ 611, 1422]),\n",
       " 496: array([1037, 1425]),\n",
       " 497: array([1280, 1291]),\n",
       " 498: array([531, 665]),\n",
       " 499: array([ 564, 1326]),\n",
       " 500: array([504, 543]),\n",
       " 501: array([ 720, 1215]),\n",
       " 502: array([ 182, 1226]),\n",
       " 503: array([1219, 1394]),\n",
       " 504: array([ 439, 1175]),\n",
       " 505: array([ 704, 1388]),\n",
       " 506: array([1220, 1361]),\n",
       " 507: array([ 533, 1211]),\n",
       " 508: array([902, 957]),\n",
       " 509: array([1189, 1347]),\n",
       " 510: array([503, 693]),\n",
       " 511: array([ 563, 1380]),\n",
       " 512: array([ 883, 1426]),\n",
       " 513: array([679, 772]),\n",
       " 514: array([872, 932]),\n",
       " 515: array([ 466, 1149]),\n",
       " 516: array([1074, 1356]),\n",
       " 517: array([  73, 1382]),\n",
       " 518: array([ 74, 296]),\n",
       " 519: array([248, 303]),\n",
       " 520: array([1341, 1449]),\n",
       " 521: array([628, 657]),\n",
       " 522: array([687, 921]),\n",
       " 523: array([ 652, 1057]),\n",
       " 524: array([1122, 1329]),\n",
       " 525: array([1161, 1358]),\n",
       " 526: array([1042, 1378]),\n",
       " 527: array([ 481, 1411]),\n",
       " 528: array([ 969, 1187]),\n",
       " 529: array([ 783, 1352]),\n",
       " 530: array([ 981, 1342]),\n",
       " 531: array([1000, 1324]),\n",
       " 532: array([1172, 1241]),\n",
       " 533: array([1197, 1383]),\n",
       " 534: array([947, 968]),\n",
       " 535: array([ 383, 1312]),\n",
       " 536: array([643, 764]),\n",
       " 537: array([ 502, 1255]),\n",
       " 538: array([548, 686]),\n",
       " 539: array([ 474, 1209]),\n",
       " 540: array([858, 992]),\n",
       " 541: array([1081, 1404]),\n",
       " 542: array([209, 238]),\n",
       " 543: array([  93, 1218]),\n",
       " 544: array([ 180, 1118]),\n",
       " 545: array([1319, 1462]),\n",
       " 546: array([ 998, 1364]),\n",
       " 547: array([722, 959]),\n",
       " 548: array([ 136, 1492]),\n",
       " 549: array([1344, 1405]),\n",
       " 550: array([ 917, 1421]),\n",
       " 551: array([ 293, 1202]),\n",
       " 552: array([ 400, 1373]),\n",
       " 553: array([646, 953]),\n",
       " 554: array([159, 412]),\n",
       " 555: array([ 85, 220]),\n",
       " 556: array([860, 945]),\n",
       " 557: array([ 208, 1316]),\n",
       " 558: array([ 632, 1140]),\n",
       " 559: array([1066, 1452]),\n",
       " 560: array([ 324, 1296]),\n",
       " 561: array([1148, 1477]),\n",
       " 562: array([1024, 1321]),\n",
       " 563: array([ 455, 1145]),\n",
       " 564: array([586, 627]),\n",
       " 565: array([1271, 1353]),\n",
       " 566: array([1290, 1408]),\n",
       " 567: array([557, 752]),\n",
       " 568: array([1171, 1205]),\n",
       " 569: array([1077, 1104]),\n",
       " 570: array([221, 396]),\n",
       " 571: array([ 62, 442]),\n",
       " 572: array([ 984, 1243]),\n",
       " 573: array([ 590, 1384]),\n",
       " 574: array([  47, 1374]),\n",
       " 575: array([ 983, 1461]),\n",
       " 576: array([ 688, 1031]),\n",
       " 577: array([ 534, 1552]),\n",
       " 578: array([  49, 1333]),\n",
       " 579: array([ 736, 1375]),\n",
       " 580: array([1023, 1186]),\n",
       " 581: array([841, 903]),\n",
       " 582: array([ 170, 1418]),\n",
       " 583: array([1372, 1403]),\n",
       " 584: array([690, 703]),\n",
       " 585: array([547, 663]),\n",
       " 586: array([201, 352]),\n",
       " 587: array([ 530, 1438]),\n",
       " 588: array([ 748, 1328]),\n",
       " 589: array([1253, 1474]),\n",
       " 590: array([1393, 1499]),\n",
       " 591: array([1013, 1317]),\n",
       " 592: array([ 607, 1410]),\n",
       " 593: array([1311, 1376]),\n",
       " 594: array([1282, 1304]),\n",
       " 595: array([  18, 1451]),\n",
       " 596: array([519, 861]),\n",
       " 597: array([813, 869]),\n",
       " 598: array([ 300, 1432]),\n",
       " 599: array([216, 398]),\n",
       " 600: array([ 713, 1435]),\n",
       " 601: array([1314, 1479]),\n",
       " 602: array([ 46, 116]),\n",
       " 603: array([1184, 1487]),\n",
       " 604: array([1201, 1401]),\n",
       " 605: array([ 215, 1231]),\n",
       " 606: array([583, 641]),\n",
       " 607: array([  91, 1206]),\n",
       " 608: array([ 283, 1325]),\n",
       " 609: array([1512, 1573]),\n",
       " 610: array([ 356, 1431]),\n",
       " 611: array([1128, 1517]),\n",
       " 612: array([1106, 1395]),\n",
       " 613: array([ 651, 1294]),\n",
       " 614: array([1166, 1402]),\n",
       " 615: array([  22, 1275]),\n",
       " 616: array([1005, 1370]),\n",
       " 617: array([ 505, 1434]),\n",
       " 618: array([1240, 1493]),\n",
       " 619: array([1338, 1544]),\n",
       " 620: array([ 631, 1459]),\n",
       " 621: array([207, 480]),\n",
       " 622: array([  63, 1549]),\n",
       " 623: array([1313, 1441]),\n",
       " 624: array([1276, 1436]),\n",
       " 625: array([ 942, 1495]),\n",
       " 626: array([ 650, 1496]),\n",
       " 627: array([712, 896]),\n",
       " 628: array([705, 757]),\n",
       " 629: array([ 61, 311]),\n",
       " 630: array([1153, 1433]),\n",
       " 631: array([1084, 1256]),\n",
       " 632: array([ 428, 1420]),\n",
       " 633: array([ 581, 1216]),\n",
       " 634: array([697, 960]),\n",
       " 635: array([1416, 1581]),\n",
       " 636: array([ 574, 1472]),\n",
       " 637: array([1041, 1391]),\n",
       " 638: array([ 742, 1407]),\n",
       " 639: array([1228, 1281]),\n",
       " 640: array([ 785, 1208]),\n",
       " 641: array([1015, 1099]),\n",
       " 642: array([1458, 1588]),\n",
       " 643: array([ 251, 1286]),\n",
       " 644: array([1330, 1443]),\n",
       " 645: array([1310, 1534]),\n",
       " 646: array([750, 961]),\n",
       " 647: array([1050, 1315]),\n",
       " 648: array([ 597, 1506]),\n",
       " 649: array([ 223, 1594]),\n",
       " 650: array([546, 993]),\n",
       " 651: array([ 987, 1127]),\n",
       " 652: array([1010, 1440]),\n",
       " 653: array([1234, 1413]),\n",
       " 654: array([1164, 1366]),\n",
       " 655: array([1346, 1463]),\n",
       " 656: array([1369, 1439]),\n",
       " 657: array([ 263, 1357]),\n",
       " 658: array([ 609, 1409]),\n",
       " 659: array([1192, 1331]),\n",
       " 660: array([ 642, 1545]),\n",
       " 661: array([1385, 1455]),\n",
       " 662: array([313, 974]),\n",
       " 663: array([817, 850]),\n",
       " 664: array([1251, 1634]),\n",
       " 665: array([587, 905]),\n",
       " 666: array([ 337, 1327]),\n",
       " 667: array([1381, 1483]),\n",
       " 668: array([1063, 1568]),\n",
       " 669: array([ 997, 1508]),\n",
       " 670: array([1453, 1541]),\n",
       " 671: array([1456, 1538]),\n",
       " 672: array([1020, 1334]),\n",
       " 673: array([ 219, 1527]),\n",
       " 674: array([1424, 1510]),\n",
       " 675: array([ 218, 1174]),\n",
       " 676: array([ 733, 1471]),\n",
       " 677: array([1476, 1537]),\n",
       " 678: array([1239, 1505]),\n",
       " 679: array([ 672, 1531]),\n",
       " 680: array([1387, 1533]),\n",
       " 681: array([ 725, 1371]),\n",
       " 682: array([1048, 1165]),\n",
       " 683: array([664, 709]),\n",
       " 684: array([1399, 1532]),\n",
       " 685: array([1094, 1465]),\n",
       " 686: array([ 132, 1565]),\n",
       " 687: array([1365, 1570]),\n",
       " 688: array([603, 678]),\n",
       " 689: array([ 673, 1523]),\n",
       " 690: array([ 198, 1295]),\n",
       " 691: array([1481, 1627]),\n",
       " 692: array([1389, 1482]),\n",
       " 693: array([1135, 1257]),\n",
       " 694: array([1530, 1585]),\n",
       " 695: array([  30, 1515]),\n",
       " 696: array([ 602, 1643]),\n",
       " 697: array([ 259, 1427]),\n",
       " 698: array([133, 362]),\n",
       " 699: array([1415, 1444]),\n",
       " 700: array([1245, 1600]),\n",
       " 701: array([1467, 1535]),\n",
       " 702: array([1198, 1562]),\n",
       " 703: array([1285, 1625]),\n",
       " 704: array([ 307, 1267]),\n",
       " 705: array([ 751, 1578]),\n",
       " 706: array([ 59, 279]),\n",
       " 707: array([1486, 1525]),\n",
       " 708: array([1448, 1550]),\n",
       " 709: array([1340, 1547]),\n",
       " 710: array([1392, 1511]),\n",
       " 711: array([1270, 1446]),\n",
       " 712: array([1466, 1546]),\n",
       " 713: array([1379, 1548]),\n",
       " 714: array([1489, 1663]),\n",
       " 715: array([1513, 1668]),\n",
       " 716: array([1516, 1574]),\n",
       " 717: array([1322, 1363]),\n",
       " 718: array([1237, 1423]),\n",
       " 719: array([453, 782]),\n",
       " 720: array([1429, 1644]),\n",
       " 721: array([ 569, 1478]),\n",
       " 722: array([1162, 1500]),\n",
       " 723: array([1485, 1641]),\n",
       " 724: array([1262, 1563]),\n",
       " 725: array([1297, 1589]),\n",
       " 726: array([ 909, 1524]),\n",
       " 727: array([1473, 1646]),\n",
       " 728: array([1368, 1616]),\n",
       " 729: array([1320, 1569]),\n",
       " 730: array([1260, 1430]),\n",
       " 731: array([ 714, 1657]),\n",
       " 732: array([1437, 1670]),\n",
       " 733: array([1397, 1626]),\n",
       " 734: array([1360, 1684]),\n",
       " 735: array([1484, 1604]),\n",
       " 736: array([1542, 1622]),\n",
       " 737: array([1223, 1648]),\n",
       " 738: array([1090, 1491]),\n",
       " 739: array([1289, 1623]),\n",
       " 740: array([1576, 1629]),\n",
       " 741: array([1528, 1649]),\n",
       " 742: array([1293, 1690]),\n",
       " 743: array([1551, 1633]),\n",
       " 744: array([1154, 1620]),\n",
       " 745: array([1064, 1566]),\n",
       " 746: array([1170, 1305]),\n",
       " 747: array([ 775, 1612]),\n",
       " 748: array([1450, 1642]),\n",
       " 749: array([1445, 1488]),\n",
       " 750: array([1522, 1651]),\n",
       " 751: array([1579, 1671]),\n",
       " 752: array([1350, 1480]),\n",
       " 753: array([1601, 1645]),\n",
       " 754: array([1454, 1660]),\n",
       " 755: array([1652, 1699]),\n",
       " 756: array([1580, 1592]),\n",
       " 757: array([1406, 1685]),\n",
       " 758: array([1497, 1539]),\n",
       " 759: array([1036, 1591]),\n",
       " 760: array([1377, 1417]),\n",
       " 761: array([1428, 1447]),\n",
       " 762: array([ 940, 1016]),\n",
       " 763: array([1536, 1593]),\n",
       " 764: array([1501, 1680]),\n",
       " 765: array([1624, 1689]),\n",
       " 766: array([1503, 1621]),\n",
       " 767: array([1390, 1687]),\n",
       " 768: array([1083, 1615]),\n",
       " 769: array([1613, 1706]),\n",
       " 770: array([1502, 1553]),\n",
       " 771: array([1307, 1614]),\n",
       " 772: array([1266, 1567]),\n",
       " 773: array([1288, 1747]),\n",
       " 774: array([1658, 1726]),\n",
       " 775: array([1284, 1504]),\n",
       " 776: array([1655, 1732]),\n",
       " 777: array([1475, 1665]),\n",
       " 778: array([1521, 1704]),\n",
       " 779: array([1529, 1678]),\n",
       " 780: array([1124, 1238]),\n",
       " 781: array([1558, 1662]),\n",
       " 782: array([1577, 1720]),\n",
       " 783: array([1040, 1292]),\n",
       " 784: array([1610, 1681]),\n",
       " 785: array([1250, 1396]),\n",
       " 786: array([1598, 1659]),\n",
       " 787: array([  56, 1718]),\n",
       " 788: array([1306, 1540]),\n",
       " 789: array([1179, 1677]),\n",
       " 790: array([ 526, 1308]),\n",
       " 791: array([1419, 1676]),\n",
       " 792: array([ 512, 1605]),\n",
       " 793: array([1269, 1653]),\n",
       " 794: array([1494, 1722]),\n",
       " 795: array([1147, 1619]),\n",
       " 796: array([1398, 1710]),\n",
       " 797: array([1683, 1716]),\n",
       " 798: array([1002, 1693]),\n",
       " 799: array([1323, 1664]),\n",
       " 800: array([1111, 1650]),\n",
       " 801: array([1564, 1759]),\n",
       " 802: array([1367, 1609]),\n",
       " 803: array([1571, 1599]),\n",
       " 804: array([1543, 1723]),\n",
       " 805: array([1070, 1217]),\n",
       " 806: array([1617, 1770]),\n",
       " 807: array([1073, 1739]),\n",
       " 808: array([1022, 1635]),\n",
       " 809: array([1009, 1628]),\n",
       " 810: array([1224, 1696]),\n",
       " 811: array([1509, 1717]),\n",
       " 812: array([1151, 1762]),\n",
       " 813: array([1349, 1700]),\n",
       " 814: array([1697, 1754]),\n",
       " 815: array([1630, 1714]),\n",
       " 816: array([1032, 1805]),\n",
       " 817: array([1602, 1715]),\n",
       " 818: array([1498, 1695]),\n",
       " 819: array([1751, 1794]),\n",
       " 820: array([1400, 1607]),\n",
       " 821: array([1464, 1603]),\n",
       " 822: array([1638, 1640]),\n",
       " 823: array([1673, 1744]),\n",
       " 824: array([1514, 1661]),\n",
       " 825: array([1103, 1737]),\n",
       " 826: array([1708, 1731]),\n",
       " 827: array([1278, 1758]),\n",
       " 828: array([1012, 1775]),\n",
       " 829: array([1639, 1666]),\n",
       " 830: array([1692, 1743]),\n",
       " 831: array([1587, 1742]),\n",
       " 832: array([1584, 1810]),\n",
       " 833: array([1412, 1746]),\n",
       " 834: array([1337, 1813]),\n",
       " 835: array([1468, 1795]),\n",
       " 836: array([1554, 1597]),\n",
       " 837: array([1339, 1457]),\n",
       " 838: array([1595, 1788]),\n",
       " 839: array([1773, 1820]),\n",
       " 840: array([1336, 1507]),\n",
       " 841: array([1701, 1740]),\n",
       " 842: array([1691, 1755]),\n",
       " 843: array([1072, 1711]),\n",
       " 844: array([1470, 1760]),\n",
       " 845: array([1080, 1721]),\n",
       " 846: array([1442, 1596]),\n",
       " 847: array([1520, 1815]),\n",
       " 848: array([1460, 1735]),\n",
       " 849: array([1753, 1801]),\n",
       " 850: array([1606, 1725]),\n",
       " 851: array([1062, 1656]),\n",
       " 852: array([1196, 1582]),\n",
       " 853: array([1560, 1727]),\n",
       " 854: array([1738, 1785]),\n",
       " 855: array([1590, 1768]),\n",
       " 856: array([1345, 1779]),\n",
       " 857: array([1749, 1798]),\n",
       " 858: array([1637, 1707]),\n",
       " 859: array([1076, 1694]),\n",
       " 860: array([1572, 1812]),\n",
       " 861: array([1736, 1783]),\n",
       " 862: array([1559, 1792]),\n",
       " 863: array([1675, 1847]),\n",
       " 864: array([1101, 1557]),\n",
       " 865: array([1819, 1839]),\n",
       " 866: array([1724, 1776]),\n",
       " 867: array([1730, 1766]),\n",
       " 868: array([1734, 1782]),\n",
       " 869: array([1229, 1767]),\n",
       " 870: array([1756, 1840]),\n",
       " 871: array([1679, 1713]),\n",
       " 872: array([1750, 1777]),\n",
       " 873: array([1672, 1752]),\n",
       " 874: array([1586, 1728]),\n",
       " 875: array([1014, 1850]),\n",
       " 876: array([1765, 1818]),\n",
       " 877: array([1682, 1800]),\n",
       " 878: array([1771, 1806]),\n",
       " 879: array([1608, 1631]),\n",
       " 880: array([1705, 1831]),\n",
       " 881: array([1825, 1841]),\n",
       " 882: array([1674, 1748]),\n",
       " 883: array([1763, 1866]),\n",
       " 884: array([1006, 1781]),\n",
       " 885: array([1332, 1804]),\n",
       " 886: array([1733, 1817]),\n",
       " 887: array([1004, 1853]),\n",
       " 888: array([1490, 1778]),\n",
       " 889: array([1003, 1061]),\n",
       " 890: array([1561, 1780]),\n",
       " 891: array([1808, 1826]),\n",
       " 892: array([1309, 1823]),\n",
       " 893: array([1158, 1802]),\n",
       " 894: array([1741, 1877]),\n",
       " 895: array([1719, 1834]),\n",
       " 896: array([1769, 1827]),\n",
       " 897: array([1556, 1833]),\n",
       " 898: array([1757, 1846]),\n",
       " 899: array([1303, 1838]),\n",
       " 900: array([1774, 1786]),\n",
       " 901: array([1075, 1807]),\n",
       " 902: array([1526, 1799]),\n",
       " 903: array([1703, 1860]),\n",
       " 904: array([1836, 1882]),\n",
       " 905: array([1667, 1803]),\n",
       " 906: array([1518, 1864]),\n",
       " 907: array([1745, 1862]),\n",
       " 908: array([1583, 1709]),\n",
       " 909: array([1519, 1849]),\n",
       " 910: array([1669, 1791]),\n",
       " 911: array([1712, 1772]),\n",
       " 912: array([1702, 1888]),\n",
       " 913: array([1790, 1844]),\n",
       " 914: array([1811, 1821]),\n",
       " 915: array([1814, 1843]),\n",
       " 916: array([1875, 1897]),\n",
       " 917: array([1698, 1885]),\n",
       " 918: array([1555, 1870]),\n",
       " 919: array([1359, 1900]),\n",
       " 920: array([1824, 1861]),\n",
       " 921: array([1159, 1892]),\n",
       " 922: array([1688, 1852]),\n",
       " 923: array([1857, 1895]),\n",
       " 924: array([1787, 1828]),\n",
       " 925: array([1793, 1868]),\n",
       " 926: array([1414, 1863]),\n",
       " 927: array([1654, 1886]),\n",
       " 928: array([1618, 1867]),\n",
       " 929: array([1848, 1879]),\n",
       " 930: array([1386, 1764]),\n",
       " 931: array([1851, 1898]),\n",
       " 932: array([1884, 1910]),\n",
       " 933: array([1575, 1858]),\n",
       " 934: array([1761, 1871]),\n",
       " 935: array([1842, 1905]),\n",
       " 936: array([1809, 1887]),\n",
       " 937: array([1873, 1894]),\n",
       " 938: array([1908, 1924]),\n",
       " 939: array([1686, 1926]),\n",
       " 940: array([1816, 1920]),\n",
       " 941: array([1636, 1874]),\n",
       " 942: array([1835, 1837]),\n",
       " 943: array([1896, 1919]),\n",
       " 944: array([1796, 1829]),\n",
       " 945: array([1854, 1889]),\n",
       " 946: array([1901, 1932]),\n",
       " 947: array([1891, 1913]),\n",
       " 948: array([1890, 1942]),\n",
       " 949: array([1832, 1917]),\n",
       " 950: array([1872, 1893]),\n",
       " 951: array([1909, 1937]),\n",
       " 952: array([1869, 1935]),\n",
       " 953: array([1927, 1928]),\n",
       " 954: array([1830, 1931]),\n",
       " 955: array([1789, 1903]),\n",
       " 956: array([1611, 1941]),\n",
       " 957: array([1856, 1933]),\n",
       " 958: array([1904, 1907]),\n",
       " 959: array([1845, 1906]),\n",
       " 960: array([1859, 1922]),\n",
       " 961: array([1876, 1881]),\n",
       " 962: array([1729, 1940]),\n",
       " 963: array([1632, 1936]),\n",
       " 964: array([1822, 1947]),\n",
       " 965: array([1797, 1883]),\n",
       " 966: array([1916, 1921]),\n",
       " 967: array([1912, 1956]),\n",
       " 968: array([1915, 1934]),\n",
       " 969: array([1647, 1958]),\n",
       " 970: array([1784, 1945]),\n",
       " 971: array([1911, 1930]),\n",
       " 972: array([1918, 1961]),\n",
       " 973: array([1878, 1954]),\n",
       " 974: array([1925, 1949]),\n",
       " 975: array([1902, 1923]),\n",
       " 976: array([1855, 1939]),\n",
       " 977: array([1914, 1944]),\n",
       " 978: array([1952, 1959]),\n",
       " 979: array([1865, 1953]),\n",
       " 980: array([1957, 1968]),\n",
       " 981: array([1899, 1963]),\n",
       " 982: array([1938, 1960]),\n",
       " 983: array([1948, 1964]),\n",
       " 984: array([1971, 1973]),\n",
       " 985: array([1880, 1929]),\n",
       " 986: array([1965, 1967]),\n",
       " 987: array([1955, 1977]),\n",
       " 988: array([1950, 1981]),\n",
       " 989: array([1966, 1976]),\n",
       " 990: array([1946, 1978]),\n",
       " 991: array([1975, 1980]),\n",
       " 992: array([1974, 1982]),\n",
       " 993: array([1969, 1986]),\n",
       " 994: array([1962, 1970]),\n",
       " 995: array([1951, 1983]),\n",
       " 996: array([1979, 1989]),\n",
       " 997: array([1943, 1984]),\n",
       " 998: array([1972, 1990]),\n",
       " 999: array([1985, 1988]),\n",
       " 1000: array([1993, 1994]),\n",
       " 1001: array([1987, 1995]),\n",
       " 1002: array([1991, 1992]),\n",
       " 1003: array([1996, 1997])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(enumerate(cluster_model.children_, model.n_leaves_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b5e27",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "**Tried: Google Pegasus**. Result: Does a terrible job of keeping the important information and doesn't retain the question but guesses at a conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "076b9f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589705e3",
   "metadata": {},
   "source": [
    "### Pegasus Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "86cc4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = 'google/pegasus-xsum'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "80af86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize(sentences):\n",
    "    batch = tokenizer(sentences, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = model.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f91cc803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"California's largest electricity provider has turned off power to hundreds of thousands of customers.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11661be",
   "metadata": {},
   "source": [
    "### T5 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43fc94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e37632933d4534a5439599ca172b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce6b42c378c4089b2315f3037eeee8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b927031f53466ba6ed9a35f4c06c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fbc23214fe43559fd6abe6cb827e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573bc27bf1c4411faefadf70c8d14a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c928702f8bf649ab920e40e3b93a4f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cfda12b357e456580cb1c331fa94f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "ARTICLE = \"\"\" Background: Trust is a critical component of competency committees given their high-stakes decisions. Research from outside of medicine on group trust has not focused on trust in group decisions, and \"group trust\" has not been clearly defined. The purpose was twofold: to examine the definition of trust in the context of group decisions and to explore what factors may influence trust from the perspective of those who rely on competency committees through a proposed group trust model. Methods: The authors conducted a literature search of four online databases, seeking articles published on trust in group settings. Reviewers extracted, coded, and analyzed key data including definitions of trust and factors pertaining to group trust. Results: The authors selected 42 articles for full text review. Although reviewers found multiple general definitions of trust, they were unable to find a clear definition of group trust and propose the following: a group-directed willingness to accept vulnerability to actions of the members based on the expectation that members will perform a particular action important to the group, encompassing social exchange, collective perceptions, and interpersonal trust. Additionally, the authors propose a model encompassing individual level factors (trustor and trustee), interpersonal interactions, group level factors (structure and processes), and environmental factors.\"\"\"\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"snrspeaks/t5-one-line-summary\") #snrspeaks/t5-one-line-summary\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snrspeaks/t5-one-line-summary\")\n",
    "\n",
    "# T5 uses a max_length of 512 so we cut the article to 512 tokens.\n",
    "inputs = tokenizer.encode(\"summarize: \" + ARTICLE, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "tokenizer.decode(outputs[0])\n",
    "def summarize(text):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a69144",
   "metadata": {},
   "source": [
    "### Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c82df11e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difficulty with this task lies in the fact that prosodic cues are never absolute ; they are relative to individual speakers , gender , dialect , discourse context , local context , phonological environment , and many other factors.Apart from system delay , another current limitation that will influence future interactive speech systems is the unavailability of full prosodic analysis.One obvious shortcoming is that some information gets lost in the thresholding that converts posterior probabilities from the prosodic model and the auxiliary LM into binary features.One major time and cost limitation in developing LVCSR systems in Indian languages is the need for large training data \n",
      "\n",
      " sum::: ['The aim of this paper is to develop a speech recognition system (LVCSR) based on prosodic cues.'] \n",
      "\n",
      "\n",
      "\n",
      "The problem with rich annotations is that they increase the state space of the grammar substantially.The only shortcoming is the cost of annotation.But we also believe that ultimately this issue of annotator bias.This issue of annotator bias.Another shortcoming of our approach is that it requires us to be disciplined in our pass/overgeneration annotations \n",
      "\n",
      " sum::: ['In this paper we show how to create rich annotated grammars.'] \n",
      "\n",
      "\n",
      "\n",
      "As a consequence , when adapting existing methods and techniques to a new domain , researchers and users are faced with the problem of absence of annotated material that could be used for training.The latter approach has the potential weakness of unsupervised training erasing what was learned from the manually annotated corpus.We consider the problem of NER in Arabic Wikipedia , a semisupervised domain adaptation setting for which we have no labeled training data in the target domain.The main limitation of the first approach in the context of this challenge is that it is completely unsupervised and therefore does not take advantage of the training set provided by the task organizers \n",
      "\n",
      " sum::: ['In the domain of natural language processing, there is a large corpus of annotated material.'] \n",
      "\n",
      "\n",
      "\n",
      "The second problem of traditional word alignment approaches is the fact that parameter estimations are usually based on plain text items only.However , the main limitation of existing studies is that the individuals’ propensity of alignment is only characterized using a proportion of lexical elements.Although experiments show that this constituent matching/violation counting feature achieves significant improvements on various language-pairs , one issue is that matching syntactic analysis can not always guarantee a good translation.One clear weakness is the selection of only a single alignment from the distribution of source words at the end of 1,000 walks , since this does not allow for one-to-many mappings.The main limitation of this work is that the features considered are local to the alignment links joining pairs of words \n",
      "\n",
      " sum::: ['The first problem of word alignment approaches is the fact that it is not possible to predict the word alignment links joining pairs of words.'] \n",
      "\n",
      "\n",
      "\n",
      "The main drawback of these systems is that they fail to recognize terms which are not included in the dictionary.An obvious drawback is that it is necessary to re-classify many words if the application domain changes significantly.Its disadvantage is that sense disambiguation is not carried out relative to any well defined set of senses , but rather an ad hoc set.As also suggested in ( Pradhan et al. , 2008 ) , the major drawback is the poor generalization power affecting lexical features.A drawback is that their method limits the training of multi-sense embeddings to the M most common words , forcing a complete re-training of the model should a new word of interest appear.The disadvantage is that many synonyms need to be discarded in order to achieve this property.The main drawback with these approaches lies in the WordNet structure itself , where frequently two semantically similar senses are distant in the WordNet hierarchy.A major drawback is the low coverage of the lexicon.Its major drawback is the low number of paraphrases.The main drawback of using CLWSD to evaluate lexical choice is that CLWSD is a lexical sample task , which only evaluates disambiguation of 20 English nouns.A potential drawback of this approach is that it depends heavily on the existence of dictionaries , however these are not always available for any domain and language or if they exist , their coverage is very scarce . \n",
      "\n",
      " sum::: ['The main drawback of these systems is that they fail to recognize terms which are not included in the dictionary.'] \n",
      "\n",
      "\n",
      "\n",
      "Although these approaches do not suffer from so-called label-bias problems ( Lafferty et al. , 2001 ) , one limitation is that they are inefficient to train with large-scale , especially large category data.A main problem with this approach is that , in the majority of the cases , labels are hard to find and thus the amount of training data is limited ..A drawback of these approaches is they still require a manually labelled dataset for training , which is itself time-consuming to produce and still introduces an element of subjectivity ..However , a major drawback of these machine learning-based approaches is that a large amount of data should be labeled in order to let the prediction system learn a classifier of good generalization ability . \n",
      "\n",
      " sum::: ['A number of machine learning-based approaches have been proposed to train prediction systems on large datasets.'] \n",
      "\n",
      "\n",
      "\n",
      "To overcome the disadvantage of measure word generation in a general SMT system.A large drawback of SMT systems is that they use no or little grammatical knowledge , relying mainly on a target language model for producing correct target language texts , often resulting in ungrammatical output.A major problem with machine translation , regardless of the translation method , is that performance drops rapidly as input sentences become longer.A well-known problem of Statistical Machine Translation ( SMT ) is that performance quickly degrades as soon as testing conditions deviate from training conditions \n",
      "\n",
      " sum::: ['The aim of this research is to improve the performance of Statistical Machine Translation ( SMT ).'] \n",
      "\n",
      "\n",
      "\n",
      "However , the problem is not totally solved because many verb reorderings are still missed.The problem is that the non-contiguous elements in a verbchain are assigned into a single node while the subject in between belongs to its own node.The other problem is that the parse trees of original and compressed sentences sometimes do not correspond \n",
      "\n",
      " sum::: ['We have solved the problem of missing verb reorderings in verb chains.'] \n",
      "\n",
      "\n",
      "\n",
      "Furthermore , most pattern-based methods rely on term frequency , which have the limitation of finding infrequent but important product features.The main disadvantage with the naive algorithm is that it queries each term appearing in each list and hence , suffers from high run time cost \n",
      "\n",
      " sum::: ['This paper presents a naive algorithm for finding the most important features of a product in a list of thousands of products.'] \n",
      "\n",
      "\n",
      "\n",
      "This solution can avoid the problem of the expansion of CFG rules.However , the main limitation of existing approaches is that they are ad-hoc : the rules that govern word formation and inflection are only implicit in such systems , usually intertwined with control structures and general code.One disadvantage of the model above is that it is not capable of modeling bilexical dependencies on the right hand side of the rules.The problem with this approach is that creating these rules requires much cost and that they are usually domain-dependent.It is trivial to implement , but the disadvantage is , of course , that we would have to store one rule for each utterance that we would like our system to produce \n",
      "\n",
      " sum::: ['In this paper we present a solution to the problem of word formation and inflection: we model the rules that govern the formation of words and the inflection of utterances.'] \n",
      "\n",
      "\n",
      "\n",
      "The main weakness of this method is that an SF error can be corrected only if the right SF appears at least in one of the n-best parse trees.One shortcoming of the dual decomposition approach is that it only applies to parse-scoring functions with an arc-factored component.We have found that the problem of combinatorial explosion in parsing English.One drawback of the reranking approach is that correct SF for the predicates of a sentence can actually appear in different parse trees.We will focus in this paper on one kind of weakness of such parser which is their inability to properly take into account subcategorization frames ( SF ) of predicative lexemes2.And the shell contains a system for evaluating parses , extending IIeidorn 's ( 1982 ) parse metric , which is used not only for ranking final parses but also for pruning away unlikely partial analyses during parsing , thus reducing the problem of parse space explosion.However , one shortcoming of existing parsers is that as the complexity of the sentences recognized increases , the computational complexity increases quadratically.A possible problem with this method is in the approximation of exponentially many parse trees by a polynomial-size sample.But in parsing we have a problem of the explosion of possible constituents.A drawback is that this structure may be cubic in the length of the parsed sentence , and more generally polynomial for some proposed algorithms.A frequent response to the problem of an explosion of syntactic parses in natural language systems.On the other hand the relatively low upper bound for the CCG parser on DepBank.However , similarly to the previous studies on HPSG parsing , these groups had no solution to the problem of exponential explosion of unpacked parse results \n",
      "\n",
      " sum::: ['The dual decomposition of syntactic parses is one of the most popular methods for correcting SF errors in natural language systems.'] \n",
      "\n",
      "\n",
      "\n",
      "This fact in turn caused the problem of underrepresentation of Kazakh language in various fields such as science , entertainment , official documentation , etc ..The other important criterion is the ability to read Kazakh , since not all of the interviewees could read in Kazakh sufficiently fluent \n",
      "\n",
      " sum::: ['One of the main reasons for the low number of Kazakh speakers in the world today is the fact that the number of Kazakh speakers in the world is very low.'] \n",
      "\n",
      "\n",
      "\n",
      "Perhaps the biggest limitation is the small number of research participants.Another limitation is that the research was conducted using a single system.Another limitation is that it is hard to obtain data big enough to split the data into subparts for both the hierarchical mixed model analysis and classification.However , one problem with this approach is that there is no guarantee that other medical experts will rate the sites in a similar manner ..A current limitation with these approaches is that they require each rater to generate a complete dataset , which is often impossible given both human foibles and the typical turnover rate of raters in a research or clinical environment . \n",
      "\n",
      " sum::: ['There are a number of approaches to rating medical sites.'] \n",
      "\n",
      "\n",
      "\n",
      "To cope with the problem of sparse training resources.We also address the issue of sparse or impoverished training data.First , as maximum margin classifiers , they sidestep the common issue of overfitting.They also discussed the issue of training with unbalanced data \n",
      "\n",
      " sum::: ['In this paper, we introduce a new approach to train classifiers.'] \n",
      "\n",
      "\n",
      "\n",
      "One probable disadvantage is that the scheme will be less general.The disadvantage is that it is likely to worsen the generalising power of the model.The main drawback is that the entries produced automatically need some semimanual checking.A possible drawback is that for some inputs , the right output might not be available in the set considered by the training data , even if it might easily be constructed from known parts using a generative approach.The disadvantage is that , as all the results are not manually validated , some resulting classifications can appear incorrect.The main drawback is that training time is increased because of the extra nested loop needed to calculate feature covariances.It has many positive features , but one drawback is that it does not provide estimates of class membership probabilities.A drawback is that the time complexity of inference as presented here is quadratic in the number of classes rather than linear.The drawback is that it causes sensitivity to outliers.Their drawback is that , as most generative models , they are generally computed to maximize the joint likelihood of the training data \n",
      "\n",
      " sum::: ['The main advantage of this approach is that it does not require any manual validation.'] \n",
      "\n",
      "\n",
      "\n",
      "A notorious problem with computational linguistics is that there is no path into it.The main drawback of applying this technique in dialectometry is that it is not directly related to the aggregate analysis , but is rather an independent step.A remaining problem is that no studies could provide empirical comparisons across grammar theories.It is , however , not intended to replace corpus studies because it has the drawback of not being able to take into account the influence of a wider linguistic environment \n",
      "\n",
      " sum::: ['The aim of this paper is to develop a method of dialectometry that can provide empirical comparisons between grammar theories.'] \n",
      "\n",
      "\n",
      "\n",
      "A serious problem in manual nugget creation is the inconsistency in human decisions ( Lin and Hovy , 2003 ).This problem of circularity in expert coding.The bottleneck in Artificial Intelligence is the unbalanced knowledge sources shared by human beings and a computer system.From a cognitive perspective , the most obvious weakness of our algorithm is its strict incrementality \n",
      "\n",
      " sum::: ['In this paper, we show how to train an artificial intelligence algorithm on nugget creation.'] \n",
      "\n",
      "\n",
      "\n",
      "The limitation is that word vectors developed from distributional models cannot reveal word relatedness if its information does not lie in word distributions.However , its limitation is that the distance measure does not capture sufficient information of semantic relations between language constituents.There are two main ( not unrelated ) disadvantages to word similarity based approaches : 1. word co-occurrence information is not sufficiently exploited.One potential limitation of using only similarity features to represent a text pair is that of low representation power.A second limitation of the approach presented in this paper is that the metric used to measure the similarity between strings ( n-gram overlap ) is only a crude approximation of an ideal semantic similarity metric.Its main weakness is that it does not take into account the semantic similarities between the words that are combined in the CDSM models.Another limitation of the current implementation is the limited scope of the similarity function \n",
      "\n",
      " sum::: ['The goal of this paper is to develop a word similarity based approach to represent a text pair.'] \n",
      "\n",
      "\n",
      "\n",
      "While these algorithms usually achieve the best performance , as compared to their unsupervised or knowledge-based alternatives , there is an important shortcoming associated with these methods : their applicability is limited only to those words for which sense tagged data is available.Two types of solutions have been proposed for the problem of low agreement on sense tagging.While the supervised learning approach has been successful , it has the drawback of requiring manually sense-tagged data.The biggest limitation associated with this method is the need for large amounts of sense-tagged data \n",
      "\n",
      " sum::: ['In the field of natural language processing, there are a number of methods for learning from sense-tagged data.'] \n",
      "\n",
      "\n",
      "\n",
      "One drawback of this work is that depth-boundedness is undecidable.We counter the problem of a large parameter space.A resulting limitation is that the bound is loose in many cases \n",
      "\n",
      " sum::: ['This paper presents a new approach to the problem of depth-boundedness in Hilbert spaces.'] \n",
      "\n",
      "\n",
      "\n",
      "This problem arises due to limited vowel presentation in this writing system.The first problem is that Mongolian uses the Cyrillic alphabet to represent both conventional words and loanwords , and so the automatic extraction of loanwords is difficult.Although this method does not require the availability of English pronunciation , it has a serious limitation because it does not provide a mechanism for inserting the omitted short vowels in Arabic names.The main problem is that even though several Slavic languages have the same property as Czech , the ambiguity is not preserved \n",
      "\n",
      " sum::: ['The Mongolian language has a problem with ambiguity.'] \n",
      "\n",
      "\n",
      "\n",
      "What the author and her colleagues have done to avoid the problem of analyzer bias.We must hence accept the intrinsic limitation of using a bias whose source is the introspection of a single , or of a community of scientists.An inherent difficulty of this approach for the reader is that we only get to see a small subset of the examples that the experimenter has collected and our view is controlled by the opinions of an analyst , who typically was not a participant to the conversation and who might not even have been present at the time.A potential problem with this evidence is that normal young adults have an a priori leftward bias ( e.g. , Jewell & McCourt , 2000 ) ..A limitation of this study , as with any survey-based research , is that selection and recall bias may have been present . \n",
      "\n",
      " sum::: ['The problem of selection and recall bias in research is well known.'] \n",
      "\n",
      "\n",
      "\n",
      "So the loss and distortion of semantic information.Moreover , a shortcoming of occurrence-based methods of polysemy resolution is that a given term may be assigned to an implausibly large number of categories.A weakness of the term recognition part is , however , that too many terms were identified , which in turn led to the aforementioned inflation in vocabulary size.A major problem with describing category structure in terms of similarity is that the notion of similarity is too unconstrained to give an account of conceptual coherence . \n",
      "\n",
      " sum::: [\"It is well known that the size of a word's vocabulary increases as the number of terms it contains increases.\"] \n",
      "\n",
      "\n",
      "\n",
      "The problem of data sparseness for PCFG.The major problem of this approach is data sparseness.The only weakness of this strategy is its apparent inadequacy in dealing with the sparse data problem.The problem of data sparseness \n",
      "\n",
      " sum::: ['This paper presents a strategy for dealing with the problem of data sparseness for PCFG.'] \n",
      "\n",
      "\n",
      "\n",
      "A common problem for unsupervised models trained on verb-object tuples is that the objects can belong to more than one semantic class.A key challenge in this task is sparsity of labeled data : a given predicate-role instance may only occur a handful of times in the training set.The major limitation of supervised approaches is that they require meaning annotations for example sentences.Although our original aim was to develop a probabilistic framework that exploits Levin’s ( 1993 ) linguistic classification and the systematic correspondence between syntax and semantics , a limitation of the model is that it can not infer class information for verbs not listed in Levin.One weakness of this rulebased tagger is that no unsupervised training algorithm has been presented for learning rules automatically without a manually annotated corpus \n",
      "\n",
      " sum::: ['In this paper we present a rule-based tagger for learning verb-objects that does not require a manually annotated corpus.'] \n",
      "\n",
      "\n",
      "\n",
      "Although there exist abundant collections of raw text , the high expense of manually annotating the text.Their disadvantage is that a tagged corpus is essential for training.A drawback is that the corpus is not publicly available yet.The problem is that the procedure of building such a reference corpus is expensive \n",
      "\n",
      " sum::: ['In our series of letters from African journalists, novelist and writer Colm Tibn looks at the challenges of building a reference corpus.'] \n",
      "\n",
      "\n",
      "\n",
      "The main problem of non-lexicalized context-free grammars is that nonterminal symbols encode too general information which weakly discriminates syntactic ambiguities.While these models are well suited for the effective handling of highly divergent sentential word orders , the above frameworks have a limitation shared with probabilistic context free grammars that the preferred ordering of subtrees is insufficiently constrained by their embedding context.One limitation of using the CLE algorithm for generation is that the resulting tree , though maximal in probability , may not conform to basic linguistic properties of a dependency tree.The main difficulty with the model is that because constraints on pronominal anaphora are stated entirely in terms of configurational relations of tree geometry , specifically , in terms of c-command and minimal dominating S and NP domains , control and unbounded dependency structures can only be handled by additional and fairly complex devices.Nevertheless , this approach has a drawback of over-generating ungrammatical sentences due to its “almost-free” alignment.A drawback of our method is that it increases the size of the synchronous context-free grammar massively.However , a fundamental problem with this system is that it does not guarantee that the output parse is a projective dependency tree , only a projective dependency forest , that is , a sequence of adjacent , non-overlapping projective trees ( Nivre 2008 ) \n",
      "\n",
      " sum::: ['In this paper, we develop a synchronous context-free grammar based on a projective dependency tree ( CLE ) algorithm.'] \n",
      "\n",
      "\n",
      "\n",
      "HCDAE outperforms single DAE for high dimensional feature learning ( row 6 vs. 5 ; row 9 vs. 8 ; row 14 vs. 13 ; row 17 vs. 16 ) , and further improve the performance of DAE feature learning , which can also somewhat address the bring shortcoming of the limited input features.A main drawback of manifold learning methods is , however , that there are no explicit mappings from the input data manifold to the output embedding . \n",
      "\n",
      " sum::: ['In this paper, we have proposed a new manifold learning method for feature learning called HCDAE, which achieves better performance than the single DAE method.'] \n",
      "\n",
      "\n",
      "\n",
      "While this study introduces statistical measures to evaluate instance reliability , it remains vulnerable to data sparseness and has the limitation of taking into consideration only one-word terms.While this study introduces statistical measures to evaluate instance quality , it remains vulnerable to data sparseness and has the limitation of considering only one-word terms \n",
      "\n",
      " sum::: ['This study introduces statistical measures to evaluate instance reliability and has the limitation of taking into consideration only one-word terms.'] \n",
      "\n",
      "\n",
      "\n",
      "Our heuristics currently allow some such exceptions to be found , although they are by no means a complete solution to the problem of exceptions.Despite the fact that a major limitation to our approach are the false positive events that are propagated from the original EE system \n",
      "\n",
      " sum::: ['In this paper we present a new approach to the problem of finding exceptions in the EE system.'] \n",
      "\n",
      "\n",
      "\n",
      "The challenge of this task is the much skewed distribution in real text.A difficulty to achieving this is the exponential relationship between the number of possible paraphrases of a summary of a set of facts and the number of facts in that set \n",
      "\n",
      " sum::: ['The aim of this paper is to produce a summary of a set of facts that can be paraphrased.'] \n",
      "\n",
      "\n",
      "\n",
      "While MERT does not scale to large numbers of features , the scarcity of manually aligned training data.This has the potential drawback of increasing the number of features , which can make MERT less stable ( Foster and Kuhn , 2009 ) \n",
      "\n",
      " sum::: ['MERT is a web-based tool that allows users to train their own neural networks.'] \n",
      "\n",
      "\n",
      "\n",
      "A major drawback of this early work was that it used no lexical information in the supertagging process as the training material consisted of ( part-of-speech , supertag ) pairs.The only drawback is , that we are confronted , again , with a syntactic feature containing , among other things , records of derivation history.One shortcoming of our current approach is that we focus mostly on unitary sources of overgeneration : a single lexical item , tree property or derivation operation that consistently occurs in overgenerated strings.The drawback was that morphotactics was explicitly raised to the level of the sentence grammar , hence the categorial lexicon accounted for both constituent order and the morpheme order with no distinction \n",
      "\n",
      " sum::: ['The supertagging of strings was first proposed in the 1970s as a method for training new strings.'] \n",
      "\n",
      "\n",
      "\n",
      "Despite of their success , a limitation of them is that their performances are easily affected by the size of the context window.A major problem with interactive displays based on front projection is that users cast undesirable shadows on the display surface ..Furthermore , it always holds a drawback of writing color buffers multi-times per frame ..The limitations of image interpretation using smartphones are a major drawback of DICOM viewing applications . \n",
      "\n",
      " sum::: ['Interactive displays based on front projection have become one of the most popular display technologies in recent years.'] \n",
      "\n",
      "\n",
      "\n",
      "Furthermore , one possible drawback in employing this bootstrapping method is that there may be a complementary distribution between prosodic and lexical features.In the case of Japanese text processing , the most serious problem is poor accuracy of word segmentation and POS tagging.A shortcoming which is common to all of these approaches using a “percent correct” measurement to evaluate models of part-of-speech induction is that in assigning an induced word cluster to a known target category , such as noun , and evaluating the goodness of the cluster according to how well it represents the class noun , the assumption is made that it is fine for a target class to be represented by multiple induced clusters , but it is unacceptable for a single induced category to represent a combination of multiple target categories.Thus , we can overcome effectively the problem of unobserved co-occurrences of words in the training corpus.The main drawback is the strong confidence this approach places on word boundaries ( Beaufort et al. , 2010 ).The most important limitation of the evaluation that we have given in this paper is that we have only considered single words as context.Many hand-tested corpus evaluations have been done in the past ( e.g. , Walker 1989 ; Strube 1998 ; Mitkov 1998 ; Strube and Hahn 1999 ) , but these have the drawback of being carried out on small corpora \n",
      "\n",
      " sum::: ['The bootstrapping method of part-of-speech induction has been widely used to train text processing systems, but it is not well known how well it works.'] \n",
      "\n",
      "\n",
      "\n",
      "Its most obvious drawback is that the method can translate only those source language strings contained in the translation database.However , this method has the major drawback of needing to build a new phrase table for each document to translate \n",
      "\n",
      " sum::: ['The Translate method can be used to translate text from one language to another.'] \n",
      "\n",
      "\n",
      "\n",
      "A major weakness of many existing scoring engines such as the Intelligent Essay AssessorTM ( Landauer et al. , 2003 ) is that they adopt a holistic scoring scheme , which summarizes the quality of an essay with a single score and thus provides very limited feedback to the writer.A major weakness of many existing essay scoring engines such as IntelliMetric ( Elliot , 2001 ) and Intelligent Essay Assessor ( Landauer et al. , 2003 ) is that they adopt a holistic scoring scheme , which summarizes the quality of an essay with a single score and thus provides very limited feedback to the writer \n",
      "\n",
      " sum::: ['The aim of this paper is to develop an essay scoring engine that provides feedback on the quality of an essay.'] \n",
      "\n",
      "\n",
      "\n",
      "The latter drawback is the more serious one : the metrics were not designed to evaluate single key/response pairs , but whole texts.A second limitation is that various metrics may be highly correlated with one another , and provide redundant information on performance.A basic problem with productivity monitoring has been that standards have been perceived as absolute and short term ..A drawback of existing tools is their focus on identifying single factors associated with the observed or measured ranks , failing to address relationships between these factors . \n",
      "\n",
      " sum::: ['There are two main drawbacks of productivity monitoring tools: first, they are not easy to use, and second, they do not provide a clear picture of productivity.'] \n",
      "\n",
      "\n",
      "\n",
      "The disadvantage of this approach is that it involves a good deal of human effort to research on a specific data set and summarize the rules.This approach has the drawback of biasing somewhat the frequencies in our data set towards the categories that take precedence.One main problem with this approach is that these programs are written on a case-by-case basis because the data sets involved are heterogeneous in structure ..A drawback of the compound Poisson approach is that the relevant probabilities must be determined through a recursion relation and such calculations can be computationally intensive if the cluster size is relatively large or if analyses are conducted with strata variables ..A significant drawback of currently available algorithms is the need to use empirical parameters or rely on indirect quality measures to estimate the degree of complexity , i.e. , the number of subgroups present in the sample ..The results showed that a major drawback of the JPS classification is that is difficult to apply and has poor reproducibility . \n",
      "\n",
      " sum::: ['In the past few years, there has been a growing interest in the development of programs that can classify large data sets.'] \n",
      "\n",
      "\n",
      "\n",
      "The most significant drawback is that ontologies are not standard among systems.One limitation is that we have been using the same set of features for all concepts.Their main drawback is that they may or may not produce the term types and granularities useful to the user.The limitation is that the choice of the appropriate conceptual types is non trivial , even when selecting very high-level tags.A main drawback of these knowledge-based systems is the knowledge representation formalisms they use . \n",
      "\n",
      " sum::: ['A knowledge-based system is one that uses concepts to represent knowledge.'] \n",
      "\n",
      "\n",
      "\n",
      "The limitation of locating parts of arguments , such as the positions and head words , is that it is only a partial solution to argument labeling in discourse parsing.However , this approach has several practical limitations : ( 1 ) it does not consider the problem of argument identification of SRL systems , treating arguments as already given ; ( 2 ) it generates rules for the argument classification step preferably from manually annotated data ; ( 3 ) it has been demonstrated for a single language ( French ) , and was not applied to any other language \n",
      "\n",
      " sum::: ['This paper presents a new approach to argument classification in speech recognition systems (SRLs).'] \n",
      "\n",
      "\n",
      "\n",
      "The only drawback or risk of this strategy is that some of the system timex-values could be incorrect.A disadvantage of TNF is that it re-attaches a single node in every iteration.To address this concern , a sequential MTS was proposed , but it has the drawback of an increase of the number of possible MTSs as Nt becomes random . \n",
      "\n",
      " sum::: ['In this paper, we show that a multi-valued system ( MTS) can be solved with a single iteration of a Markov chain Monte Carlo (MMC).'] \n",
      "\n",
      "\n",
      "\n",
      "However , the WCN does not assign probability to the u = fi* case –.The main drawback to modeling p ( t Is ) in terms of p ( w I h , s ) is that the latter distribution is conditioned on two very disparate sources of information which are difficult to combine in a complementary way.A drawback of the TSM model is the assumption that source and target information is generated monotonically \n",
      "\n",
      " sum::: ['The World Health Organization (WHO) has developed the World Cancer Network (WCN).'] \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-dc8ddbde670d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sum:::\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-20eb7a1654a0>\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'longest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtranslated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtgt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtgt_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m             )\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1793\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m             )\n\u001b[1;32m   1797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m         )\n\u001b[1;32m   1398\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         )\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1089\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m                 )\n\u001b[1;32m   1093\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attn_layer_head_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             )\n\u001b[1;32m    443\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ID, cluster in get_clusters(cluster_model).items():\n",
    "    sentences = \".\".join(cluster)\n",
    "    print(sentences, \"\\n\\n\", \"sum:::\", summarize(sentences), \"\\n\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb0f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
