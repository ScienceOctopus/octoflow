{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "665e945b",
   "metadata": {},
   "source": [
    "# Recursive Clustering and Summarization\n",
    "\n",
    "Plan:\n",
    "- recursively cluster collections\n",
    "- create tree of clusters (the HDBSCAN does this anyways but likely not as we want)\n",
    "- cluster until max-depth is reached or (better) until each leaf only has one \"plausible\" cluster (based on thresholds or probabilities)\n",
    "- try summarizing to get \"main idea\" out of cluster\n",
    "\n",
    "\n",
    "- cluster on keywords ( randomize all grammar + stop words )\n",
    "- topic clusters\n",
    "- context: title, abstract, etc. keywords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7cdbf",
   "metadata": {},
   "source": [
    "## Recursively cluster \n",
    "\n",
    "Based on the topic_clustering notebook, we will try with Agglomerative Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022c35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"downloads/40k_balanced_pm_acl.csv\")#.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ed786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = df[df.labels == 1]\n",
    "\n",
    "\n",
    "sentences = list(pos[\"text\"]) #otherwise key error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f058d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59967de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_h = pos[pos[\"source\"].isin([\"Oct1_clinical_studies_pm\",'oct3_labels', 'labels_oct7'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a7c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_h = list(pos_h[\"text\"]) #otherwise key error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "print(\"Encode the corpus ... get a coffee in the meantime\")\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = model.encode(sentences, batch_size=64, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a521f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "\n",
    "def cluster(embeddings, **kwargs):\n",
    "    embeddings = embeddings.cpu()\n",
    "    # Normalize the embeddings to unit length\n",
    "    corpus_embeddings = embeddings /  np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "    # Perform kmean clustering\n",
    "    clustering_model = AgglomerativeClustering(**kwargs) #, affinity='cosine', linkage='average', distance_threshold=0.4)\n",
    "    clustering_model.fit(corpus_embeddings)\n",
    "   # cluster_assignment = clustering_model.labels_\n",
    "    return clustering_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(clustering_model):\n",
    "    \n",
    "    clusters = {}\n",
    "    for sentence_id, cluster_id in enumerate(clustering_model.labels_):\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        try:\n",
    "            clusters[cluster_id].append(sentences[sentence_id])\n",
    "        except:\n",
    "            print(sentence_id, \"sentence_id\")\n",
    "    return clusters\n",
    "   \n",
    "#     for i, cluster in clustered_sentences.items():\n",
    "#         print(\"Cluster \", i+1)\n",
    "#         print(cluster)\n",
    "#         print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a3cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d06dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model = cluster(sample, n_clusters=None, distance_threshold=1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5091d82",
   "metadata": {},
   "source": [
    "Cluster Model attributes\n",
    "\n",
    "   n_clusters_ : int\n",
    "        The number of clusters found by the algorithm. If\n",
    "        ``distance_threshold=None``, it will be equal to the given\n",
    "        ``n_clusters``.\n",
    "\n",
    "    labels_\n",
    "    n_leaves_\n",
    "\n",
    "    n_connected_components_ : The estimated number of connected components in the graph.\n",
    "\n",
    "    children_ : array-like of shape (n_samples-1, 2)\n",
    "        The children of each non-leaf node. Values less than `n_samples`\n",
    "        correspond to leaves of the tree which are the original samples.\n",
    "        A node `i` greater than or equal to `n_samples` is a non-leaf\n",
    "        node and has children `children_[i - n_samples]`. Alternatively\n",
    "        at the i-th iteration, children[i][0] and children[i][1]\n",
    "        are merged to form node `n_samples + i`\n",
    "\n",
    "    distances_ : array-like of shape (n_nodes-1,)\n",
    "        Distances between nodes in the corresponding place in `children_`.\n",
    "        Only computed if `distance_threshold` is used or `compute_distances`\n",
    "        is set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd412499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# ii = itertools.count(sample.shape[0])\n",
    "# [{'node_id': next(ii), 'left': x[0], 'right':x[1]} for x in cluster_model.children_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8afe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(get_clusters(cluster_model).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db754668",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_clusters(cluster_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab426ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for thresh in [1, 1.2, 1.4, 1.8]:\n",
    "    cluster_model = cluster(sample, n_clusters=None, distance_threshold=thresh)\n",
    "    plt.hist([len(v) for v in get_clusters(cluster_model).values()], bins='auto', label=str(thresh))\n",
    "    plt.title(\"Threshold \" + str(thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d1aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collection_to_clusters(texts, model=model,  **kwargs):\n",
    "    embs = model.encode(texts, batch_size=64, show_progress_bar=True, convert_to_tensor=True)\n",
    "    cluster_model = cluster(embs, **kwargs)\n",
    "    return get_clusters(cluster_model).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4644a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_tree = {}\n",
    "lens = [len(v) for v in clusters.values()]\n",
    "for i, v in clusters.items():\n",
    "    if len(v) > 25:\n",
    "        cluster_tree[i] = {\"parent\" : v}\n",
    "        cluster_tree[i] = {\"children\" :[*collection_to_clusters(v, n_clusters=None, distance_threshold=0.4)]}\n",
    "        #get values, embed and sample again with lower threshold\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab235893",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in cluster_tree.items():\n",
    "    print(i)\n",
    "    for sent in v[\"children\"]:\n",
    "        print(sent)\n",
    "        print(\"\\n\\n\")\n",
    "    print(\"-------------- \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c8830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0d66f3a9",
   "metadata": {},
   "source": [
    "len(get_clusters(cluster_model).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict(enumerate(cluster_model.children_, cluster_model.n_leaves_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e0608",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "**Tried: Google Pegasus**. Result: Does a terrible job of keeping the important information and doesn't retain the question but guesses at a conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e90d53",
   "metadata": {},
   "source": [
    "### Pegasus Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = 'google/pegasus-xsum'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb7cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize(sentences):\n",
    "    batch = tokenizer(sentences, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = model.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe1b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae6a056",
   "metadata": {},
   "source": [
    "### T5 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79511b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "ARTICLE = \"\"\" Background: Trust is a critical component of competency committees given their high-stakes decisions. Research from outside of medicine on group trust has not focused on trust in group decisions, and \"group trust\" has not been clearly defined. The purpose was twofold: to examine the definition of trust in the context of group decisions and to explore what factors may influence trust from the perspective of those who rely on competency committees through a proposed group trust model. Methods: The authors conducted a literature search of four online databases, seeking articles published on trust in group settings. Reviewers extracted, coded, and analyzed key data including definitions of trust and factors pertaining to group trust. Results: The authors selected 42 articles for full text review. Although reviewers found multiple general definitions of trust, they were unable to find a clear definition of group trust and propose the following: a group-directed willingness to accept vulnerability to actions of the members based on the expectation that members will perform a particular action important to the group, encompassing social exchange, collective perceptions, and interpersonal trust. Additionally, the authors propose a model encompassing individual level factors (trustor and trustee), interpersonal interactions, group level factors (structure and processes), and environmental factors.\"\"\"\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"snrspeaks/t5-one-line-summary\") #snrspeaks/t5-one-line-summary\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snrspeaks/t5-one-line-summary\")\n",
    "\n",
    "# T5 uses a max_length of 512 so we cut the article to 512 tokens.\n",
    "inputs = tokenizer.encode(\"summarize: \" + ARTICLE, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "tokenizer.decode(outputs[0])\n",
    "def summarize(text):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9bdfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(\"I have seen a ghost in my shed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea74cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"I have seen a ghost in my shed\"[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2442d",
   "metadata": {},
   "source": [
    "### Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7575d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ID, cluster in get_clusters(cluster_model).items():\n",
    "    sentences = \".\".join(cluster)\n",
    "    print(sentences)\n",
    "    print( \"\\n\\n\", \"sum:::\", summarize(sentences[:256]), \"\\n\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d79bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip bertopic --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91484216",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall bertopic --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall umap\n",
    "pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e69836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping bertopic as it is not installed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "213c41df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.19.5\n",
      "Uninstalling numpy-1.19.5:\n",
      "  Successfully uninstalled numpy-1.19.5\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb3ae5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Using cached bertopic-0.9.3-py2.py3-none-any.whl (57 kB)\n",
      "  Using cached bertopic-0.9.2-py2.py3-none-any.whl (57 kB)\n",
      "  Using cached bertopic-0.9.1-py2.py3-none-any.whl (55 kB)\n",
      "  Using cached bertopic-0.9.0-py2.py3-none-any.whl (55 kB)\n",
      "  Using cached bertopic-0.8.1-py2.py3-none-any.whl (53 kB)\n",
      "  Using cached bertopic-0.8.0-py2.py3-none-any.whl (53 kB)\n",
      "  Using cached bertopic-0.7.0-py2.py3-none-any.whl (40 kB)\n",
      "  Using cached bertopic-0.6.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting torch>=1.4.0\n",
      "  Using cached torch-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "Collecting umap-learn>=0.5.0\n",
      "  Using cached umap_learn-0.5.2-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.19.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from bertopic) (1.19.5)\n",
      "Collecting hdbscan>=0.8.27\n",
      "  Using cached hdbscan-0.8.27-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting sentence-transformers>=0.4.1\n",
      "  Using cached sentence_transformers-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from bertopic) (4.62.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from bertopic) (0.24.1)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from bertopic) (1.1.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from hdbscan>=0.8.27->bertopic) (1.5.3)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from hdbscan>=0.8.27->bertopic) (1.0.1)\n",
      "Requirement already satisfied: cython>=0.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from hdbscan>=0.8.27->bertopic) (0.29.22)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from hdbscan>=0.8.27->bertopic) (1.16.0)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a807311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic==0.9.2\n",
      "  Using cached bertopic-0.9.2-py2.py3-none-any.whl (57 kB)\n",
      "Collecting plotly<4.14.3,>=4.7.0\n",
      "  Using cached plotly-4.14.2-py2.py3-none-any.whl (13.2 MB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement numpy>=1.20.0 (from bertopic) (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0rc1, 1.13.0rc2, 1.13.0, 1.13.1, 1.13.3, 1.14.0rc1, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0rc1, 1.16.0rc2, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0rc1, 1.17.0rc2, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0rc1, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0rc1, 1.19.0rc2, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for numpy>=1.20.0\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bertopic==0.9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f19129a",
   "metadata": {},
   "source": [
    "## BERTopic topic modeling + set intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29137cc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named bertopic",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-07ae2b298db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentence-transformers/all-mpnet-base-v2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_probabilities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named bertopic"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "m = BERTopic(embedding_model='sentence-transformers/all-mpnet-base-v2', calculate_probabilities=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ed1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = topic_model.fit_transform(sents_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = topic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce08682",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_h[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(0)  # Select the most frequent topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ec9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(1)  # Select the most frequent topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = m.transform(sents_h[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4722dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = sentences[1100]\n",
    "\n",
    "def extract_topics(texts, distance_thresh=0.035, model=topic_model):\n",
    "    topic_labels = model.transform(texts)[0]\n",
    "    topic_dict = {}\n",
    "    for idx, ID in enumerate(topic_labels):\n",
    "        topics = model.get_topic(ID)\n",
    "        for t in topics:\n",
    "            topic = t[0]\n",
    "            dist = t[1]\n",
    "            if dist > distance_thresh:\n",
    "                if not topic_dict.get(topic):\n",
    "                    topic_dict[topic] = [ texts[idx] ] \n",
    "                else:\n",
    "                    sents = topic_dict[topic] + [texts[idx]]\n",
    "                    topic_dict[topic] = sents\n",
    "    return topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = extract_topics(sents_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"topic_dict.json\", \"w\") as f:\n",
    "    json.dump(topic_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topics_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269c3e02",
   "metadata": {},
   "source": [
    "## Hierachy by source text overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ab53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
