{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Octopus\n",
    "\n",
    "## Goals\n",
    "\n",
    "* Identify and pull out sentences from papers (across all fields of STEM) that identify the/a Research Problem\n",
    "\n",
    "* Collate/cluster those (are any papers addressing the same Problem?)\n",
    "\n",
    "* Create a hierarchy of those Problems – linking them all to one another such that the most general ones are at the top (e.g. ‘diagnosing and curing breast cancer’) with more specific Problems linked further down (e.g. ‘the best chemotherapy regimes for triple negative breast cancer patients’).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "\n",
    "  * **Text analysis**: Looking at patterns of problem vs non-problem statements eg. often occuring bigrams, trigrams, phrases. Interesting library: [scattertext](https://github.com/JasonKessler/scattertext)\n",
    "\n",
    "  \n",
    "\n",
    "  * **Rule-based matching** as final processing step (*after model prediction*) to clean false positives and false negatives. Either regex or spaCy's [Phrase Matcher](https://spacy.io/api/phrasematcher) [[interactive](https://explosion.ai/demos/matcher)] are good options\n",
    "    * Advanced: [Dependency Matching](https://spacy.io/usage/v3#features-dep-matcher) working on syntax trees instead of sentence patterns\n",
    "  * **Hierarchical Clustering**: exploratory notebooks understanding the current SotA in unsupervised clustering and trying promising libraries or algorithms with Octopus' data and seeing if it’s feasible\n",
    "\n",
    "  \n",
    "\n",
    "  * **DevOps**: hooks, AWS configs, scripts, GH actions and general CI / CD  for successful testing, validating and building workflows\n",
    "\n",
    "  \n",
    "\n",
    "  * **Software 2.0 Infra**: Setup of an [active learning](https://humanloop.com/blog/why-you-should-be-using-active-learning) for efficient human labeling using [prodi.gy](prodi.gy), [labelstud.io](https://labelstud.io/) or similar\n",
    "\n",
    "    \n",
    "    \n",
    "  * Bespoke **App** for Language Model Interpretation ala Markus' [Netlens](https://github.com/deepfx/netlens)\n",
    "\n",
    "  * **Clustering and Analysis** (use clusteval or hnet) or define custom cluster-quality metric. Try different approaches (HDBSCAN, UMAP, T-SNE)\n",
    "\n",
    "  * **Bespoke App** for open source contributors to label data and **create Regex-like pattern matching** through an easy to learn syntax eliminating/supporting software dev / modeling\n",
    "\n",
    "\n",
    "  * **Advanced: Automatic Pattern discovery** : Given, examples of text, find the underlying common patterns of subsets of them. This probably involves evolutionary algorithms, a good comp. linguistics knowledge and will warrant a stand-alone library. [Example: PatternOmatic](https://github.com/revuel/PatternOmatic/blob/develop/PatternOmatic/nlp/bnf.py)(doesn't really work)\n",
    "\n",
    "## DATASETs `/datasets`\n",
    "\n",
    "* Datasets in public Google Drive @ https://drive.google.com/drive/folders/1SN6nHxgW9InLpJhUm7bzirU4wzd7NT0G\n",
    "\n",
    "* `problem_statements.csv`: processed dataset consisting of 3500+ labels. Rows with \"PMID\" entry are biomedical and human-labeled by a team member. Check \"source\" column. Includes ~500 problem statements and 1500 non-problem statements from ACL (*computational linguistics*) papers; source: [Identifying problems and solutions in scientific text](https://link.springer.com/content/pdf/10.1007/s11192-018-2718-6.pdf)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
